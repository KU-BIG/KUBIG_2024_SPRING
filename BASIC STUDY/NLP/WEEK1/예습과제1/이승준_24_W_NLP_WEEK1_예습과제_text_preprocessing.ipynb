{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNRt+HEhglcxMmBYUrMiLz3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["텍스트 전처리의 가장 기본적인 파이프라인를 실습해보는 코드 과제입니다.\n","\n","과제에 주어진 방식대로 할 필요 없이, 여러분이 원하는 시도를 마음껏 해보셔도 좋습니다\n","(다른 형태소 분석기를 사용하거나, 불용어를 추가하거나 etc)."],"metadata":{"id":"XIKk0BR2AZwv"}},{"cell_type":"markdown","source":["## Goal\n","\n","프로틴 보충제 사이트에서 리뷰를 크롤링해 워드 클라우드 그리기!\n","\n","파이프라인\n","\n","1.   정규표현식으로 한글 추리기\n","2.   띄어쓰기 교정 (PyKospacing)\n","3.   형태소로 토큰화 (okt)\n","4.   불용어 제거\n","5.   원하는 단어 Konlpy 사전에 추가\n","6.   워드클라우드 그리기\n"],"metadata":{"id":"pVntH9GoBGQ0"}},{"cell_type":"markdown","source":["## 1. import, load data"],"metadata":{"id":"wP9dGBmSDuku"}},{"cell_type":"code","source":["!pip install konlpy\n","!pip install git+https://github.com/haven-jeon/PyKoSpacing.git"],"metadata":{"id":"zyKW6IFhDyLF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","import pandas as pd"],"metadata":{"id":"DDmS35drFiDy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"-kCv54uVFi8S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/MyDrive/24-winter KUBIG NLP/WEEK 1 예습과제 - text preprocessing/protein.csv\")"],"metadata":{"id":"ZgiHrfK9FkMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"0VKLk9iDF15_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. 정규 표현식으로 한글 단어만 남기기\n","\n","정규표현식으로 한글단어만 남기고 모두 제외하기\n","\n","정규표현식이란?\n","\n","* 특정 규칙이 있는 텍스트 데이터를 정제하는 것\n","* 정규표현식 모듈 re를 통해 구현 가능"],"metadata":{"id":"ONxa9uwHF2gG"}},{"cell_type":"code","source":["def extract_hangul(text):\n","    hangul = re.sub('[^가-힣]', ' ', text) # 한글과 공백 제외하고 지우기\n","    return hangul"],"metadata":{"id":"G_qbK9PiGX2R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example = extract_hangul(df['text'][1])\n","print(\"전처리 이전: \",df['text'][1])\n","print(\"전처리 이후: \",example)"],"metadata":{"id":"9xRtIPbYIcOk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. 띄어쓰기 교정(PyKoSpacing)\n","\n","PyKoSpacing은 띄어쓰기 교정해주는 패키지\n","\n","1. re 모듈로 한글외 다른 문자 공백화 -> Py로 공백뭉치들 하나의 공백으로\n","2. 일반적인 띄어쓰기도 적용"],"metadata":{"id":"Ndz0ToilTMZF"}},{"cell_type":"code","source":["from pykospacing import Spacing\n","spacing = Spacing()"],"metadata":{"id":"G8Znalha0cHj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def spacing_text(text):\n","    spacing_text = spacing(text)\n","    return spacing_text"],"metadata":{"id":"zjA8e6UW0keD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spaced = spacing_text(example)\n","print(\"띄어쓰기 전: \",example)\n","print(\"띄어쓰기 후: \",spaced)"],"metadata":{"id":"hiLT4xwN0zGK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. 형태소 분석기 (okt)\n","\n","한국어에서 토큰화 해주는 대표적인 도구 -> konlpy\n","\n","그중 가장 대표적인 형태소 분석기 -> Okt\n","\n","\n","*   토큰화란?\n","\n","주어진 텍스트에서 토큰(token)이라 불리는 단위로 나누는 작업\n","\n","토큰의 단위가 상황에 따라 다르지만, 보통 의미있는 단위로 토큰을 정의\n","\n","보통 단어(word) 로 나눈다.\n","\n","\n","\n","*   형태소란?\n","\n","의미를 가지는 가장 작은 말의 단위\n","\n"],"metadata":{"id":"d73tucrP07vT"}},{"cell_type":"code","source":["from konlpy.tag import Okt\n","okt = Okt()"],"metadata":{"id":"lHpIDtXI1l0Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_morphs(text):\n","    morphs = okt.morphs(text)\n","    return morphs # morph 는 형태소를 반환하는 메소드"],"metadata":{"id":"PL1AgWeN2cmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["morphs_ = extract_morphs(spaced)\n","print(\"형태소 분석 전: \",spaced)\n","print(\"형태소 분석 후: \",morphs_)"],"metadata":{"id":"ZhrMw5bo2zeU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. 불용어 제거\n","\n","분석에 있어 큰 의미가 없는 '불용어(stopword)'를 지정해줘야 함\n","\n","불용어를 텍스트 파일로 따로 저장해서 지정"],"metadata":{"id":"jwcADbPj27C9"}},{"cell_type":"code","source":["with open('/content/drive/MyDrive/24-winter KUBIG NLP/WEEK 1 예습과제 - text preprocessing/stopword.txt') as f:\n","    list_file = f.readlines()\n","stopwords_list = []\n","for stopword in list_file:\n","    stopwords = re.sub(r'[\\n]', '', stopword) # 줄바꿈, 공백 제거\n","    stopwords_list.append(stopwords) # 채우기\n","\n","def remove_stopwords(text):\n","    remove_stop = [x for x in text if x not in stopwords_list]\n","    return remove_stop"],"metadata":{"id":"wmx5adku3bMx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["remove_stop = remove_stopwords(morphs_)\n","print(\"불용어 제거 전: \",morphs_)\n","print(\"불용어 제거 후: \",remove_stop)"],"metadata":{"id":"1mK08oaW5d7Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["한글자 단어들은 모두 지우는게 더 나은 경우가 있다. 다만 '맛' '짱' 같은 단어들은 남기기"],"metadata":{"id":"St9jjEV05uba"}},{"cell_type":"code","source":["def remove_one(text):\n","    except_list = ['맛', '향', '짱']\n","    remove_one = [x for x in text if len(x) > 1 or x in except_list] # 중요단어 제외한 한글자 단어 지우기\n","    return remove_one"],"metadata":{"id":"K2s8vUF76PWK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["remove_one = remove_one(remove_stop)\n","print(\"한글자 단어 제거 전: \",remove_stop)\n","print(\"한글자 단어 제거 후: \",remove_one)"],"metadata":{"id":"3ANtPLNS6cxN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["모든 형태소가 똑같이 처리되기 때문에 '가성비' 같은 단어가 '가' '성비' 로 나뉘는 경우가 있다.\n","\n","이때는 konlpy 사전에 직접 단어를 추가 ->\n","os 모듈을 이용해 코랩 패키지에 저장된 konlpy 폴더에 직접 조작\n","\n","chdir 로 경로를 이동해주고, makedirs로 임시폴더를 만든 후, 임시폴더에서 단어사전을 수정한 후 원본폴더에 저장해준다.\n","\n","** FileNotFoundError가 발생하는 경우 아래 directory에서 python 버전이 잘못된 경우일 수 있습니다."],"metadata":{"id":"NPdkxXEn6e6-"}},{"cell_type":"code","source":["import os\n","\n","os.chdir('/usr/local/lib/python3.10/dist-packages/konlpy/java')\n","os.getcwd()\n","os.makedirs('./aaaa')"],"metadata":{"id":"7B-a3eVd8Ft0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.chdir('/usr/local/lib/python3.10/dist-packages/konlpy/java/aaaa') #임시 폴더로 이동\n","os.getcwd()"],"metadata":{"id":"hU5JcRYn9OQT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 임시폴더에 konlpy 사전 파일의 압축 풀기\n","\n","!jar xvf ../open-korean-text-2.1.0.jar"],"metadata":{"id":"MaAhWsK0-Ovo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["압축이 풀렸으니 names.txt 열어보기"],"metadata":{"id":"4Sny-uaJ-QVT"}},{"cell_type":"code","source":["with open(f\"/usr/local/lib/python3.10/dist-packages/konlpy/java/aaaa/org/openkoreantext/processor/util/noun/names.txt\") as f:\n","    data = f.read()"],"metadata":{"id":"J4g1laUK_7xw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"id":"c25839rL_zXK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["우선 세개의 단어 추가, 쓰기모드로 변경해 파일저장\n","\n","+ 몇단어 추가"],"metadata":{"id":"j4WJOJG3_13d"}},{"cell_type":"code","source":["data += '프로틴\\n가성비\\n밀크티\\n초코맛\\n딸기맛\\n'\n","\n","with open(f\"/usr/local/lib/python3.10/dist-packages/konlpy/java/aaaa/org/openkoreantext/processor/util/noun/names.txt\", 'w') as f:\n","    f.write(data)"],"metadata":{"id":"rr0_7gxBAJoL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이제 다시 파일 압축 시키기\n","\n","* 런타임을 재실행 해야 함"],"metadata":{"id":"K-nlkIweAfLg"}},{"cell_type":"code","source":["!jar cvf ../open-korean-text-2.1.0.jar *"],"metadata":{"id":"Xyk1vNUkAuBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(okt.nouns(\"가성비\"))"],"metadata":{"id":"Tw_4v5lMAyoV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["전과정 하나로 통합"],"metadata":{"id":"oZlBPcIWA3td"}},{"cell_type":"code","source":["from konlpy.tag import Okt\n","okt = Okt()\n","\n","from pykospacing import Spacing\n","spacing = Spacing()\n","\n","except_list = ['맛','향','짱']\n","\n","with open('/content/drive/MyDrive/24-winter KUBIG NLP/WEEK 1 예습과제 - text preprocessing/stopword.txt') as f:\n","    list_file = f.readlines()\n","\n","stopwords_list = []\n","for stopword in list_file:\n","  stopwords = re.sub('[\\n]', '', stopword)\n","  stopwords_list.append(stopwords)\n","\n","def review_to_words(raw_review):\n","  text = re.sub('[^가-힣]', ' ', raw_review)\n","  text = spacing(text)\n","  text = okt.morphs(text, stem=True)\n","  text = [x for x in text if x not in stopwords_list]\n","  text = [x for x in text if len(x)>1 or x in except_list]\n","  text = \" \".join(text)\n","  return text"],"metadata":{"id":"oGoME9ALB3M0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이제 word_list를 만들어 전처리한 단어들을 모아주기"],"metadata":{"id":"qc187JkcF-EF"}},{"cell_type":"code","source":["import tqdm\n","df_len = df.shape[0]\n","word_list = []\n","for i in tqdm.tqdm(range(df_len)):\n","  word_list.append(review_to_words(df['text'][i]))"],"metadata":{"id":"KZaHdYmmNIuS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##wordcloud 로 시각화"],"metadata":{"id":"k7EOTfd9NOnf"}},{"cell_type":"code","source":["from wordcloud import WordCloud\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","def displayWorldCloud(data = None, backgroundcolor = 'white', width = None, height = None):\n","    wordcloud = WordCloud(font_path = '/content/drive/MyDrive/24-winter KUBIG NLP/WEEK 1 예습과제 - text preprocessing/MALGUN.TTF',\n","                          background_color = backgroundcolor,\n","                          width = width,\n","                          height = height).generate(data)\n","    plt.figure(figsize = (15 , 10))\n","    plt.imshow(wordcloud)\n","    plt.axis(\"off\")\n","    plt.show()"],"metadata":{"id":"8TIvEPPCNcxY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["displayWorldCloud(data = ' '.join(word_list), width=600, height=400)"],"metadata":{"id":"a7caqRZ2OjFz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 번외 다른 형태소 분석기 사용"],"metadata":{"id":"gzAy_iZCOxjN"}},{"cell_type":"code","source":["!pip install pip==20.0.2 pororo fairseq==0.10.2\n","\n","!pip uninstall torch torchvision\n","!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu"],"metadata":{"id":"jFQAThKQlpv8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pororo import Pororo\n","\n","Pororo.available_models(\"dp\")\n","dp = Pororo(task=\"dep_parse\", lang=\"ko\")"],"metadata":{"id":"2nw8FKoxlqJu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_morphs(text):\n","    morphs_po = dp(text)\n","    return morphs_po # morph 는 형태소를 반환하는 메소드"],"metadata":{"id":"xDJGmFSQmh_x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["morphs_ = extract_morphs(spaced)\n","print(\"형태소 분석 전: \",spaced)\n","print(\"형태소 분석 후: \",morphs_)"],"metadata":{"id":"OH5siMscmqbI"},"execution_count":null,"outputs":[]}]}
