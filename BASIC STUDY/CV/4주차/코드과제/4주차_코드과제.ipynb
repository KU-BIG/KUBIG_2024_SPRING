{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A62Nr9-wrjQ6"
      },
      "source": [
        "#4ì£¼ì°¨ ê³¼ì œ ì„¤ëª…\n",
        "<p>ì´ë²ˆ ê³¼ì œì˜ ëª©í‘œëŠ” ì„¸ì…˜ ì‹œê°„ì— ë°°ìš´ Generation model ì¤‘ GANì„ ì‹¤ìŠµí•´ë³´ë©´ì„œ\n",
        " 1) discriminatorì™€ generatorë¥¼ ì–´ë–»ê²Œ êµëŒ€ë¡œ í•™ìŠµì‹œì¼œì•¼ í•˜ëŠ”ì§€ 2) ì‹¤ì œë¡œ ì–´ë–¤ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ëŠ”ì§€ 3) GANì„ ë°œì „ì‹œí‚¨ LSGANê³¼ DCGANì€ ì–´ë–»ê²Œ êµ¬í˜„ë˜ëŠ”ì§€ì— ëŒ€í•´ ì—¬ëŸ¬ë¶„ë“¤ì´ ì§ì ‘ ëŠë¼ëŠ” ê²ƒì…ë‹ˆë‹¤.</p>\n",
        "\n",
        "<p>GANì„ ì§ì ‘ scratchë¶€í„° êµ¬í˜„í•˜ëŠ” ê²ƒì€ ì–´ë ¤ìš´ ì¼ì´ê¸°ì—, ê¸€ë¡œë§Œ ë“¤ì—ˆë˜ ê°œë…ì„ ì¢€ ë” ìƒì„¸íˆ ì½”ë“œë¡œ ì´í•´í•˜ëŠ”ë° ì¤‘ì ì„ ë‘ì—ˆìŠµë‹ˆë‹¤. ğŸ˜‚</p>\n",
        "\n",
        "<p> ê³¼ì œëŠ” í›Œë¥­í•œ êµë³´ì¬ì¸ CS231 ê³µì‹ assignment3ì„ ë‹¤ìˆ˜ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤ ğŸ™‡ğŸ»â€â™‚ï¸</p>\n",
        "\n",
        "í•´ë‹¹ ê³¼ì œëŠ” ëŸ°íƒ€ì„ ì—°ê²°ì‹œ 'GPU' ì‚¬ìš©ì„ ê°•ë ¥íˆ ê¶Œì¥ë“œë¦½ë‹ˆë‹¤!!(CPU ì“°ë©´ í•™ìŠµì‹œí‚¬ ë•Œ ë§ì´ ëŠë¦½ë‹ˆë‹¤..!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqkyZSg-j5-S",
        "tags": [
          "pdf-title"
        ]
      },
      "source": [
        "# Generative Adversarial Networks (GANs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W7PETxWej5-V",
        "tags": [
          "pdf-ignore"
        ]
      },
      "outputs": [],
      "source": [
        "# Setup cell. run!\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision.datasets as dset\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # Set default size of plots.\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "def show_images(images):\n",
        "    images = np.reshape(images, [images.shape[0], -1]) # Images reshape to (batch_size, D).\n",
        "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
        "    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
        "\n",
        "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
        "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhdMz4jNVEjE"
      },
      "source": [
        "gan-checks.npzëŠ” ì½”ë“œê³¼ì œ.ipynbì™€ í•¨ê»˜ ì˜¬ë ¤ë“œë¦° íŒŒì¼ë¡œ colab ê¸°ì¤€ ì¢Œì¸¡ íŒŒì¼ ë²„íŠ¼ ëˆ„ë¥´ì…”ì„œ í˜„ì¬ ìœ„ì¹˜ì— ì—…ë¡œë“œí•˜ì‹  í›„ì— ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì‹œë©´ ë©ë‹ˆë‹¤!\n",
        "\n",
        "ê³¼ì œì— í‹€ë¦° ë‹µì•ˆì„ ì‘ì„±í•œ í›„ ê³„ì† ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ì„œ ì‹œê°„ ë‚­ë¹„í•˜ì§€ ì•Šë„ë¡ ë‹µì•ˆì´ ë§ì„ ë•Œê¹Œì§€ ì²´í¬í•´ì£¼ëŠ” íŒŒì¼ì…ë‹ˆë‹¤ ã…ã…"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zXOlKVjwU9pX"
      },
      "outputs": [],
      "source": [
        "# í˜„ì¬ìœ„ì¹˜ì— íŒŒì¼ ì—…ë¡œë“œ í›„ ì‹¤í–‰. ë¬¸ì œ ë°œìƒ ì‹œ DM ì£¼ì„¸ìš”!\n",
        "answers = dict(np.load('gan-checks.npz'))\n",
        "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ5c0xnYpuOm"
      },
      "source": [
        "# Help Functions 1\n",
        "ê¸°ë³¸ì ì¸ ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤ì…ë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Lx2b91tXpVQO"
      },
      "outputs": [],
      "source": [
        "class ChunkSampler(sampler.Sampler):\n",
        "    \"\"\"Samples elements sequentially from some offset.\n",
        "    Arguments:\n",
        "        num_samples: # of desired datapoints\n",
        "        start: offset where we should start selecting from\n",
        "    \"\"\"\n",
        "    def __init__(self, num_samples, start=0):\n",
        "        self.num_samples = num_samples\n",
        "        self.start = start\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.start + self.num_samples))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "def preprocess_img(x):\n",
        "    return 2 * x - 1.0\n",
        "\n",
        "def deprocess_img(x):\n",
        "    return (x + 1.0) / 2.0\n",
        "\n",
        "def rel_error(x,y):\n",
        "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
        "\n",
        "def count_params(model):\n",
        "    \"\"\"Count the number of parameters in the current TensorFlow graph \"\"\"\n",
        "    param_count = np.sum([np.prod(p.size()) for p in model.parameters()])\n",
        "    return param_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcHnNzLnj5-X",
        "tags": [
          "pdf-ignore"
        ]
      },
      "source": [
        "## Dataset\n",
        "í•™ìŠµ ë°ì´í„°ëŠ” MNIST ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤ :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X9i7TUkj5-Z",
        "scrolled": false,
        "tags": [
          "pdf-ignore"
        ]
      },
      "outputs": [],
      "source": [
        "NUM_TRAIN = 50000\n",
        "NUM_VAL = 5000\n",
        "\n",
        "NOISE_DIM = 96\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "# ë°”ë¡œ ì‹¤í–‰í•˜ì…”ë„ ë˜ê³ , MNIST dataë¥¼ ë°›ì„ ê²½ë¡œì„¤ì •ì„ í™˜ê²½ì— ë§ê²Œ ì„¤ì •í•´ì£¼ì…”ë„ ë©ë‹ˆë‹¤.\n",
        "mnist_train = dset.MNIST(\n",
        "    './cs231n/datasets/MNIST_data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=T.ToTensor()\n",
        ")\n",
        "loader_train = DataLoader(\n",
        "    mnist_train,\n",
        "    batch_size=batch_size,\n",
        "    sampler=ChunkSampler(NUM_TRAIN, 0)\n",
        ")\n",
        "\n",
        "mnist_val = dset.MNIST(\n",
        "    './cs231n/datasets/MNIST_data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=T.ToTensor()\n",
        ")\n",
        "loader_val = DataLoader(\n",
        "    mnist_val,\n",
        "    batch_size=batch_size,\n",
        "    sampler=ChunkSampler(NUM_VAL, NUM_TRAIN)\n",
        ")\n",
        "\n",
        "imgs = next(loader_train.__iter__())[0].view(batch_size, 784).numpy().squeeze()\n",
        "show_images(imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M3Zw0hYj5-b"
      },
      "source": [
        "## Random Noise : Input of Generation Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PphjJP5VvMG9"
      },
      "source": [
        "# H.W 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YGtwpNnWibN"
      },
      "source": [
        "ì²«ë²ˆì§¸ ê³¼ì œëŠ” ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” Generatorì— ì…ë ¥í•  'ë…¸ì´ì¦ˆ'ë¥¼ ìƒ˜í”Œë§í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤. Hintì— ì£¼ì–´ì§„ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê³  shapeì™€ rangeë¥¼ ê³ ë ¤í•˜ì—¬ ë…¸ì´ì¦ˆ ìƒ˜í”Œë§ í•¨ìˆ˜ë¥¼ ì™„ì„±í•´ì£¼ì„¸ìš”!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZYzLMJcSvs3J"
      },
      "outputs": [],
      "source": [
        "def sample_noise(batch_size, dim, seed=None):\n",
        "    \"\"\"\n",
        "    Generate a PyTorch Tensor of uniform random noise.\n",
        "\n",
        "    Input:\n",
        "    - batch_size: Integer giving the batch size of noise to generate.\n",
        "    - dim: Integer giving the dimension of noise to generate.\n",
        "\n",
        "    Output:\n",
        "    - A PyTorch Tensor of shape (batch_size, dim) containing uniform\n",
        "      random noise in the range (-1, 1).\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "    # ************* START ******************\n",
        "    # TODO : random noiseë¥¼ ë§Œë“œëŠ” ì‹ì„ ì§œì£¼ì„¸ìš”\n",
        "    # Hint 1: -1ë¶€í„° 1ì‚¬ì´ì˜ uniform noiseë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”. shapeì€ [batch_size, dim] ì…ë‹ˆë‹¤.\n",
        "    # Hint 2: torch.randë¥¼ ì‚¬ìš©í•˜ì„¸ìš”\n",
        "\n",
        "    return ###############\n",
        "\n",
        "    # ************* END ******************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sample_noise_test",
        "outputId": "52726993-cdb4-42b4-ab9f-ebef4a97ac17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All tests passed!\n"
          ]
        }
      ],
      "source": [
        "# sample_noise í•¨ìˆ˜ë¥¼ ì˜ ë§Œë“¤ì—ˆëŠ”ì§€ í…ŒìŠ¤íŠ¸í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. ì—ëŸ¬ ë°œìƒ ì‹œ Hintë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”!\n",
        "\n",
        "def test_sample_noise():\n",
        "    batch_size = 3\n",
        "    dim = 4\n",
        "    torch.manual_seed(231)\n",
        "    z = sample_noise(batch_size, dim)\n",
        "    np_z = z.cpu().numpy()\n",
        "    assert np_z.shape == (batch_size, dim)\n",
        "    assert torch.is_tensor(z)\n",
        "    assert np.all(np_z >= -1.0) and np.all(np_z <= 1.0)\n",
        "    assert np.any(np_z < 0.0) and np.any(np_z > 0.0)\n",
        "    print('All tests passed!')\n",
        "\n",
        "test_sample_noise()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0JSkADnj5-e",
        "tags": [
          "pdf-ignore"
        ]
      },
      "source": [
        "## Flatten & Unflatten & Weight initalization\n",
        "\n",
        "1ì°¨ì›ì˜ ë²¡í„°ë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” flatten í•¨ìˆ˜ì™€ ê·¸ ë°˜ëŒ€ì¸ unflatten, ê·¸ë¦¬ê³   weight initializerë¡œ ìì£¼ ì“°ì´ëŠ” Xavier initalizationì…ë‹ˆë‹¤. ê³¼ì œ ì‹œ ì‚¬ìš©ë˜ëŠ” í•¨ìˆ˜ì´ë‹ˆ ê¸°ì–µí•´ì£¼ì„¸ìš”!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jq-QrHKRqcBR"
      },
      "outputs": [],
      "source": [
        "# run!\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size() # read in N, C, H, W\n",
        "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
        "\n",
        "class Unflatten(nn.Module):\n",
        "    \"\"\"\n",
        "    An Unflatten module receives an input of shape (N, C*H*W) and reshapes it\n",
        "    to produce an output of shape (N, C, H, W).\n",
        "    \"\"\"\n",
        "    def __init__(self, N=-1, C=128, H=7, W=7):\n",
        "        super(Unflatten, self).__init__()\n",
        "        self.N = N\n",
        "        self.C = C\n",
        "        self.H = H\n",
        "        self.W = W\n",
        "    def forward(self, x):\n",
        "        return x.view(self.N, self.C, self.H, self.W)\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.ConvTranspose2d):\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj2OateGj5-f"
      },
      "source": [
        "# H.W 2 : Discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU7Gj8i-xhN4"
      },
      "source": [
        "DiscriminatorëŠ” ì•„ë˜ì™€ ê°™ì€ êµ¬ì¡°ì…ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        " * nn.Flatten()\n",
        " * Fully connected layer with input size 784 and output size 256\n",
        " * LeakyReLU with alpha 0.01\n",
        " * Fully connected layer with input_size 256 and output size 256\n",
        " * LeakyReLU with alpha 0.01\n",
        " * Fully connected layer with input size 256 and output size 1\n",
        "\n",
        "\n",
        "*   ë§ˆì§€ë§‰ output shapeì€ [batch_size, 1] í˜•íƒœë¥¼ ê°–ìŠµë‹ˆë‹¤\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE5b6q7KZEFv"
      },
      "source": [
        "ë¹ˆì¹¸ì— ë“¤ì–´ê°€ì•¼ í•  ì½”ë“œë¥¼ ì™„ì„±í•´ì£¼ì„¸ìš”! ì½”ë“œë¥¼ ì‘ì„±í•˜ë©´ì„œ vanila GANì˜ ë„¤íŠ¸ì›Œí¬ê°€ ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆëŠ”ì§€ ì´í•´í•˜ì‹œë©´ ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cuiOZemvqjDV"
      },
      "outputs": [],
      "source": [
        "def discriminator(seed=None):\n",
        "    \"\"\"\n",
        "    Build and return a PyTorch model implementing the architecture above.\n",
        "    \"\"\"\n",
        "\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "    model = None\n",
        "\n",
        "    # ************* START ******************\n",
        "\n",
        "    model = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        ###############\n",
        "        ###############\n",
        "        ###############\n",
        "        ###############\n",
        "        ###############\n",
        "    )\n",
        "\n",
        "    # *************** END *******************\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwtfx2vNj5-g",
        "outputId": "d60b9b04-f4f4-448d-87eb-925df5649197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct number of parameters in discriminator.\n"
          ]
        }
      ],
      "source": [
        "# ì™„ì„±í•œ Discriminatorì˜ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸\n",
        "def test_discriminator(true_count=267009):\n",
        "    model = discriminator()\n",
        "    cur_count = count_params(model)\n",
        "    if cur_count != true_count:\n",
        "        print('Incorrect number of parameters in discriminator. Check your achitecture.')\n",
        "    else:\n",
        "        print('Correct number of parameters in discriminator.')\n",
        "\n",
        "test_discriminator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vciao8Lj5-h"
      },
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaQikOQgyprj"
      },
      "source": [
        "GeneratorëŠ” ì•„ë˜ì™€ ê°™ì€ êµ¬ì¡°ì…ë‹ˆë‹¤\n",
        "\n",
        "\n",
        "\n",
        " * Fully connected layer from noise_dim to 1024\n",
        " * `ReLU`\n",
        " * Fully connected layer with output size 1024\n",
        " * `ReLU`\n",
        " * Fully connected layer with output size 784\n",
        " * `TanH` (to clip the image to be in the range of [-1,1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdVeKLdEZVjN"
      },
      "source": [
        "Discriminatorì™€ ë§ˆì°¬ê°€ì§€ë¡œ ë¹ˆì¹¸ì„ ì ì ˆí•˜ê²Œ ì±„ì›Œì£¼ì‹œë©´ ë©ë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "g5myrLJiqpVh"
      },
      "outputs": [],
      "source": [
        "def generator(noise_dim=NOISE_DIM, seed=None):\n",
        "    \"\"\"\n",
        "    Build and return a PyTorch model implementing the architecture above.\n",
        "    \"\"\"\n",
        "\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "    model = None\n",
        "\n",
        "    model = nn.Sequential(\n",
        "        ###############,\n",
        "        ###############,\n",
        "        ###############,\n",
        "        ###############,\n",
        "        ###############,\n",
        "        ###############\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTQSgkeMj5-h",
        "outputId": "c1a29e87-27b4-41a6-d6ab-e9190d7d0e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct number of parameters in generator.\n"
          ]
        }
      ],
      "source": [
        "# ì™„ì„±í•œ generatorì˜ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸\n",
        "def test_generator(true_count=1858320):\n",
        "    model = generator(4)\n",
        "    cur_count = count_params(model)\n",
        "    if cur_count != true_count:\n",
        "        print('Incorrect number of parameters in generator. Check your achitecture.')\n",
        "    else:\n",
        "        print('Correct number of parameters in generator.')\n",
        "\n",
        "test_generator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJcQ3rcUj5-i"
      },
      "source": [
        "# H.W 3 : GAN Loss\n",
        "\n",
        "\n",
        "##   Generator Loss\n",
        "$$\\ell_G  =  -\\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$ <br>\n",
        "\n",
        "## Discriminator Loss\n",
        "$$ \\ell_D = -\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] - \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$ <Br>\n",
        "\n",
        "ì´ Lossë“¤ì„ minimizingí•˜ê¸° ìœ„í•´ ì›ë˜ Lossì‹ì— -ë¥¼ ë¶™ì˜€ìŠµë‹ˆë‹¤.\n",
        "\n",
        "$$ bce(s, y) = -y * \\log(s) - (1 - y) * \\log(1 - s) $$ <Br>\n",
        "\n",
        "*   í•´ë‹¹ ì‹ì„ ë‚˜ì´ë¸Œí•˜ê²Œ ì ìš©í•˜ë©´ unstableí•˜ê¸° ë•Œë¬¸ì— ì•„ë˜ì˜ bce í•¨ìˆ˜ì— stableí•œ implementationì„ ì œê³µí•˜ì˜€ìŠµë‹ˆë‹¤.\n",
        "\n",
        "* $\\log D(G(z))$, $\\log D(x)$ and $\\log \\left(1-D(G(z))\\right)$ ì˜ expectationì„ ê³„ì‚°í•˜ëŠ” ë°©ì‹ì´ ì•„ë‹Œ, minibatch ì›ì†Œì— ëŒ€í•´ averagingì„ ì·¨í•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wHrDqxPj5-j"
      },
      "source": [
        "Test your generator and discriminator loss. You should see errors < 1e-7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HfVOCgiq0nwy"
      },
      "outputs": [],
      "source": [
        "def bce_loss(input, target):\n",
        "    \"\"\"\n",
        "    Numerically stable version of the binary cross-entropy loss function.\n",
        "\n",
        "    As per https://github.com/pytorch/pytorch/issues/751\n",
        "    See the TensorFlow docs for a derivation of this formula:\n",
        "    https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits\n",
        "\n",
        "    Inputs:\n",
        "    - input: PyTorch Tensor of shape (N, ) giving scores.\n",
        "    - target: PyTorch Tensor of shape (N,) containing 0 and 1 giving targets.\n",
        "\n",
        "    Returns:\n",
        "    - A PyTorch Tensor containing the mean BCE loss over the minibatch of input data.\n",
        "    \"\"\"\n",
        "    neg_abs = - input.abs()\n",
        "    loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n",
        "    return loss.mean()\n",
        "\n",
        "def discriminator_loss(logits_real, logits_fake):\n",
        "    \"\"\"\n",
        "    Computes the discriminator loss described above.\n",
        "\n",
        "    Inputs:\n",
        "    - logits_real: PyTorch Tensor of shape (N,) giving scores for the real data.\n",
        "    - logits_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
        "\n",
        "    Returns:\n",
        "    - loss: PyTorch Tensor containing (scalar) the loss for the discriminator.\n",
        "    \"\"\"\n",
        "    loss = None\n",
        "    # ************* START ******************\n",
        "    # TODO: Fake imageì— ëŒ€í•œ lossì™€ Real imageì— ëŒ€í•œ lossë¥¼ ê°ê° ê³„ì‚°í•˜ê³  í‰ê· í™”í•˜ì„¸ìš”\n",
        "    # Hint: ìœ„ì—ì„œ ì •ì˜í•œ bce_loss()ë¥¼ ì‚¬ìš©í•˜ì—¬ binary cross-entropyë°©ì‹ìœ¼ë¡œ ê° elementë“¤ì— ëŒ€í•œ lossë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤\n",
        "    # Hint: ì´ë•Œ bce_loss()ì˜ inputì€ logits_xxxxì´ë©° targetì€ torch.zeros_likeì™€ torch.ones_likeë¥¼ ì‚¬ìš©í•´ì„œ ì •ì˜í•´ì£¼ì„¸ìš”!\n",
        "\n",
        "    loss_fake = ###############\n",
        "    loss_real = ###############\n",
        "    loss = ###############\n",
        "\n",
        "    # ************* END ******************\n",
        "    return loss\n",
        "\n",
        "def generator_loss(logits_fake):\n",
        "    \"\"\"\n",
        "    Computes the generator loss described above.\n",
        "\n",
        "    Inputs:\n",
        "    - logits_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
        "\n",
        "    Returns:\n",
        "    - loss: PyTorch Tensor containing the (scalar) loss for the generator.\n",
        "    \"\"\"\n",
        "    loss = None\n",
        "    # ************* START ******************\n",
        "    # TODO: Fake imageì— ëŒ€í•œ lossë¥¼ ê³„ì‚°í•˜ì„¸ìš”\n",
        "    # Hint: torch.zeros_likeì™€ torch.ones_like ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì„œ ì •ì˜í•´ì£¼ì„¸ìš”!\n",
        "\n",
        "    loss = ###############\n",
        "\n",
        "    # ************* END ******************\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C93Ft93Oj5-k",
        "outputId": "db591015-6d3b-4995-e3ba-961222a27af9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum error in d_loss: 3.97058e-09\n"
          ]
        }
      ],
      "source": [
        "def test_discriminator_loss(logits_real, logits_fake, d_loss_true):\n",
        "    d_loss = discriminator_loss(torch.Tensor(logits_real).type(dtype),\n",
        "                                torch.Tensor(logits_fake).type(dtype)).cpu().numpy()\n",
        "    print(\"Maximum error in d_loss: %g\"%rel_error(d_loss_true, d_loss))\n",
        "\n",
        "test_discriminator_loss(\n",
        "    answers['logits_real'],\n",
        "    answers['logits_fake'],\n",
        "    answers['d_loss_true']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpU2nibMj5-k",
        "outputId": "ae897729-c94c-43ed-a904-9ec1427e714e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum error in g_loss: 4.4518e-09\n"
          ]
        }
      ],
      "source": [
        "def test_generator_loss(logits_fake, g_loss_true):\n",
        "    g_loss = generator_loss(torch.Tensor(logits_fake).type(dtype)).cpu().numpy()\n",
        "    print(\"Maximum error in g_loss: %g\"%rel_error(g_loss_true, g_loss))\n",
        "\n",
        "test_generator_loss(\n",
        "    answers['logits_fake'],\n",
        "    answers['g_loss_true']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRfbBYW4j5-l"
      },
      "source": [
        "# Optimizing our Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhuGED3Zj5-l"
      },
      "source": [
        "# Training a GAN!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VorrIjIQvn3f"
      },
      "source": [
        "# H.W 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4XCZUou0ZMsP"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(model):\n",
        "    \"\"\"\n",
        "    Construct and return an Adam optimizer for the model with learning rate 1e-3,\n",
        "    beta1=0.5, and beta2=0.999.\n",
        "\n",
        "    Input:\n",
        "    - model: A PyTorch model that we want to optimize.\n",
        "\n",
        "    Returns:\n",
        "    - An Adam optimizer for the model with the desired hyperparameters.\n",
        "    \"\"\"\n",
        "    optimizer = None\n",
        "    # ************* START ******************\n",
        "    #TODO : Adam optimizerë¥¼ ì •ì˜í•´ì£¼ì„¸ìš”. learning rate ì¡°ì ˆ ë° schedulerë„ ì ìš©í•´ë³´ì„¸ìš”.\n",
        "\n",
        "    optimizer = ###############\n",
        "\n",
        "    # ************* END ******************\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def run_a_gan(D, G, D_solver, G_solver, discriminator_loss, generator_loss, loader_train, show_every=250,\n",
        "              batch_size=128, noise_size=96, num_epochs=10):\n",
        "    \"\"\"\n",
        "    Train a GAN!\n",
        "\n",
        "    Inputs:\n",
        "    - D, G: PyTorch models for the discriminator and generator\n",
        "    - D_solver, G_solver: torch.optim Optimizers to use for training the\n",
        "      discriminator and generator.\n",
        "    - discriminator_loss, generator_loss: Functions to use for computing the generator and\n",
        "      discriminator loss, respectively.\n",
        "    - show_every: Show samples after every show_every iterations.\n",
        "    - batch_size: Batch size to use for training.\n",
        "    - noise_size: Dimension of the noise to use as input to the generator.\n",
        "    - num_epochs: Number of epochs over the training dataset to use for training.\n",
        "\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    iter_count = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        for x, _ in loader_train:\n",
        "            if len(x) != batch_size:\n",
        "                continue\n",
        "\n",
        "\n",
        "            # ************* START ******************\n",
        "            #TODO 1. Discriminator í•™ìŠµê³¼ì •\n",
        "            # Real imagesì— ëŒ€í•´ logits_realì„ ì •ì˜í•˜ê³  fake_imagesì— ëŒ€í•´ logits_fakeë¥¼ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "            # D_solverëŠ” optimizerì…ë‹ˆë‹¤.\n",
        "            # 1. real_images : real_imagesë¥¼ ìœ„ ë°˜ë³µë¬¸ì—ì„œ ì¶œë ¥ë˜ëŠ” image dataë¡œ ì •ì˜í•´ì£¼ì„¸ìš”. ì´ë•Œ .type(dtype)ë¡œ typeì„ ë§ì¶°ì£¼ì…”ì•¼ í•©ë‹ˆë‹¤.\n",
        "            # 2. logits_real : real_dataì˜ rangeë¥¼ [0,1]ì—ì„œ [-1,1]ë¡œ ë³€ê²½í•œ í›„ pytorch Discriminator modelì¸ D()ì— ì…ë ¥í•´ì£¼ì„¸ìš”.\n",
        "            # ë§ˆì°¬ê°€ì§€ë¡œ .type(dtype)ë¡œ typeì„ ë§ì¶°ì£¼ì…”ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "            # ì‹¤ì œ ì´ë¯¸ì§€ì— ëŒ€í•œ loss ê³„ì‚°\n",
        "            D_solver.zero_grad()\n",
        "            real_images = 1. ###############\n",
        "            logits_real = 2. ###############\n",
        "\n",
        "\n",
        "            # ê°€ì§œ  ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œ í›„ loss ê³„ì‚°\n",
        "            # 3. fake_images : ìƒì„±í•œ noiseë¥¼ pytorch generator modelì¸ G()ì— ì…ë ¥í•´ì£¼ì„¸ìš”.\n",
        "            # ì´ë•Œ Discriminatorì˜ í•™ìŠµê³¼ì •ì´ë¯€ë¡œ GeneratorëŠ” ê³ ì •ë˜ì–´ì•¼ í•˜ë©°, gradient ê³„ì‚°ê³¼ì •ì— ì‚¬ìš©ë˜ì§€ ì•Šë„ë¡ ì„¤ì •í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.(ì¤‘ìš”)\n",
        "            # pytorch methodë¥¼ ì´ìš©í•´ tensorì˜ gradientê°€ ì „íŒŒë˜ì§€ ì•Šë„ë¡ ë§Œë“¤ì–´ì£¼ì„¸ìš”.(stop_gradient)\n",
        "\n",
        "            g_fake_seed = sample_noise(batch_size, noise_size).type(dtype)\n",
        "            fake_images = 3. ###############\n",
        "            logits_fake = D(fake_images.view(batch_size, 1, 28, 28))\n",
        "\n",
        "            d_total_error = discriminator_loss(logits_real, logits_fake)\n",
        "            d_total_error.backward()\n",
        "            D_solver.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            #TODO 2. Generator í•™ìŠµê³¼ì •\n",
        "            #fake_imageì— ëŒ€í•´ì„œë§Œ lossë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "            #Discriminatorì™€ ë¹„ìŠ·í•œ ë°©ì‹ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸ í•˜ëŠ” ê²ƒê¹Œì§€ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”\n",
        "\n",
        "            # 1. G_solverì˜ gradientë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
        "            # 2. g_fake_seed : fake imageë¥¼ ë§Œë“¤ì–´ì£¼ê¸° ìœ„í•œ g_fake_seedë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "            # 3. fake_images : ìƒì„±í•œ g_fake_seedë¥¼ pytorch generator modelì— ì…ë ¥í•´ì£¼ì„¸ìš”.\n",
        "            # Generator í•™ìŠµê³¼ì •ì´ê¸° ë•Œë¬¸ì— ì•ì„œ ì •ì˜í•œ fake_imagesì™€ ë‹¬ë¦¬ stop_gradientë¥¼ ê³ ë ¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "            # 4. gen_logits_fake : fake_imagesë¥¼ MMNIST sizeì¸ 1,28,28ì— ë§ê²Œ ë³€ê²½í•œ ë’¤ discriminator modelì— ì…ë ¥í•´ì£¼ì„¸ìš”.\n",
        "            # 5. g_error : ì•ì—ì„œ ì§ì ‘ ì •ì˜í•œ generatorì˜ lossë¥¼ ê³„ì‚°í•´ì£¼ëŠ” í•¨ìˆ˜ì— ì…ë ¥í•©ë‹ˆë‹¤.\n",
        "            # 6. ì •ì˜í•œ g_errorì˜ gradientë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "            # 7. optimizerì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "            1. ###############\n",
        "            g_fake_seed = 2. ###############\n",
        "            fake_images = 3. ###############\n",
        "\n",
        "            gen_logits_fake = 4. ###############\n",
        "            g_error = 5. ###############\n",
        "            6. ###############\n",
        "            7. ###############\n",
        "\n",
        "\n",
        "            # ************* END ******************\n",
        "\n",
        "\n",
        "            if (iter_count % show_every == 0):\n",
        "                print('Iter: {}, D: {:.4}, G:{:.4}'.format(iter_count,d_total_error.item(),g_error.item()))\n",
        "                imgs_numpy = fake_images.data.cpu().numpy()\n",
        "                images.append(imgs_numpy[0:16])\n",
        "\n",
        "            iter_count += 1\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Hn7wbb6j5-l",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Make the discriminator\n",
        "D = discriminator().type(dtype)\n",
        "\n",
        "# Make the generator\n",
        "G = generator().type(dtype)\n",
        "\n",
        "# Use the function you wrote earlier to get optimizers for the Discriminator and the Generator\n",
        "D_solver = get_optimizer(D)\n",
        "G_solver = get_optimizer(G)\n",
        "\n",
        "# Run it!\n",
        "images = run_a_gan(\n",
        "    D,\n",
        "    G,\n",
        "    D_solver,\n",
        "    G_solver,\n",
        "    discriminator_loss,\n",
        "    generator_loss,\n",
        "    loader_train\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEXkVPImj5-n"
      },
      "source": [
        "Run the cell below to show the generated images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNXceBtDj5-n"
      },
      "outputs": [],
      "source": [
        "numIter = 0\n",
        "for img in images:\n",
        "    print(\"Iter: {}\".format(numIter))\n",
        "    show_images(img)\n",
        "    plt.show()\n",
        "    numIter += 250\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgcxWJA4f5bY"
      },
      "source": [
        "Vanilla GAN output image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUTRjUafj5-o"
      },
      "outputs": [],
      "source": [
        "# This output is your answer.\n",
        "print(\"Vanilla GAN final image:\")\n",
        "show_images(images[-1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqvA-Qbsj5-o"
      },
      "source": [
        "# Least Squares GAN\n",
        "LSGANì€ original GANì˜ unstable loss functionì„ ê°œì„ í•œ GANì…ë‹ˆë‹¤.\n",
        "ëª¨ë¸ êµ¬ì¡°ëŠ” ë°”ë€Œì§€ ì•Šì•˜ì§€ë§Œ loss functionì´ ì´ì „ê³¼ ë‹¤ë¦…ë‹ˆë‹¤. <br>\n",
        "[Least Squares GAN](https://arxiv.org/abs/1611.04076)\n",
        "\n",
        "\n",
        "\n",
        "## Generation loss\n",
        "\n",
        "$$\\ell_G  =  \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[\\left(D(G(z))-1\\right)^2\\right]$$ <br>\n",
        "\n",
        "## Discriminator loss\n",
        "$$ \\ell_D = \\frac{1}{2}\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\left(D(x)-1\\right)^2\\right] + \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[ \\left(D(G(z))\\right)^2\\right]$$ <br>\n",
        "\n",
        "\n",
        "*   ì•ì˜ Vanilla GAN lossì™€ ë§ˆì°¬ê°€ì§€ë¡œ expectationì„ ê³„ì‚°í•˜ëŠ” ë°©ì‹ì´ ì•„ë‹Œ, minibatch ì›ì†Œì— ëŒ€í•´ averagingì„ ì·¨í•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "*    $D(x)$ and $D(G(z))$ ëŠ” discriminator (`scores_real` and `scores_fake`).ì—ì„œ ë‚˜ì˜¨ direct outputì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKq075P0vsaw"
      },
      "source": [
        "# H.W 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4tFcqIqShOTT"
      },
      "outputs": [],
      "source": [
        "def ls_discriminator_loss(scores_real, scores_fake):\n",
        "    \"\"\"\n",
        "    Compute the Least-Squares GAN loss for the discriminator.\n",
        "\n",
        "    Inputs:\n",
        "    - scores_real: PyTorch Tensor of shape (N,) giving scores for the real data.\n",
        "    - scores_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
        "\n",
        "    Outputs:\n",
        "    - loss: A PyTorch Tensor containing the loss.\n",
        "    \"\"\"\n",
        "    loss = None\n",
        "    ##############################################################################\n",
        "    # TODO: LSGANì˜ Discriminator lossë¥¼ êµ¬í˜„í•´ë³´ì„¸ìš” (Markdownì— ì í˜€ìˆëŠ” ìˆ˜ì‹ì„ ì°¸ê³ í•˜ì„¸ìš”)\n",
        "    # Hints : scores_realì€ D(x)ì˜ outputì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
        "    # Hints : scores_fakeëŠ” D(G(z))ì˜ outputì„ ì˜ë¯¸í•©ë‹ˆë‹¤.                                                                                 #\n",
        "    ##############################################################################\n",
        "    # ************* START ******************\n",
        "\n",
        "    loss = ###############\n",
        "\n",
        "    # ************* END ******************\n",
        "    return loss\n",
        "\n",
        "def ls_generator_loss(scores_fake):\n",
        "    \"\"\"\n",
        "    Computes the Least-Squares GAN loss for the generator.\n",
        "\n",
        "    Inputs:\n",
        "    - scores_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
        "\n",
        "    Outputs:\n",
        "    - loss: A PyTorch Tensor containing the loss.\n",
        "    \"\"\"\n",
        "    loss = None\n",
        "    ##############################################################################\n",
        "    # TODO: LSGANì˜ Generator lossë¥¼ êµ¬í˜„í•´ë³´ì„¸ìš” (Markdownì— ì í˜€ìˆëŠ” ìˆ˜ì‹ì„ ì°¸ê³ í•˜ì„¸ìš”)\n",
        "    # Hints : scores_fakeëŠ” D(G(z))ì˜ outputì„ ì˜ë¯¸í•©ë‹ˆë‹¤.                                                                                 #\n",
        "    ##############################################################################\n",
        "    # ************* START ******************\n",
        "\n",
        "    loss = ###############\n",
        "\n",
        "    # ************* END ******************\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xscEf-qhj5-o",
        "outputId": "de874494-d02c-41f2-a5e4-682def225e43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum error in d_loss: 1.53171e-08\n",
            "Maximum error in g_loss: 2.7837e-09\n"
          ]
        }
      ],
      "source": [
        "# ë‘ lossê°€ ì œëŒ€ë¡œ ì •ì˜ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
        "def test_lsgan_loss(score_real, score_fake, d_loss_true, g_loss_true):\n",
        "    score_real = torch.Tensor(score_real).type(dtype)\n",
        "    score_fake = torch.Tensor(score_fake).type(dtype)\n",
        "    d_loss = ls_discriminator_loss(score_real, score_fake).cpu().numpy()\n",
        "    g_loss = ls_generator_loss(score_fake).cpu().numpy()\n",
        "    print(\"Maximum error in d_loss: %g\"%rel_error(d_loss_true, d_loss))\n",
        "    print(\"Maximum error in g_loss: %g\"%rel_error(g_loss_true, g_loss))\n",
        "\n",
        "test_lsgan_loss(\n",
        "    answers['logits_real'],\n",
        "    answers['logits_fake'],\n",
        "    answers['d_loss_lsgan_true'],\n",
        "    answers['g_loss_lsgan_true']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc0hwev0j5-p"
      },
      "source": [
        "Run the following cell to train your model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeAm_enVj5-p",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "D_LS = discriminator().type(dtype)\n",
        "G_LS = generator().type(dtype)\n",
        "\n",
        "D_LS_solver = get_optimizer(D_LS)\n",
        "G_LS_solver = get_optimizer(G_LS)\n",
        "\n",
        "images = run_a_gan(\n",
        "    D_LS,\n",
        "    G_LS,\n",
        "    D_LS_solver,\n",
        "    G_LS_solver,\n",
        "    ls_discriminator_loss,\n",
        "    ls_generator_loss,\n",
        "    loader_train\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7shgysKrj5-q"
      },
      "source": [
        "Run the cell below to show generated images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Drd_56ACj5-q"
      },
      "outputs": [],
      "source": [
        "numIter = 0\n",
        "for img in images:\n",
        "    print(\"Iter: {}\".format(numIter))\n",
        "    show_images(img)\n",
        "    plt.show()\n",
        "    numIter += 250\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1dot-Yjh4yZ"
      },
      "source": [
        "LSGAN output image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-IhBigbj5-r"
      },
      "outputs": [],
      "source": [
        "# This output is your answer.\n",
        "print(\"LSGAN final image:\")\n",
        "show_images(images[-1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3QD-ARaj5-s"
      },
      "source": [
        "# Deeply Convolutional GANs\n",
        "Discriminatorì™€ Generator ë„¤íŠ¸ì›Œí¬ë¥¼ ì •ì˜í•  ë•Œ FC-layerë§Œ ì‚¬ìš©í•œ vanila GANì™€ ë‹¬ë¦¬ Convolutional layerë¥¼ ë„ì…í•œ DCGANì„ ì‹¤ìŠµí•©ë‹ˆë‹¤ :) <br>\n",
        "[DCGAN](https://arxiv.org/abs/1511.06434)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCgj4nOqvy3C"
      },
      "source": [
        "# H.W 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-OegegFrmbt"
      },
      "source": [
        "#### Discriminator\n",
        "\n",
        "ì•„ë˜ì˜ Discriminator architectureë¥¼ ì½”ë“œë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”!\n",
        "\n",
        "\n",
        "* Reshape into MNIST image tensor (Use Unflatten(N=, C=, H=, W=)!)\n",
        "* Conv2D: out_channels=32 , 5x5, Stride 1, Padding 0\n",
        "* Leaky ReLU(alpha=0.01)\n",
        "* Max Pool 2x2, Stride 2\n",
        "* Conv2D: out_channels=64, 5x5, Stride 1, Padding 0\n",
        "* Leaky ReLU(alpha=0.01)\n",
        "* Max Pool 2x2, Stride 2\n",
        "* Flatten()\n",
        "* Fully Connected with output size 4 x 4 x 64\n",
        "* Leaky ReLU(alpha=0.01)\n",
        "* Fully Connected with output size 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8RagG2GvfJIx"
      },
      "outputs": [],
      "source": [
        "def build_dc_classifier(batch_size):\n",
        "    \"\"\"\n",
        "    Build and return a PyTorch model for the DCGAN discriminator implementing\n",
        "    the architecture above.\n",
        "    \"\"\"\n",
        "\n",
        "    ##############################################################################\n",
        "    # TODO: Discriminatorë¥¼ buildí•˜ì„¸ìš”                                                                                           #\n",
        "    # HINT: nn.Sequentialë¥¼ ì‚¬ìš©í•˜ë©´ í¸í•©ë‹ˆë‹¤\n",
        "    ##############################################################################\n",
        "    # ************* START ******************\n",
        "\n",
        "    model = ###############\n",
        "\n",
        "    return model\n",
        "    # ************* END ******************\n",
        "    ##############################################################################\n",
        "    #                               END OF YOUR CODE                             #\n",
        "    ##############################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlNNI7DIj5-s",
        "outputId": "c3d08d9d-7df6-47c2-b353-9de69c97361e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1])\n"
          ]
        }
      ],
      "source": [
        "data = next(enumerate(loader_train))[-1][0].type(dtype)\n",
        "b = build_dc_classifier(batch_size).type(dtype)\n",
        "out = b(data)\n",
        "print(out.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FMsX1osj5-t"
      },
      "source": [
        "Check the number of parameters in your classifier as a sanity check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I5vPgjHj5-t",
        "outputId": "3aa2fcd3-7294-4422-ce17-25c448bf07d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct number of parameters in generator.\n"
          ]
        }
      ],
      "source": [
        "def test_dc_classifer(true_count=1102721):\n",
        "    model = build_dc_classifier(batch_size)\n",
        "    cur_count = count_params(model)\n",
        "    if cur_count != true_count:\n",
        "        print('Incorrect number of parameters in generator. Check your achitecture.')\n",
        "    else:\n",
        "        print('Correct number of parameters in generator.')\n",
        "\n",
        "test_dc_classifer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QO8U_Sgj5-t"
      },
      "source": [
        "#### Generator\n",
        "DCGANì—ì„œ ì‚¬ìš©í•  generatorì˜ êµ¬ì¡°ëŠ”  InfoGAN paperì˜ êµ¬ì¡°ì™€ ë™ì¼í•©ë‹ˆë‹¤ <br>\n",
        "[InfoGAN paper](https://arxiv.org/pdf/1606.03657.pdf). <br>\n",
        "ìˆ˜ì—… ì‹œê°„ì— ë§í•œ upsampling ê¸°ë²•ë„ transpose convolutionìœ¼ë¡œ ìˆ˜í–‰í•˜ë‹ˆ ì•„ë˜ì˜ architectureë¥¼ ì½”ë“œë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”!\n",
        "\n",
        "* Fully connected with input size noise_dim and output size 1024\n",
        "* `ReLU`\n",
        "* BatchNorm\n",
        "* Fully connected with output size 7 x 7 x 128\n",
        "* ReLU\n",
        "* BatchNorm\n",
        "* Reshape into Image Tensor of shape 7, 7, 128 (Use Unflatten(N=, C=, H=, W=)!)\n",
        "* Conv2D^T (Transpose): out_channels=64 ,4x4, stride 2, 'same' padding (use `padding=1`)\n",
        "* `ReLU`\n",
        "* BatchNorm\n",
        "* Conv2D^T (Transpose): out_channels=1, 4x4, stride 2, 'same' padding (use `padding=1`)\n",
        "* `TanH`\n",
        "* Should have a 28x28x1 image, reshape back into 784 vector (use Flatten())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR3YoaSrv2iE"
      },
      "source": [
        "#H.W 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "rqDeTbeVdzkP"
      },
      "outputs": [],
      "source": [
        "def build_dc_generator(noise_dim=NOISE_DIM):\n",
        "    \"\"\"\n",
        "    Build and return a PyTorch model implementing the DCGAN generator using\n",
        "    the architecture described above.\n",
        "    \"\"\"\n",
        "\n",
        "    ##############################################################################\n",
        "    # TODO: Generatorë¥¼ buildí•˜ì„¸ìš”                                                                                           #\n",
        "    # HINT: nn.Sequentialë¥¼ ì‚¬ìš©í•˜ë©´ í¸í•©ë‹ˆë‹¤\n",
        "    # HINT: BatchNorm ì •ì˜ ì‹œ 1dì™€ 2dë¥¼ êµ¬ë¶„í•˜ì…”ì•¼ í•©ë‹ˆë‹¤.\n",
        "    ##############################################################################\n",
        "    # ************* START ******************\n",
        "\n",
        "    model = ###############\n",
        "\n",
        "    return model\n",
        "    # ************* END ******************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQZpnSWmj5-u",
        "outputId": "5518ecac-d678-4ebe-f0ce-f5a30446338e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 784])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_g_gan = build_dc_generator().type(dtype)\n",
        "test_g_gan.apply(initialize_weights)\n",
        "\n",
        "fake_seed = torch.randn(batch_size, NOISE_DIM).type(dtype)\n",
        "fake_images = test_g_gan.forward(fake_seed)\n",
        "fake_images.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNWWS4u5j5-u"
      },
      "source": [
        "Check the number of parameters in your generator as a sanity check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3iGEbYmj5-u",
        "outputId": "873b4f69-5987-4310-d68f-3e9da15db258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct number of parameters in generator.\n"
          ]
        }
      ],
      "source": [
        "def test_dc_generator(true_count=6580801):\n",
        "    model = build_dc_generator(4)\n",
        "    cur_count = count_params(model)\n",
        "    if cur_count != true_count:\n",
        "        print('Incorrect number of parameters in generator. Check your achitecture.')\n",
        "    else:\n",
        "        print('Correct number of parameters in generator.')\n",
        "\n",
        "test_dc_generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnGJkgqGj5-v",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "D_DC = build_dc_classifier(batch_size).type(dtype)\n",
        "D_DC.apply(initialize_weights)\n",
        "G_DC = build_dc_generator().type(dtype)\n",
        "G_DC.apply(initialize_weights)\n",
        "\n",
        "D_DC_solver = get_optimizer(D_DC)\n",
        "G_DC_solver = get_optimizer(G_DC)\n",
        "\n",
        "images = run_a_gan(\n",
        "    D_DC,\n",
        "    G_DC,\n",
        "    D_DC_solver,\n",
        "    G_DC_solver,\n",
        "    discriminator_loss,\n",
        "    generator_loss,\n",
        "    loader_train,\n",
        "    num_epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31k6XXJKj5-v"
      },
      "source": [
        "Run the cell below to show generated images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOHZrYN3j5-w"
      },
      "outputs": [],
      "source": [
        "numIter = 0\n",
        "for img in images:\n",
        "    print(\"Iter: {}\".format(numIter))\n",
        "    show_images(img)\n",
        "    plt.show()\n",
        "    numIter += 250\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAUxkDF1j5-w"
      },
      "source": [
        "DCGAN output image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb00MK6oj5-x"
      },
      "outputs": [],
      "source": [
        "# This output is your answer.\n",
        "print(\"DCGAN final image:\")\n",
        "show_images(images[-1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWVr3kBh31nX"
      },
      "source": [
        "4ì£¼ ë™ì•ˆ ëª¨ë‘ ê³ ìƒ ë§ìœ¼ì…¨ìŠµë‹ˆë‹¤ :) ë§ì´ ë¶€ì¡±í•œ ì„¸ì…˜ê³¼ ê³¼ì œì„ì—ë„ ë¶ˆêµ¬í•˜ê³  ì˜ ë”°ë¼ì™€ì£¼ì…”ì„œ ì •ë§ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.\n",
        "\n",
        "ì¶”ìš´ ë‚ ì”¨ì— ê±´ê°• ì¡°ì‹¬í•˜ì‹œê³  ë‚¨ì€ í”„ë¡œì íŠ¸ì™€ ìŠ¤í„°ë””ë„ ëê¹Œì§€ í™”ì´íŒ… í•˜ì‹œê¸°ë¥¼ ì‘ì›í•˜ê² ìŠµë‹ˆë‹¤ ã…ã… ê³¼ì œ ë˜ëŠ” ì´ì™¸ì— ê¶ê¸ˆí•œ ì‚¬í•­ì´ ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ 17ê¸° ì„ì²­ìˆ˜ì—ê²Œ DM ë³´ë‚´ì£¼ì„¸ìš”! ğŸ™‡ğŸ»â€â™‚ï¸"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
