{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A62Nr9-wrjQ6"
      },
      "source": [
        "#4주차 과제 설명\n",
        "<p>이번 과제의 목표는 세션 시간에 배운 Generation model 중 GAN을 실습해보면서\n",
        " 1) discriminator와 generator를 어떻게 교대로 학습시켜야 하는지 2) 실제로 어떤 이미지가 생성되는지 3) GAN을 발전시킨 LSGAN과 DCGAN은 어떻게 구현되는지에 대해 여러분들이 직접 느끼는 것입니다.</p>\n",
        "\n",
        "<p>GAN을 직접 scratch부터 구현하는 것은 어려운 일이기에, 글로만 들었던 개념을 좀 더 상세히 코드로 이해하는데 중점을 두었습니다. 😂</p>\n",
        "\n",
        "<p> 과제는 훌륭한 교보재인 CS231 공식 assignment3을 다수 참고하였습니다 🙇🏻‍♂️</p>\n",
        "\n",
        "해당 과제는 런타임 연결시 'GPU' 사용을 강력히 권장드립니다!!(CPU 쓰면 학습시킬 때 많이 느립니다..!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqkyZSg-j5-S",
        "tags": [
          "pdf-title"
        ]
      },
      "source": [
        "# Generative Adversarial Networks (GANs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W7PETxWej5-V",
        "tags": [
          "pdf-ignore"
        ]
      },
      "outputs": [],
      "source": [
        "# Setup cell. run!\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision.datasets as dset\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # Set default size of plots.\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "def show_images(images):\n",
        "    images = np.reshape(images, [images.shape[0], -1]) # Images reshape to (batch_size, D).\n",
        "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
        "    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
        "\n",
        "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
        "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhdMz4jNVEjE"
      },
      "source": [
        "gan-checks.npz는 코드과제.ipynb와 함께 올려드린 파일로 colab 기준 좌측 파일 버튼 누르셔서 현재 위치에 업로드하신 후에 아래 코드를 실행하시면 됩니다!\n",
        "\n",
        "과제에 틀린 답안을 작성한 후 계속 코드를 실행하면서 시간 낭비하지 않도록 답안이 맞을 때까지 체크해주는 파일입니다 ㅎㅎ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zXOlKVjwU9pX"
      },
      "outputs": [],
      "source": [
        "# 현재위치에 파일 업로드 후 실행. 문제 발생 시 DM 주세요!\n",
        "answers = dict(np.load('gan-checks.npz'))\n",
        "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ5c0xnYpuOm"
      },
      "source": [
        "# Help Functions 1\n",
        "기본적인 전처리 함수들입니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Lx2b91tXpVQO"
      },
      "outputs": [],
      "source": [
        "class ChunkSampler(sampler.Sampler):\n",
        "    \"\"\"Samples elements sequentially from some offset.\n",
        "    Arguments:\n",
        "        num_samples: # of desired datapoints\n",
        "        start: offset where we should start selecting from\n",
        "    \"\"\"\n",
        "    def __init__(self, num_samples, start=0):\n",
        "        self.num_samples = num_samples\n",
        "        self.start = start\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.start + self.num_samples))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "def preprocess_img(x):\n",
        "    return 2 * x - 1.0\n",
        "\n",
        "def deprocess_img(x):\n",
        "    return (x + 1.0) / 2.0\n",
        "\n",
        "def rel_error(x,y):\n",
        "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
        "\n",
        "def count_params(model):\n",
        "    \"\"\"Count the number of parameters in the current TensorFlow graph \"\"\"\n",
        "    param_count = np.sum([np.prod(p.size()) for p in model.parameters()])\n",
        "    return param_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcHnNzLnj5-X",
        "tags": [
          "pdf-ignore"
        ]
      },
      "source": [
        "## Dataset\n",
        "학습 데이터는 MNIST 데이터를 사용합니다 :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X9i7TUkj5-Z",
        "scrolled": false,
        "tags": [
          "pdf-ignore"
        ]
      },
      "outputs": [],
      "source": [
        "NUM_TRAIN = 50000\n",
        "NUM_VAL = 5000\n",
        "\n",
        "NOISE_DIM = 96\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "# 바로 실행하셔도 되고, MNIST data를 받을 경로설정을 환경에 맞게 설정해주셔도 됩니다.\n",
        "mnist_train = dset.MNIST(\n",
        "    './cs231n/datasets/MNIST_data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=T.ToTensor()\n",
        ")\n",
        "loader_train = DataLoader(\n",
        "    mnist_train,\n",
        "    batch_size=batch_size,\n",
        "    sampler=ChunkSampler(NUM_TRAIN, 0)\n",
        ")\n",
        "\n",
        "mnist_val = dset.MNIST(\n",
        "    './cs231n/datasets/MNIST_data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=T.ToTensor()\n",
        ")\n",
        "loader_val = DataLoader(\n",
        "    mnist_val,\n",
        "    batch_size=batch_size,\n",
        "    sampler=ChunkSampler(NUM_VAL, NUM_TRAIN)\n",
        ")\n",
        "\n",
        "imgs = next(loader_train.__iter__())[0].view(batch_size, 784).numpy().squeeze()\n",
        "show_images(imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M3Zw0hYj5-b"
      },
      "source": [
        "## Random Noise : Input of Generation Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PphjJP5VvMG9"
      },
      "source": [
        "# H.W 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YGtwpNnWibN"
      },
      "source": [
        "첫번째 과제는 가짜 이미지를 생성하는 Generator에 입력할 '노이즈'를 샘플링하는 함수를 작성하는 문제입니다. Hint에 주어진 함수를 사용하고 shape와 range를 고려하여 노이즈 샘플링 함수를 완성해주세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZYzLMJcSvs3J"
      },
      "outputs": [],
      "source": [
        "def sample_noise(batch_size, dim, seed=None):\n",
        "    \"\"\"\n",
        "    Generate a PyTorch Tensor of uniform random noise.\n",
        "\n",
        "    Input:\n",
        "    - batch_size: Integer giving the batch size of noise to generate.\n",
        "    - dim: Integer giving the dimension of noise to generate.\n",
        "\n",
        "    Output:\n",
        "    - A PyTorch Tensor of shape (batch_size, dim) containing uniform\n",
        "      random noise in the range (-1, 1).\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "    # ************* START ******************\n",
        "    # TODO : random noise를 만드는 식을 짜주세요\n",
        "    # Hint 1: -1부터 1사이의 uniform noise를 만들어주세요. shape은 [batch_size, dim] 입니다.\n",
        "    # Hint 2: torch.rand를 사용하세요\n",
        "\n",
        "    return ###############\n",
        "\n",
        "    # ************* END ******************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sample_noise_test",
        "outputId": "52726993-cdb4-42b4-ab9f-ebef4a97ac17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All tests passed!\n"
          ]
        }
      ],
      "source": [
        "# sample_noise 함수를 잘 만들었는지 테스트하는 함수입니다. 에러 발생 시 Hint를 다시 확인해주세요!\n",
        "\n",
        "def test_sample_noise():\n",
        "    batch_size = 3\n",
        "    dim = 4\n",
        "    torch.manual_seed(231)\n",
        "    z = sample_noise(batch_size, dim)\n",
        "    np_z = z.cpu().numpy()\n",
        "    assert np_z.shape == (batch_size, dim)\n",
        "    assert torch.is_tensor(z)\n",
        "    assert np.all(np_z >= -1.0) and np.all(np_z <= 1.0)\n",
        "    assert np.any(np_z < 0.0) and np.any(np_z > 0.0)\n",
        "    print('All tests passed!')\n",
        "\n",
        "test_sample_noise()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0JSkADnj5-e",
        "tags": [
          "pdf-ignore"
        ]
      },
      "source": [
        "## Flatten & Unflatten & Weight initalization\n",
        "\n",
        "1차원의 벡터를 만들어주는 flatten 함수와 그 반대인 unflatten, 그리고  weight initializer로 자주 쓰이는 Xavier initalization입니다. 과제 시 사용되는 함수이니 기억해주세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jq-QrHKRqcBR"
      },
      "outputs": [],
      "source": [
        "# run!\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size() # read in N, C, H, W\n",
        "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
        "\n",
        "class Unflatten(nn.Module):\n",
        "    \"\"\"\n",
        "    An Unflatten module receives an input of shape (N, C*H*W) and reshapes it\n",
        "    to produce an output of shape (N, C, H, W).\n",
        "    \"\"\"\n",
        "    def __init__(self, N=-1, C=128, H=7, W=7):\n",
        "        super(Unflatten, self).__init__()\n",
        "        self.N = N\n",
        "        self.C = C\n",
        "        self.H = H\n",
        "        self.W = W\n",
        "    def forward(self, x):\n",
        "        return x.view(self.N, self.C, self.H, self.W)\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.ConvTranspose2d):\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj2OateGj5-f"
      },
      "source": [
        "# H.W 2 : Discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU7Gj8i-xhN4"
      },
      "source": [
        "Discriminator는 아래와 같은 구조입니다.\n",
        "\n",
        "\n",
        " * nn.Flatten()\n",
        " * Fully connected layer with input size 784 and output size 256\n",
        " * LeakyReLU with alpha 0.01\n",
        " * Fully connected layer with input_size 256 and output size 256\n",
        " * LeakyReLU with alpha 0.01\n",
        " * Fully connected layer with input size 256 and output size 1\n",
        "\n",
        "\n",
        "*   마지막 output shape은 [batch_size, 1] 형태를 갖습니다\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE5b6q7KZEFv"
      },
      "source": [
        "빈칸에 들어가야 할 코드를 완성해주세요! 코드를 작성하면서 vanila GAN의 네트워크가 어떻게 구성되어 있는지 이해하시면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cuiOZemvqjDV"
      },
      "outputs": [],
      "source": [
        "def discriminator(seed=None):\n",
        "    \"\"\"\n",
        "    Build and return a PyTorch model implementing the architecture above.\n",
        "    \"\"\"\n",
        "\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "    model = None\n",
        "\n",
        "    # ************* START ******************\n",
        "\n",
        "    model = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        ###############\n",
        "        ###############\n",
        "        ###############\n",
        "        ###############\n",
        "        ###############\n",
        "    )\n",
        "\n",
        "    # *************** END *******************\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwtfx2vNj5-g",
        "outputId": "d60b9b04-f4f4-448d-87eb-925df5649197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct number of parameters in discriminator.\n"
          ]
        }
      ],
      "source": [
        "# 완성한 Discriminator의 파라미터 수가 일치하는지 확인\n",
        "def test_discriminator(true_count=267009):\n",
        "    model = discriminator()\n",
        "    cur_count = count_params(model)\n",
        "    if cur_count != true_count:\n",
        "        print('Incorrect number of parameters in discriminator. Check your achitecture.')\n",
        "    else:\n",
        "        print('Correct number of parameters in discriminator.')\n",
        "\n",
        "test_discriminator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vciao8Lj5-h"
      },
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaQikOQgyprj"
      },
      "source": [
        "Generator는 아래와 같은 구조입니다\n",
        "\n",
        "\n",
        "\n",
        " * Fully connected layer from noise_dim to 1024\n",
        " * `ReLU`\n",
        " * Fully connected layer with output size 1024\n",
        " * `ReLU`\n",
        " * Fully connected layer with output size 784\n",
        " * `TanH` (to clip the image to be in the range of [-1,1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdVeKLdEZVjN"
      },
      "source": [
        "Discriminator와 마찬가지로 빈칸을 적절하게 채워주시면 됩니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "g5myrLJiqpVh"
      },
      "outputs": [],
      "source": [
        "def generator(noise_dim=NOISE_DIM, seed=None):\n",
        "    \"\"\"\n",
        "    Build and return a PyTorch model implementing the architecture above.\n",
        "    \"\"\"\n",
        "\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "    model = None\n",
        "\n",
        "    model = nn.Sequential(\n",
        "        ###############,\n",
        "        ###############,\n",
        "        ###############,\n",
        "        ###############,\n",
        "        ###############,\n",
        "        ###############\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTQSgkeMj5-h",
        "outputId": "c1a29e87-27b4-41a6-d6ab-e9190d7d0e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct number of parameters in generator.\n"
          ]
        }
      ],
      "source": [
        "# 완성한 generator의 파라미터 수가 일치하는지 확인\n",
        "def test_generator(true_count=1858320):\n",
        "    model = generator(4)\n",
        "    cur_count = count_params(model)\n",
        "    if cur_count != true_count:\n",
        "        print('Incorrect number of parameters in generator. Check your achitecture.')\n",
        "    else:\n",
        "        print('Correct number of parameters in generator.')\n",
        "\n",
        "test_generator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJcQ3rcUj5-i"
      },
      "source": [
        "# H.W 3 : GAN Loss\n",
        "\n",
        "\n",
        "##   Generator Loss\n",
        "$$\\ell_G  =  -\\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$ <br>\n",
        "\n",
        "## Discriminator Loss\n",
        "$$ \\ell_D = -\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] - \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$ <Br>\n",
        "\n",
        "이 Loss들을 minimizing하기 위해 원래 Loss식에 -를 붙였습니다.\n",
        "\n",
        "$$ bce(s, y) = -y * \\log(s) - (1 - y) * \\log(1 - s) $$ <Br>\n",
        "\n",
        "*   해당 식을 나이브하게 적용하면 unstable하기 때문에 아래의 bce 함수에 stable한 implementation을 제공하였습니다.\n",
        "\n",
        "* $\\log D(G(z))$, $\\log D(x)$ and $\\log \\left(1-D(G(z))\\right)$ 의 expectation을 계산하는 방식이 아닌, minibatch 원소에 대해 averaging을 취하는 방식을 사용합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wHrDqxPj5-j"
      },
      "source": [
        "Test your generator and discriminator loss. You should see errors < 1e-7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HfVOCgiq0nwy"
      },
      "outputs": [],
      "source": [
        "def bce_loss(input, target):\n",
        "    \"\"\"\n",
        "    Numerically stable version of the binary cross-entropy loss function.\n",
        "\n",
        "    As per https://github.com/pytorch/pytorch/issues/751\n",
        "    See the TensorFlow docs for a derivation of this formula:\n",
        "    https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits\n",
        "\n",
        "    Inputs:\n",
        "    - input: PyTorch Tensor of shape (N, ) giving scores.\n",
        "    - target: PyTorch Tensor of shape (N,) containing 0 and 1 giving targets.\n",
        "\n",
        "    Returns:\n",
        "    - A PyTorch Tensor containing the mean BCE loss over the minibatch of input data.\n",
        "    \"\"\"\n",
        "    neg_abs = - input.abs()\n",
        "    loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n",
        "    return loss.mean()\n",
        "\n",
        "def discriminator_loss(logits_real, logits_fake):\n",
        "    \"\"\"\n",
        "    Computes the discriminator loss described above.\n",
        "\n",
        "    Inputs:\n",
        "    - logits_real: PyTorch Tensor of shape (N,) giving scores for the real data.\n",
        "    - logits_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
        "\n",
        "    Returns:\n",
        "    - loss: PyTorch Tensor containing (scalar) the loss for the discriminator.\n",
        "    \"\"\"\n",
        "    loss = None\n",
        "    # ************* START ******************\n",
        "    # TODO: Fake image에 대한 loss와 Real image에 대한 loss를 각각 계산하고 평균화하세요\n",
        "    # Hint: 위에서 정의한 bce_loss()를 사용하여 binary cross-entropy방식으로 각 element들에 대한 loss를 계산합니다\n",
        "    # Hint: 이때 bce_loss()의 input은 logits_xxxx이며 target은 torch.zeros_like와 torch.ones_like를 사용해서 정의해주세요!\n",
        "\n",
        "    loss_fake = ###############\n",
        "    loss_real = ###############\n",
        "    loss = ###############\n",
        "\n",
        "    # ************* END ******************\n",
        "    return loss\n",
        "\n",
        "def generator_loss(logits_fake):\n",
        "    \"\"\"\n",
        "    Computes the generator loss described above.\n",
        "\n",
        "    Inputs:\n",
        "    - logits_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
        "\n",
        "    Returns:\n",
        "    - loss: PyTorch Tensor containing the (scalar) loss for the generator.\n",
        "    \"\"\"\n",
        "    loss = None\n",
        "    # ************* START ******************\n",
        "    # TODO: Fake image에 대한 loss를 계산하세요\n",
        "    # Hint: torch.zeros_like와 torch.ones_like 중 하나를 선택해서 정의해주세요!\n",
        "\n",
        "    loss = ###############\n",
        "\n",
        "    # ************* END ******************\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C93Ft93Oj5-k",
        "outputId": "db591015-6d3b-4995-e3ba-961222a27af9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum error in d_loss: 3.97058e-09\n"
          ]
        }
      ],
      "source": [
        "def test_discriminator_loss(logits_real, logits_fake, d_loss_true):\n",
        "    d_loss = discriminator_loss(torch.Tensor(logits_real).type(dtype),\n",
        "                                torch.Tensor(logits_fake).type(dtype)).cpu().numpy()\n",
        "    print(\"Maximum error in d_loss: %g\"%rel_error(d_loss_true, d_loss))\n",
        "\n",
        "test_discriminator_loss(\n",
        "    answers['logits_real'],\n",
        "    answers['logits_fake'],\n",
        "    answers['d_loss_true']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpU2nibMj5-k",
        "outputId": "ae897729-c94c-43ed-a904-9ec1427e714e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum error in g_loss: 4.4518e-09\n"
          ]
        }
      ],
      "source": [
        "def test_generator_loss(logits_fake, g_loss_true):\n",
        "    g_loss = generator_loss(torch.Tensor(logits_fake).type(dtype)).cpu().numpy()\n",
        "    print(\"Maximum error in g_loss: %g\"%rel_error(g_loss_true, g_loss))\n",
        "\n",
        "test_generator_loss(\n",
        "    answers['logits_fake'],\n",
        "    answers['g_loss_true']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRfbBYW4j5-l"
      },
      "source": [
        "# Optimizing our Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhuGED3Zj5-l"
      },
      "source": [
        "# Training a GAN!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VorrIjIQvn3f"
      },
      "source": [
        "# H.W 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4XCZUou0ZMsP"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(model):\n",
        "    \"\"\"\n",
        "    Construct and return an Adam optimizer for the model with learning rate 1e-3,\n",
        "    beta1=0.5, and beta2=0.999.\n",
        "\n",
        "    Input:\n",
        "    - model: A PyTorch model that we want to optimize.\n",
        "\n",
        "    Returns:\n",
        "    - An Adam optimizer for the model with the desired hyperparameters.\n",
        "    \"\"\"\n",
        "    optimizer = None\n",
        "    # ************* START ******************\n",
        "    #TODO : Adam optimizer를 정의해주세요. learning rate 조절 및 scheduler도 적용해보세요.\n",
        "\n",
        "    optimizer = ###############\n",
        "\n",
        "    # ************* END ******************\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def run_a_gan(D, G, D_solver, G_solver, discriminator_loss, generator_loss, loader_train, show_every=250,\n",
        "              batch_size=128, noise_size=96, num_epochs=10):\n",
        "    \"\"\"\n",
        "    Train a GAN!\n",
        "\n",
        "    Inputs:\n",
        "    - D, G: PyTorch models for the discriminator and generator\n",
        "    - D_solver, G_solver: torch.optim Optimizers to use for training the\n",
        "      discriminator and generator.\n",
        "    - discriminator_loss, generator_loss: Functions to use for computing the generator and\n",
        "      discriminator loss, respectively.\n",
        "    - show_every: Show samples after every show_every iterations.\n",
        "    - batch_size: Batch size to use for training.\n",
        "    - noise_size: Dimension of the noise to use as input to the generator.\n",
        "    - num_epochs: Number of epochs over the training dataset to use for training.\n",
        "\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    iter_count = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        for x, _ in loader_train:\n",
        "            if len(x) != batch_size:\n",
        "                continue\n",
        "\n",
        "\n",
        "            # ************* START ******************\n",
        "            #TODO 1. Discriminator 학습과정\n",
        "            # Real images에 대해 logits_real을 정의하고 fake_images에 대해 logits_fake를 정의해야 합니다.\n",
        "            # D_solver는 optimizer입니다.\n",
        "            # 1. real_images : real_images를 위 반복문에서 출력되는 image data로 정의해주세요. 이때 .type(dtype)로 type을 맞춰주셔야 합니다.\n",
        "            # 2. logits_real : real_data의 range를 [0,1]에서 [-1,1]로 변경한 후 pytorch Discriminator model인 D()에 입력해주세요.\n",
        "            # 마찬가지로 .type(dtype)로 type을 맞춰주셔야 합니다.\n",
        "\n",
        "\n",
        "            # 실제 이미지에 대한 loss 계산\n",
        "            D_solver.zero_grad()\n",
        "            real_images = 1. ###############\n",
        "            logits_real = 2. ###############\n",
        "\n",
        "\n",
        "            # 가짜  이미지를 생성한 후 loss 계산\n",
        "            # 3. fake_images : 생성한 noise를 pytorch generator model인 G()에 입력해주세요.\n",
        "            # 이때 Discriminator의 학습과정이므로 Generator는 고정되어야 하며, gradient 계산과정에 사용되지 않도록 설정해주어야 합니다.(중요)\n",
        "            # pytorch method를 이용해 tensor의 gradient가 전파되지 않도록 만들어주세요.(stop_gradient)\n",
        "\n",
        "            g_fake_seed = sample_noise(batch_size, noise_size).type(dtype)\n",
        "            fake_images = 3. ###############\n",
        "            logits_fake = D(fake_images.view(batch_size, 1, 28, 28))\n",
        "\n",
        "            d_total_error = discriminator_loss(logits_real, logits_fake)\n",
        "            d_total_error.backward()\n",
        "            D_solver.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            #TODO 2. Generator 학습과정\n",
        "            #fake_image에 대해서만 loss를 계산합니다.\n",
        "            #Discriminator와 비슷한 방식으로 가중치를 업데이트 하는 것까지 코드를 작성해주세요\n",
        "\n",
        "            # 1. G_solver의 gradient를 초기화합니다.\n",
        "            # 2. g_fake_seed : fake image를 만들어주기 위한 g_fake_seed를 정의합니다.\n",
        "            # 3. fake_images : 생성한 g_fake_seed를 pytorch generator model에 입력해주세요.\n",
        "            # Generator 학습과정이기 때문에 앞서 정의한 fake_images와 달리 stop_gradient를 고려하지 않습니다.\n",
        "            # 4. gen_logits_fake : fake_images를 MMNIST size인 1,28,28에 맞게 변경한 뒤 discriminator model에 입력해주세요.\n",
        "            # 5. g_error : 앞에서 직접 정의한 generator의 loss를 계산해주는 함수에 입력합니다.\n",
        "            # 6. 정의한 g_error의 gradient를 계산합니다.\n",
        "            # 7. optimizer의 파라미터를 업데이트합니다.\n",
        "\n",
        "            1. ###############\n",
        "            g_fake_seed = 2. ###############\n",
        "            fake_images = 3. ###############\n",
        "\n",
        "            gen_logits_fake = 4. ###############\n",
        "            g_error = 5. ###############\n",
        "            6. ###############\n",
        "            7. ###############\n",
        "\n",
        "\n",
        "            # ************* END ******************\n",
        "\n",
        "\n",
        "            if (iter_count % show_every == 0):\n",
        "                print('Iter: {}, D: {:.4}, G:{:.4}'.format(iter_count,d_total_error.item(),g_error.item()))\n",
        "                imgs_numpy = fake_images.data.cpu().numpy()\n",
        "                images.append(imgs_numpy[0:16])\n",
        "\n",
        "            iter_count += 1\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Hn7wbb6j5-l",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Make the discriminator\n",
        "D = discriminator().type(dtype)\n",
        "\n",
        "# Make the generator\n",
        "G = generator().type(dtype)\n",
        "\n",
        "# Use the function you wrote earlier to get optimizers for the Discriminator and the Generator\n",
        "D_solver = get_optimizer(D)\n",
        "G_solver = get_optimizer(G)\n",
        "\n",
        "# Run it!\n",
        "images = run_a_gan(\n",
        "    D,\n",
        "    G,\n",
        "    D_solver,\n",
        "    G_solver,\n",
        "    discriminator_loss,\n",
        "    generator_loss,\n",
        "    loader_train\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEXkVPImj5-n"
      },
      "source": [
        "Run the cell below to show the generated images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNXceBtDj5-n"
      },
      "outputs": [],
      "source": [
        "numIter = 0\n",
        "for img in images:\n",
        "    print(\"Iter: {}\".format(numIter))\n",
        "    show_images(img)\n",
        "    plt.show()\n",
        "    numIter += 250\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgcxWJA4f5bY"
      },
      "source": [
        "Vanilla GAN output image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUTRjUafj5-o"
      },
      "outputs": [],
      "source": [
        "# This output is your answer.\n",
        "print(\"Vanilla GAN final image:\")\n",
        "show_images(images[-1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqvA-Qbsj5-o"
      },
      "source": [
        "# Least Squares GAN\n",
        "LSGAN은 original GAN의 unstable loss function을 개선한 GAN입니다.\n",
        "모델 구조는 바뀌지 않았지만 loss function이 이전과 다릅니다. <br>\n",
        "[Least Squares GAN](https://arxiv.org/abs/1611.04076)\n",
        "\n",
        "\n",
        "\n",
        "## Generation loss\n",
        "\n",
        "$$\\ell_G  =  \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[\\left(D(G(z))-1\\right)^2\\right]$$ <br>\n",
        "\n",
        "## Discriminator loss\n",
        "$$ \\ell_D = \\frac{1}{2}\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\left(D(x)-1\\right)^2\\right] + \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[ \\left(D(G(z))\\right)^2\\right]$$ <br>\n",
        "\n",
        "\n",
        "*   앞의 Vanilla GAN loss와 마찬가지로 expectation을 계산하는 방식이 아닌, minibatch 원소에 대해 averaging을 취하는 방식을 사용합니다.\n",
        "\n",
        "*    $D(x)$ and $D(G(z))$ 는 discriminator (`scores_real` and `scores_fake`).에서 나온 direct output을 사용합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKq075P0vsaw"
      },
      "source": [
        "# H.W 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4tFcqIqShOTT"
      },
      "outputs": [],
      "source": [
        "def ls_discriminator_loss(scores_real, scores_fake):\n",
        "    \"\"\"\n",
        "    Compute the Least-Squares GAN loss for the discriminator.\n",
        "\n",
        "    Inputs:\n",
        "    - scores_real: PyTorch Tensor of shape (N,) giving scores for the real data.\n",
        "    - scores_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
        "\n",
        "    Outputs:\n",
        "    - loss: A PyTorch Tensor containing the loss.\n",
        "    \"\"\"\n",
        "    loss = None\n",
        "    ##############################################################################\n",
        "    # TODO: LSGAN의 Discriminator loss를 구현해보세요 (Markdown에 적혀있는 수식을 참고하세요)\n",
        "    # Hints : scores_real은 D(x)의 output을 의미합니다.\n",
        "    # Hints : scores_fake는 D(G(z))의 output을 의미합니다.                                                                                 #\n",
        "    ##############################################################################\n",
        "    # ************* START ******************\n",
        "\n",
        "    loss = ###############\n",
        "\n",
        "    # ************* END ******************\n",
        "    return loss\n",
        "\n",
        "def ls_generator_loss(scores_fake):\n",
        "    \"\"\"\n",
        "    Computes the Least-Squares GAN loss for the generator.\n",
        "\n",
        "    Inputs:\n",
        "    - scores_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
        "\n",
        "    Outputs:\n",
        "    - loss: A PyTorch Tensor containing the loss.\n",
        "    \"\"\"\n",
        "    loss = None\n",
        "    ##############################################################################\n",
        "    # TODO: LSGAN의 Generator loss를 구현해보세요 (Markdown에 적혀있는 수식을 참고하세요)\n",
        "    # Hints : scores_fake는 D(G(z))의 output을 의미합니다.                                                                                 #\n",
        "    ##############################################################################\n",
        "    # ************* START ******************\n",
        "\n",
        "    loss = ###############\n",
        "\n",
        "    # ************* END ******************\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xscEf-qhj5-o",
        "outputId": "de874494-d02c-41f2-a5e4-682def225e43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum error in d_loss: 1.53171e-08\n",
            "Maximum error in g_loss: 2.7837e-09\n"
          ]
        }
      ],
      "source": [
        "# 두 loss가 제대로 정의되었는지 확인\n",
        "def test_lsgan_loss(score_real, score_fake, d_loss_true, g_loss_true):\n",
        "    score_real = torch.Tensor(score_real).type(dtype)\n",
        "    score_fake = torch.Tensor(score_fake).type(dtype)\n",
        "    d_loss = ls_discriminator_loss(score_real, score_fake).cpu().numpy()\n",
        "    g_loss = ls_generator_loss(score_fake).cpu().numpy()\n",
        "    print(\"Maximum error in d_loss: %g\"%rel_error(d_loss_true, d_loss))\n",
        "    print(\"Maximum error in g_loss: %g\"%rel_error(g_loss_true, g_loss))\n",
        "\n",
        "test_lsgan_loss(\n",
        "    answers['logits_real'],\n",
        "    answers['logits_fake'],\n",
        "    answers['d_loss_lsgan_true'],\n",
        "    answers['g_loss_lsgan_true']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc0hwev0j5-p"
      },
      "source": [
        "Run the following cell to train your model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeAm_enVj5-p",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "D_LS = discriminator().type(dtype)\n",
        "G_LS = generator().type(dtype)\n",
        "\n",
        "D_LS_solver = get_optimizer(D_LS)\n",
        "G_LS_solver = get_optimizer(G_LS)\n",
        "\n",
        "images = run_a_gan(\n",
        "    D_LS,\n",
        "    G_LS,\n",
        "    D_LS_solver,\n",
        "    G_LS_solver,\n",
        "    ls_discriminator_loss,\n",
        "    ls_generator_loss,\n",
        "    loader_train\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7shgysKrj5-q"
      },
      "source": [
        "Run the cell below to show generated images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Drd_56ACj5-q"
      },
      "outputs": [],
      "source": [
        "numIter = 0\n",
        "for img in images:\n",
        "    print(\"Iter: {}\".format(numIter))\n",
        "    show_images(img)\n",
        "    plt.show()\n",
        "    numIter += 250\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1dot-Yjh4yZ"
      },
      "source": [
        "LSGAN output image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-IhBigbj5-r"
      },
      "outputs": [],
      "source": [
        "# This output is your answer.\n",
        "print(\"LSGAN final image:\")\n",
        "show_images(images[-1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3QD-ARaj5-s"
      },
      "source": [
        "# Deeply Convolutional GANs\n",
        "Discriminator와 Generator 네트워크를 정의할 때 FC-layer만 사용한 vanila GAN와 달리 Convolutional layer를 도입한 DCGAN을 실습합니다 :) <br>\n",
        "[DCGAN](https://arxiv.org/abs/1511.06434)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCgj4nOqvy3C"
      },
      "source": [
        "# H.W 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-OegegFrmbt"
      },
      "source": [
        "#### Discriminator\n",
        "\n",
        "아래의 Discriminator architecture를 코드로 작성해주세요!\n",
        "\n",
        "\n",
        "* Reshape into MNIST image tensor (Use Unflatten(N=, C=, H=, W=)!)\n",
        "* Conv2D: out_channels=32 , 5x5, Stride 1, Padding 0\n",
        "* Leaky ReLU(alpha=0.01)\n",
        "* Max Pool 2x2, Stride 2\n",
        "* Conv2D: out_channels=64, 5x5, Stride 1, Padding 0\n",
        "* Leaky ReLU(alpha=0.01)\n",
        "* Max Pool 2x2, Stride 2\n",
        "* Flatten()\n",
        "* Fully Connected with output size 4 x 4 x 64\n",
        "* Leaky ReLU(alpha=0.01)\n",
        "* Fully Connected with output size 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8RagG2GvfJIx"
      },
      "outputs": [],
      "source": [
        "def build_dc_classifier(batch_size):\n",
        "    \"\"\"\n",
        "    Build and return a PyTorch model for the DCGAN discriminator implementing\n",
        "    the architecture above.\n",
        "    \"\"\"\n",
        "\n",
        "    ##############################################################################\n",
        "    # TODO: Discriminator를 build하세요                                                                                           #\n",
        "    # HINT: nn.Sequential를 사용하면 편합니다\n",
        "    ##############################################################################\n",
        "    # ************* START ******************\n",
        "\n",
        "    model = ###############\n",
        "\n",
        "    return model\n",
        "    # ************* END ******************\n",
        "    ##############################################################################\n",
        "    #                               END OF YOUR CODE                             #\n",
        "    ##############################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlNNI7DIj5-s",
        "outputId": "c3d08d9d-7df6-47c2-b353-9de69c97361e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1])\n"
          ]
        }
      ],
      "source": [
        "data = next(enumerate(loader_train))[-1][0].type(dtype)\n",
        "b = build_dc_classifier(batch_size).type(dtype)\n",
        "out = b(data)\n",
        "print(out.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FMsX1osj5-t"
      },
      "source": [
        "Check the number of parameters in your classifier as a sanity check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I5vPgjHj5-t",
        "outputId": "3aa2fcd3-7294-4422-ce17-25c448bf07d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct number of parameters in generator.\n"
          ]
        }
      ],
      "source": [
        "def test_dc_classifer(true_count=1102721):\n",
        "    model = build_dc_classifier(batch_size)\n",
        "    cur_count = count_params(model)\n",
        "    if cur_count != true_count:\n",
        "        print('Incorrect number of parameters in generator. Check your achitecture.')\n",
        "    else:\n",
        "        print('Correct number of parameters in generator.')\n",
        "\n",
        "test_dc_classifer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QO8U_Sgj5-t"
      },
      "source": [
        "#### Generator\n",
        "DCGAN에서 사용할 generator의 구조는  InfoGAN paper의 구조와 동일합니다 <br>\n",
        "[InfoGAN paper](https://arxiv.org/pdf/1606.03657.pdf). <br>\n",
        "수업 시간에 말한 upsampling 기법도 transpose convolution으로 수행하니 아래의 architecture를 코드로 작성해주세요!\n",
        "\n",
        "* Fully connected with input size noise_dim and output size 1024\n",
        "* `ReLU`\n",
        "* BatchNorm\n",
        "* Fully connected with output size 7 x 7 x 128\n",
        "* ReLU\n",
        "* BatchNorm\n",
        "* Reshape into Image Tensor of shape 7, 7, 128 (Use Unflatten(N=, C=, H=, W=)!)\n",
        "* Conv2D^T (Transpose): out_channels=64 ,4x4, stride 2, 'same' padding (use `padding=1`)\n",
        "* `ReLU`\n",
        "* BatchNorm\n",
        "* Conv2D^T (Transpose): out_channels=1, 4x4, stride 2, 'same' padding (use `padding=1`)\n",
        "* `TanH`\n",
        "* Should have a 28x28x1 image, reshape back into 784 vector (use Flatten())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR3YoaSrv2iE"
      },
      "source": [
        "#H.W 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "rqDeTbeVdzkP"
      },
      "outputs": [],
      "source": [
        "def build_dc_generator(noise_dim=NOISE_DIM):\n",
        "    \"\"\"\n",
        "    Build and return a PyTorch model implementing the DCGAN generator using\n",
        "    the architecture described above.\n",
        "    \"\"\"\n",
        "\n",
        "    ##############################################################################\n",
        "    # TODO: Generator를 build하세요                                                                                           #\n",
        "    # HINT: nn.Sequential를 사용하면 편합니다\n",
        "    # HINT: BatchNorm 정의 시 1d와 2d를 구분하셔야 합니다.\n",
        "    ##############################################################################\n",
        "    # ************* START ******************\n",
        "\n",
        "    model = ###############\n",
        "\n",
        "    return model\n",
        "    # ************* END ******************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQZpnSWmj5-u",
        "outputId": "5518ecac-d678-4ebe-f0ce-f5a30446338e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 784])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_g_gan = build_dc_generator().type(dtype)\n",
        "test_g_gan.apply(initialize_weights)\n",
        "\n",
        "fake_seed = torch.randn(batch_size, NOISE_DIM).type(dtype)\n",
        "fake_images = test_g_gan.forward(fake_seed)\n",
        "fake_images.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNWWS4u5j5-u"
      },
      "source": [
        "Check the number of parameters in your generator as a sanity check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3iGEbYmj5-u",
        "outputId": "873b4f69-5987-4310-d68f-3e9da15db258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct number of parameters in generator.\n"
          ]
        }
      ],
      "source": [
        "def test_dc_generator(true_count=6580801):\n",
        "    model = build_dc_generator(4)\n",
        "    cur_count = count_params(model)\n",
        "    if cur_count != true_count:\n",
        "        print('Incorrect number of parameters in generator. Check your achitecture.')\n",
        "    else:\n",
        "        print('Correct number of parameters in generator.')\n",
        "\n",
        "test_dc_generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnGJkgqGj5-v",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "D_DC = build_dc_classifier(batch_size).type(dtype)\n",
        "D_DC.apply(initialize_weights)\n",
        "G_DC = build_dc_generator().type(dtype)\n",
        "G_DC.apply(initialize_weights)\n",
        "\n",
        "D_DC_solver = get_optimizer(D_DC)\n",
        "G_DC_solver = get_optimizer(G_DC)\n",
        "\n",
        "images = run_a_gan(\n",
        "    D_DC,\n",
        "    G_DC,\n",
        "    D_DC_solver,\n",
        "    G_DC_solver,\n",
        "    discriminator_loss,\n",
        "    generator_loss,\n",
        "    loader_train,\n",
        "    num_epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31k6XXJKj5-v"
      },
      "source": [
        "Run the cell below to show generated images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOHZrYN3j5-w"
      },
      "outputs": [],
      "source": [
        "numIter = 0\n",
        "for img in images:\n",
        "    print(\"Iter: {}\".format(numIter))\n",
        "    show_images(img)\n",
        "    plt.show()\n",
        "    numIter += 250\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAUxkDF1j5-w"
      },
      "source": [
        "DCGAN output image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb00MK6oj5-x"
      },
      "outputs": [],
      "source": [
        "# This output is your answer.\n",
        "print(\"DCGAN final image:\")\n",
        "show_images(images[-1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWVr3kBh31nX"
      },
      "source": [
        "4주 동안 모두 고생 많으셨습니다 :) 많이 부족한 세션과 과제임에도 불구하고 잘 따라와주셔서 정말 감사드립니다.\n",
        "\n",
        "추운 날씨에 건강 조심하시고 남은 프로젝트와 스터디도 끝까지 화이팅 하시기를 응원하겠습니다 ㅎㅎ 과제 또는 이외에 궁금한 사항이 있다면 언제든지 17기 임청수에게 DM 보내주세요! 🙇🏻‍♂️"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
