{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nmQ5F7UAeKB_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sgxd6SxmeVcP"
   },
   "source": [
    "## Task1\n",
    "\n",
    "빈 칸을 채워주세요!\n",
    "\n",
    "단계별 output이 github 파일에는 남아있으니 그 output과 동일한 형태인지 확인하면서 진행해주시면 됩니다~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NDvUeC8BoUb6"
   },
   "outputs": [],
   "source": [
    "#1. 생성할 문장 데이터\n",
    "\n",
    "sentence = (\"Brick walls are there for a reason and you must not think \"\n",
    "            \"that the brick walls aren't there to keep us out, but rather \"\n",
    "            \"in this way that the brick walls are there to show us how badly we want things.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "b9lkrKyZf8ie"
   },
   "outputs": [],
   "source": [
    "#2. 문자 집합 만들기\n",
    "world_set = list(set(sentence))\n",
    "\n",
    "## 문제(1): 각 문자에 정수 인코딩 (공백도 하나의 원소로 포함)\n",
    "vocab = {}\n",
    "for i in range(len(world_set)):\n",
    "    vocab[world_set[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F_0we5Y-gYDq",
    "outputId": "01af8d3e-406c-4be6-d44d-e5c950900e4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o': 0, 'm': 1, '.': 2, 'k': 3, 'f': 4, 'r': 5, 'n': 6, 'e': 7, ' ': 8, \"'\": 9, 'g': 10, 'w': 11, 'u': 12, 'c': 13, 'h': 14, 't': 15, 'B': 16, 'd': 17, 'p': 18, 'a': 19, ',': 20, 'i': 21, 'l': 22, 's': 23, 'y': 24, 'b': 25}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TpKupU6lgpfT",
    "outputId": "8aa615b8-e7e7-4ded-89bd-0a30ea2b7963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합 크기 : 26\n"
     ]
    }
   ],
   "source": [
    "#3. 문자 집합 크기 확인\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print('문자 집합 크기 : {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wFDZJHSMg9In"
   },
   "outputs": [],
   "source": [
    "#4. 하이퍼 파라미터 설정(자유롭게 수정해보세요!)\n",
    "\n",
    "hidden_size = vocab_size # 같아야 하는 것 확인!\n",
    "sequence_length = 10  # 너무 길거나 너무 짧게 잡으면 안됩니다!\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RbDcmJmghN7V",
    "outputId": "dcfb8e63-be17-440a-d2eb-f4c468c08a8f"
   },
   "outputs": [],
   "source": [
    "#5. seqence 길이 단위 자르기\n",
    "\n",
    "# 데이터 구성을 위한 리스트\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "## 문제(2): 반복문 내에서의 인덱싱을 사용하여 sequence_length 값 단위로 샘플을 잘라 데이터 만들기, y_str은 x_str은 한 칸씩 쉬프트된 sequnce\n",
    "\n",
    "for i in range(0, len(sentence) - sequence_length):\n",
    "  x_str = sentence[i:i+sequence_length]\n",
    "  y_str = sentence[i+1:i+1+sequence_length]\n",
    "  print(i, x_str, \"->\", y_str)\n",
    "\n",
    "  # x_str과 y_str이 문자집합에 해당하는 인덱스를 각각 x_data, y_data에 append\n",
    "  x_data.append([vocab[c] for c in x_str])\n",
    "  y_data.append([vocab[d] for d in y_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVFlILiOixdc",
    "outputId": "504a1c71-f8f5-446f-f9fb-8fb1e24d41fc"
   },
   "outputs": [],
   "source": [
    "# 출력해서 한 칸씩 쉬프트된 것 확인하기!\n",
    "\n",
    "print(x_data[0])\n",
    "print(y_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lPes1dvjlNb",
    "outputId": "0705e61b-779f-4c71-8303-dc6c275bb401"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tpgns\\AppData\\Local\\Temp\\ipykernel_23500\\3292177215.py:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  X = torch.FloatTensor(x_one_hot)\n"
     ]
    }
   ],
   "source": [
    "##6. 입력 시퀀스에 대해 원핫인코딩 수행\n",
    "\n",
    "## 문제(4) : x_data를 원핫인코딩 > numpy의 eye를 쓸 수 있지 않을까?\n",
    "x_one_hot = [np.eye(vocab_size)[data] for data in x_data]\n",
    "\n",
    "##7. 입력 데이터, 레이블데이터 텐서로 변환\n",
    "\n",
    "## 문제(5) : x_one_hot과 y_data 텐서로 변환 : 둘 다 같은 형식의 텐서로 변환하면 될까?? (FloatTensor, LongTensor 중 맞는 것은?)\n",
    "X = torch.FloatTensor(x_one_hot)\n",
    "Y = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lMZzZlaymMk8",
    "outputId": "9d64e989-9ca6-4c8c-830a-7460a4f3a47b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기 : torch.Size([188, 10, 26])\n",
      "레이블의 크기 : torch.Size([188, 10])\n"
     ]
    }
   ],
   "source": [
    "##8. 크기 확인\n",
    "print('훈련 데이터의 크기 : {}'.format(X.shape))\n",
    "print('레이블의 크기 : {}'.format(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "knx1DE_AmSFB",
    "outputId": "5e46adcc-8fec-4ea2-ea1f-e5f0766eb161"
   },
   "outputs": [],
   "source": [
    "##9.원핫인코딩 결과 샘플 확인하기\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6pWDiH1SmYT_",
    "outputId": "744a60f6-c22b-47e1-8ff5-dee57ac8e706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5, 21, 13,  3,  8, 11, 19, 22, 22, 23])\n"
     ]
    }
   ],
   "source": [
    "##10. 레이블 데이터 샘플 확인하기\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-Ww22xu8mfUc"
   },
   "outputs": [],
   "source": [
    "##11. RNN 모델 구현\n",
    "\n",
    "##문제(6) : 기본 pytorch 인자 넣기 연습 + forward 채우기\n",
    "### 조건 : rnn layer 2개 쌓기 + 마지막은 fc layer\n",
    "### batch_fisrt 설정 필요할까? (유튜브 강의 참고)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, layers):\n",
    "    super(Net, self).__init__()\n",
    "    self.rnn = torch.nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True)\n",
    "    self.fc = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "  \n",
    "  def forward(self, x):\n",
    "      x, hidden = self.rnn(x)\n",
    "      N, T, H = x.shape\n",
    "      x = x.contiguous().view(N*T, H)\n",
    "      x = self.fc(x)\n",
    "      x = x.view(N, T, H)\n",
    "      return x, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "No2GRvTpnLBl"
   },
   "outputs": [],
   "source": [
    "net = Net(vocab_size, hidden_size, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9-zuJLeUnQLB"
   },
   "outputs": [],
   "source": [
    "##12. loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "##13. optimizer\n",
    "optimizer = optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-RxRaiHnh9U",
    "outputId": "91348b4b-28bb-469b-85a0-8b9cc85e0454"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([188, 10, 26])\n",
      "torch.Size([2, 188, 26])\n"
     ]
    }
   ],
   "source": [
    "##14. 출력 크기 점검\n",
    "outputs, h = net(X)\n",
    "print(outputs.shape)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxxrxCd2nwoo",
    "outputId": "ac865379-a166-45d5-c8ae-18a257116dd3"
   },
   "outputs": [],
   "source": [
    "##15. Training 시작\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs, _ = net(X)\n",
    "    ##문제(7) : outputs, Y 형태 그대로 넣으면 안되죠. view 함수를 이용해 loss값을 계산해봅시다.\n",
    "    loss = criterion(outputs.reshape(-1,26), Y.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #16. 예측결과 확인\n",
    "    results = outputs.argmax(dim=2)\n",
    "    predict_str = \"\"\n",
    "    for j, result in enumerate(results):\n",
    "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
    "            predict_str += ''.join([world_set[t] for t in result])\n",
    "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
    "            predict_str += world_set[result[-1]]\n",
    "\n",
    "    print(predict_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "8qUkbiw2t0Il",
    "outputId": "60267f5c-c8de-4770-c509-244703d49bc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinksm\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkIzDTdyvTHz"
   },
   "source": [
    "결과가 어떤가요?? 마지막 에폭의 문장이 그럴싸한가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kN1zL8Dpvane"
   },
   "source": [
    "## Task2\n",
    "\n",
    "위 sentence는 제가 임의로 생성한 문장들입니다.\n",
    "\n",
    "마음에 드시는 문구 가져오셔서 문장이 어떻게 생성되는지 확인해보세요! \n",
    "\n",
    "영어가 아닌 한국어로 시도해보는 것도 좋겠죠? \n",
    "\n",
    "수정이 많이 필요(토큰화 등) 할 수 있으나 한번 시도해보시는 것 권장드립니다 :)\n",
    "\n",
    "위 베이스라인은 어디든 수정하셔도 좋고 조금 더 자연스러운 문장이 나올 수 있게 다양한 시도를 해보세요!\n",
    "\n",
    "조건 : 문장 3개 이상, 연결성이 있는 문장을 \" \" 으로 구분하여 ( )에 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "IKp-lKrjvXR9"
   },
   "outputs": [],
   "source": [
    "sentence = (\"The only way to do great work is to love what you do. \"\n",
    "            \"In the middle of difficulty lies opportunity, so Believe you can and you're halfway there. \"\n",
    "            \"Success is not final, failure is not fatal. It is the courage to continue that counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 문자 집합 만들기\n",
    "world_set = list(set(sentence))\n",
    "\n",
    "## 문제(1): 각 문자에 정수 인코딩 (공백도 하나의 원소로 포함)\n",
    "vocab = {word:id for id, word in enumerate(world_set)}\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 10\n",
    "sequence_length = 20  \n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for i in range(0, len(sentence) - sequence_length):\n",
    "  x_str = sentence[i:i+sequence_length]\n",
    "  y_str = sentence[i+1:i+1+sequence_length]\n",
    "  print(i, x_str, \"->\", y_str)\n",
    "\n",
    "  x_data.append([vocab[c] for c in x_str])\n",
    "  y_data.append([vocab[d] for d in y_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one_hot = [np.eye(vocab_size)[data] for data in x_data]\n",
    "\n",
    "X = torch.FloatTensor(x_one_hot)\n",
    "Y = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, layers, vocab_size):\n",
    "    super(Net, self).__init__()\n",
    "    self.vocab_size = vocab_size\n",
    "    self.rnn = torch.nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True)\n",
    "    self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
    "  \n",
    "  def forward(self, x):\n",
    "      x, hidden = self.rnn(x)\n",
    "      N, T, H = x.shape\n",
    "      x = x.contiguous().view(N*T, H)\n",
    "      x = self.fc(x)\n",
    "      x = x.view(N, T, self.vocab_size)\n",
    "      return x, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(vocab_size, hidden_size, 2, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    outputs, _ = net(X)\n",
    "    ##문제(7) : outputs, Y 형태 그대로 넣으면 안되죠. view 함수를 이용해 loss값을 계산해봅시다.\n",
    "    loss = criterion(outputs.reshape(-1,vocab_size), Y.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #16. 예측결과 확인\n",
    "    results = outputs.argmax(dim=2)\n",
    "    predict_str = \"\"\n",
    "    for j, result in enumerate(results):\n",
    "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
    "            predict_str += ''.join([world_set[t] for t in result])\n",
    "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
    "            predict_str += world_set[result[-1]]\n",
    "\n",
    "    print(predict_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he fnly tay th do great work is to love what you do. In the middle of difficulty lies opportunity, so Believe you can and you re halfway there. Success is not final, failure is not fital. It is the courege to continue that county'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_str"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
