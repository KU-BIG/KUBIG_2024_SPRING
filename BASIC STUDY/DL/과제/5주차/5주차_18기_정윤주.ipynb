{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ceM93HQ6maLv",
        "DZVACSdDmkQj",
        "IGnhIoe8nQor",
        "arJ421ploHJp"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "nmQ5F7UAeKB_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task1\n",
        "\n",
        "빈 칸을 채워주세요!\n",
        "\n",
        "단계별 output이 github 파일에는 남아있으니 그 output과 동일한 형태인지 확인하면서 진행해주시면 됩니다~"
      ],
      "metadata": {
        "id": "Sgxd6SxmeVcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. 생성할 문장 데이터\n",
        "\n",
        "sentence = (\"Brick walls are there for a reason and you must not think \"\n",
        "            \"that the brick walls aren't there to keep us out, but rather \"\n",
        "            \"in this way that the brick walls are there to show us how badly we want things.\")"
      ],
      "metadata": {
        "id": "NDvUeC8BoUb6"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. 문자 집합 만들기\n",
        "world_set = list(set(sentence))\n",
        "\n",
        "## 문제(1): 각 문자에 정수 인코딩 (공백도 하나의 원소로 포함)\n",
        "vocab = {char: idx for idx, char in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "b9lkrKyZf8ie"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_0we5Y-gYDq",
        "outputId": "6ebf3d0b-513f-400e-cbe8-44b928bf31c3"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'e': 0, '.': 1, 'u': 2, 'c': 3, 'g': 4, 'b': 5, 'i': 6, 'm': 7, 'd': 8, 'a': 9, 'B': 10, 'o': 11, 'n': 12, \"'\": 13, 'p': 14, 'r': 15, 's': 16, 'f': 17, ',': 18, 'w': 19, 'l': 20, 'y': 21, ' ': 22, 't': 23, 'k': 24, 'h': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. 문자 집합 크기 확인\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print('문자 집합 크기 : {}'.format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpKupU6lgpfT",
        "outputId": "1af246e6-c3d8-4eec-e547-0273d9c5233b"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 크기 : 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. 하이퍼 파라미터 설정(자유롭게 수정해보세요!)\n",
        "\n",
        "hidden_size = vocab_size # 같아야 하는 것 확인!\n",
        "sequence_length = 10  # 너무 길거나 너무 짧게 잡으면 안됩니다!\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "wFDZJHSMg9In"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- hidden size와 vocab size가 같아야 하는 이유\n",
        "\n",
        "추후에 원핫인코딩방식을 사용하기 때문\n",
        "\n",
        "=> 표현하고 싶은 단어의 인덱스 위치에 1을 부여 / 다른 인덱스 위치에는 0을 부여 따라서 문자의 개수가 벡터의 크기가 되므로 둘을 일치시키는 것이 적절\n",
        "\n",
        "[참고자료]\n",
        "\n",
        "https://wikidocs.net/60853\n"
      ],
      "metadata": {
        "id": "c9aNetJo8Lo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5. seqence 길이 단위 자르기\n",
        "\n",
        "# 데이터 구성을 위한 리스트\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "## 문제(2): 반복문 내에서의 인덱싱을 사용하여 sequence_length 값 단위로 샘플을 잘라 데이터 만들기, y_str은 x_str은 한 칸씩 쉬프트된 sequnce\n",
        "\n",
        "for i in range(0, len(sentence) - sequence_length):\n",
        "  x_str = sentence[i:i+sequence_length]\n",
        "  y_str = sentence[i+1 : i+sequence_length + 1]\n",
        "  print(i, x_str, \"->\", y_str)\n",
        "\n",
        "#x_str, y_str : 주어진 문장에서 잘라낸 일정 길이의 문자열\n",
        "#현재 위치에서 sequence_length만큼의 문자열\n",
        "#x_str, y_str을 순회하며 vocab 딕셔너리에 존재하는지 찾아서 리스트에 추가한것이 x_data, y_data(정수 인코딩된 값)\n",
        "\n",
        "  # x_str과 y_str이 문자집합에 해당하는 인덱스를 각각 x_data, y_data에 append\n",
        "  x_data.append([vocab[c] for c in x_str])\n",
        "  y_data.append([vocab[d] for d in y_str])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbDcmJmghN7V",
        "outputId": "9a8ad2b0-b3a5-40ce-f587-e73749dc55d5"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Brick wall -> rick walls\n",
            "1 rick walls -> ick walls \n",
            "2 ick walls  -> ck walls a\n",
            "3 ck walls a -> k walls ar\n",
            "4 k walls ar ->  walls are\n",
            "5  walls are -> walls are \n",
            "6 walls are  -> alls are t\n",
            "7 alls are t -> lls are th\n",
            "8 lls are th -> ls are the\n",
            "9 ls are the -> s are ther\n",
            "10 s are ther ->  are there\n",
            "11  are there -> are there \n",
            "12 are there  -> re there f\n",
            "13 re there f -> e there fo\n",
            "14 e there fo ->  there for\n",
            "15  there for -> there for \n",
            "16 there for  -> here for a\n",
            "17 here for a -> ere for a \n",
            "18 ere for a  -> re for a r\n",
            "19 re for a r -> e for a re\n",
            "20 e for a re ->  for a rea\n",
            "21  for a rea -> for a reas\n",
            "22 for a reas -> or a reaso\n",
            "23 or a reaso -> r a reason\n",
            "24 r a reason ->  a reason \n",
            "25  a reason  -> a reason a\n",
            "26 a reason a ->  reason an\n",
            "27  reason an -> reason and\n",
            "28 reason and -> eason and \n",
            "29 eason and  -> ason and y\n",
            "30 ason and y -> son and yo\n",
            "31 son and yo -> on and you\n",
            "32 on and you -> n and you \n",
            "33 n and you  ->  and you m\n",
            "34  and you m -> and you mu\n",
            "35 and you mu -> nd you mus\n",
            "36 nd you mus -> d you must\n",
            "37 d you must ->  you must \n",
            "38  you must  -> you must n\n",
            "39 you must n -> ou must no\n",
            "40 ou must no -> u must not\n",
            "41 u must not ->  must not \n",
            "42  must not  -> must not t\n",
            "43 must not t -> ust not th\n",
            "44 ust not th -> st not thi\n",
            "45 st not thi -> t not thin\n",
            "46 t not thin ->  not think\n",
            "47  not think -> not think \n",
            "48 not think  -> ot think t\n",
            "49 ot think t -> t think th\n",
            "50 t think th ->  think tha\n",
            "51  think tha -> think that\n",
            "52 think that -> hink that \n",
            "53 hink that  -> ink that t\n",
            "54 ink that t -> nk that th\n",
            "55 nk that th -> k that the\n",
            "56 k that the ->  that the \n",
            "57  that the  -> that the b\n",
            "58 that the b -> hat the br\n",
            "59 hat the br -> at the bri\n",
            "60 at the bri -> t the bric\n",
            "61 t the bric ->  the brick\n",
            "62  the brick -> the brick \n",
            "63 the brick  -> he brick w\n",
            "64 he brick w -> e brick wa\n",
            "65 e brick wa ->  brick wal\n",
            "66  brick wal -> brick wall\n",
            "67 brick wall -> rick walls\n",
            "68 rick walls -> ick walls \n",
            "69 ick walls  -> ck walls a\n",
            "70 ck walls a -> k walls ar\n",
            "71 k walls ar ->  walls are\n",
            "72  walls are -> walls aren\n",
            "73 walls aren -> alls aren'\n",
            "74 alls aren' -> lls aren't\n",
            "75 lls aren't -> ls aren't \n",
            "76 ls aren't  -> s aren't t\n",
            "77 s aren't t ->  aren't th\n",
            "78  aren't th -> aren't the\n",
            "79 aren't the -> ren't ther\n",
            "80 ren't ther -> en't there\n",
            "81 en't there -> n't there \n",
            "82 n't there  -> 't there t\n",
            "83 't there t -> t there to\n",
            "84 t there to ->  there to \n",
            "85  there to  -> there to k\n",
            "86 there to k -> here to ke\n",
            "87 here to ke -> ere to kee\n",
            "88 ere to kee -> re to keep\n",
            "89 re to keep -> e to keep \n",
            "90 e to keep  ->  to keep u\n",
            "91  to keep u -> to keep us\n",
            "92 to keep us -> o keep us \n",
            "93 o keep us  ->  keep us o\n",
            "94  keep us o -> keep us ou\n",
            "95 keep us ou -> eep us out\n",
            "96 eep us out -> ep us out,\n",
            "97 ep us out, -> p us out, \n",
            "98 p us out,  ->  us out, b\n",
            "99  us out, b -> us out, bu\n",
            "100 us out, bu -> s out, but\n",
            "101 s out, but ->  out, but \n",
            "102  out, but  -> out, but r\n",
            "103 out, but r -> ut, but ra\n",
            "104 ut, but ra -> t, but rat\n",
            "105 t, but rat -> , but rath\n",
            "106 , but rath ->  but rathe\n",
            "107  but rathe -> but rather\n",
            "108 but rather -> ut rather \n",
            "109 ut rather  -> t rather i\n",
            "110 t rather i ->  rather in\n",
            "111  rather in -> rather in \n",
            "112 rather in  -> ather in t\n",
            "113 ather in t -> ther in th\n",
            "114 ther in th -> her in thi\n",
            "115 her in thi -> er in this\n",
            "116 er in this -> r in this \n",
            "117 r in this  ->  in this w\n",
            "118  in this w -> in this wa\n",
            "119 in this wa -> n this way\n",
            "120 n this way ->  this way \n",
            "121  this way  -> this way t\n",
            "122 this way t -> his way th\n",
            "123 his way th -> is way tha\n",
            "124 is way tha -> s way that\n",
            "125 s way that ->  way that \n",
            "126  way that  -> way that t\n",
            "127 way that t -> ay that th\n",
            "128 ay that th -> y that the\n",
            "129 y that the ->  that the \n",
            "130  that the  -> that the b\n",
            "131 that the b -> hat the br\n",
            "132 hat the br -> at the bri\n",
            "133 at the bri -> t the bric\n",
            "134 t the bric ->  the brick\n",
            "135  the brick -> the brick \n",
            "136 the brick  -> he brick w\n",
            "137 he brick w -> e brick wa\n",
            "138 e brick wa ->  brick wal\n",
            "139  brick wal -> brick wall\n",
            "140 brick wall -> rick walls\n",
            "141 rick walls -> ick walls \n",
            "142 ick walls  -> ck walls a\n",
            "143 ck walls a -> k walls ar\n",
            "144 k walls ar ->  walls are\n",
            "145  walls are -> walls are \n",
            "146 walls are  -> alls are t\n",
            "147 alls are t -> lls are th\n",
            "148 lls are th -> ls are the\n",
            "149 ls are the -> s are ther\n",
            "150 s are ther ->  are there\n",
            "151  are there -> are there \n",
            "152 are there  -> re there t\n",
            "153 re there t -> e there to\n",
            "154 e there to ->  there to \n",
            "155  there to  -> there to s\n",
            "156 there to s -> here to sh\n",
            "157 here to sh -> ere to sho\n",
            "158 ere to sho -> re to show\n",
            "159 re to show -> e to show \n",
            "160 e to show  ->  to show u\n",
            "161  to show u -> to show us\n",
            "162 to show us -> o show us \n",
            "163 o show us  ->  show us h\n",
            "164  show us h -> show us ho\n",
            "165 show us ho -> how us how\n",
            "166 how us how -> ow us how \n",
            "167 ow us how  -> w us how b\n",
            "168 w us how b ->  us how ba\n",
            "169  us how ba -> us how bad\n",
            "170 us how bad -> s how badl\n",
            "171 s how badl ->  how badly\n",
            "172  how badly -> how badly \n",
            "173 how badly  -> ow badly w\n",
            "174 ow badly w -> w badly we\n",
            "175 w badly we ->  badly we \n",
            "176  badly we  -> badly we w\n",
            "177 badly we w -> adly we wa\n",
            "178 adly we wa -> dly we wan\n",
            "179 dly we wan -> ly we want\n",
            "180 ly we want -> y we want \n",
            "181 y we want  ->  we want t\n",
            "182  we want t -> we want th\n",
            "183 we want th -> e want thi\n",
            "184 e want thi ->  want thin\n",
            "185  want thin -> want thing\n",
            "186 want thing -> ant things\n",
            "187 ant things -> nt things.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력해서 한 칸씩 쉬프트된 것 확인하기!\n",
        "\n",
        "print(x_data[0])\n",
        "print(y_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVFlILiOixdc",
        "outputId": "2cff2afb-03b5-4384-dd5f-12c571bfd680"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10, 15, 6, 3, 24, 22, 19, 9, 20, 20]\n",
            "[15, 6, 3, 24, 22, 19, 9, 20, 20, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##6. 입력 시퀀스에 대해 원핫인코딩 수행\n",
        "\n",
        "## 문제(4) : x_data를 원핫인코딩 > numpy의 eye를 쓸 수 있지 않을까?\n",
        "x_one_hot = [np.eye(vocab_size)[idx] for idx in x_data]\n",
        "\n",
        "##7. 입력 데이터, 레이블데이터 텐서로 변환\n",
        "\n",
        "## 문제(5) : x_one_hot과 y_data 텐서로 변환 : 둘 다 같은 형식의 텐서로 변환하면 될까?? (FloatTensor, LongTesor 중 맞는 것은?)\n",
        "X = torch.FloatTensor(np.array(x_one_hot))\n",
        "Y = torch.LongTensor(y_data)"
      ],
      "metadata": {
        "id": "5lPes1dvjlNb"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "numpy - eye\n",
        "\n",
        "n*m 행렬을 만들어주며, 배열은 identity 행렬과 유사함.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "In [2]:np.eye(N=3, M=5, # 총 행렬의 크기는 3x5 로 만들어 달라\n",
        "               k=1, # identity matrix의 시작은 1열부터 시작하라\n",
        "\t\t\t   dtype=np.int8) # dtype은 int8로 설정\n",
        "         \n",
        "Out[2]:array([[0, 1, 0, 0, 0],\n",
        "              [0, 0, 1, 0, 0],\n",
        "              [0, 0, 0, 1, 0]],\n",
        "              dtype=int8)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "출처: https://coding-grandpa.tistory.com/entry/NumPy-identity-행렬-eye-diag-함수-이해하기-Creation-Function-III [개발자로 취직하기:티스토리]\n",
        "\n",
        "\n",
        "보통 신경망 input은 float tensor, 손실함수와 비교되는 output은 long tensor로 만들어 줌(정수값)"
      ],
      "metadata": {
        "id": "DQpkFmxO_uXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##8. 크기 확인\n",
        "print('훈련 데이터의 크기 : {}'.format(X.shape))\n",
        "print('레이블의 크기 : {}'.format(Y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMZzZlaymMk8",
        "outputId": "ea352948-43ef-4c89-c497-72dbe790e46d"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : torch.Size([188, 10, 26])\n",
            "레이블의 크기 : torch.Size([188, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##9.원핫인코딩 결과 샘플 확인하기\n",
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knx1DE_AmSFB",
        "outputId": "cfa51a03-e75e-4bbb-8b2a-8d5d94c5dd2e"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 1., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##10. 레이블 데이터 샘플 확인하기\n",
        "print(Y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pWDiH1SmYT_",
        "outputId": "2dbf1cbb-9a49-4dc3-e8b2-30191fada824"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([15,  6,  3, 24, 22, 19,  9, 20, 20, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_one_hot[0][0]) #one hot encoding size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT_DIlLO9vkW",
        "outputId": "05e0d6eb-a676-4b4b-96c1-dd72c1e736c7"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##11. RNN 모델 구현\n",
        "\n",
        "##문제(6) : 기본 pytorch 인자 넣기 연습 + forward 채우기\n",
        "### 조건 : rnn layer 2개 쌓기 + 마지막은 fc layer\n",
        "### batch_fisrt 설정 필요할까? (유튜브 강의 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn1 = torch.nn.RNN(input_size=input_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.rnn2 = torch.nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn1(x)\n",
        "        out, _ = self.rnn2(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "-Ww22xu8mfUc"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2)"
      ],
      "metadata": {
        "id": "No2GRvTpnLBl"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##12. loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "##13. optimizer\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "9-zuJLeUnQLB"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##14. 출력 크기 점검\n",
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-RxRaiHnh9U",
        "outputId": "7b322242-0bc1-4893-cb78-25990bf637f9"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([188, 10, 26])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##15. Training 시작\n",
        "\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    ##문제(7) : outputs, Y 형태 그대로 넣으면 안되죠. view 함수를 이용해 loss값을 계산해봅시다.\n",
        "    loss = criterion(outputs.view(-1, vocab_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxxrxCd2nwoo",
        "outputId": "4b0b1eef-56bf-403a-80f7-27411345f5b0"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ppffffffffffffffffffffffffffffffffffffffffffffnffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff\n",
            "n                                                                                                                                                                                                    \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "     t t       t     t                  t      t   t t        t   t t   t t          t     t t          t    t t   t              t    t   t t   t t       t     t t          t   t   t    t       t \n",
            "     t t   t   t     t     t  t   t     t      t t t t   t    t   t t   t t   t      t   t t t     t  t t    t t t t t   t      t t t  t   t t   t t   t   t     t t   t      t   t   t  t    t    t \n",
            "     t   t     t   t t     t  t   t  t  t   t  t t t t   t  t t t t t   t   t      t t   t t t     t  t t      t t t t   t      t t    t   t t   t   t     t   t t t   t      t   t   t  t    t    t \n",
            "     t   t     t   t t     t  t   t  tt t   t  t t t t   t  t t t t t   t   t      t t t t t t     t  t t  t t t t t t   t  t   t t  t t t t t   t   t     t   t t t   t      t   t   t  t    t  t t \n",
            "     t   t   t t t t t t   t  t   t   t tt  t  t t t t   t  t t t t t   t   t   t  t t t t t tt    t    t  t t t t t t   t  t   t t  t t t t t   t   t   t t t t t tt  t      t   t   t  t    t  t t \n",
            " t  h.....   t t........p  t  ....t  ..h..  t  t....h.................. .....   t  B...th......h '..p   thB....t t t ...ot .B....h.....t........ .....   t t.........h t t.   t .........t th t..B...\n",
            " t t t t t   t t t t t t   t  t   t  tt tt  tt t t t t   t  t t t t t t t t t   t  t t t t t tt    t    t  t t t t t t   t  t   t t tt t t t t t t t t   t t t t t tt  t      t   t t t  t t  t tt t \n",
            " t t t t t   t t t t t t   t  t   t  tt tt  t  t t t t   t  t t t t t t t t t   t  t t t t t tt t  t  t t  t t t t t t   t tt   t t tt t t t t t t t t   t t t t t tt  t  t   t   t t t  t t  t tt t \n",
            " t t t t t   t t t t t t   t  t   t  tt tt  t  t t t t   t  t t t t t t t t t   t  t t t t t tt t  t  t t  t t t t t t   t tt   t t tt t t t t t t t t   t t t t t tt  t  t   t   t t t  t t  t tt t \n",
            " t t t t t   t t t t t t   t  t   t  tt t   t  t t t t   t  t t t t t t t t t   t  t t t t t tt t  t  t t  t t t t t t   t t    t t tt t t t t t t t t   t t t t t tt  t      t   t t t  t t  t tt t \n",
            " t t t t t   t t t t t t   t  t   t  tt t   t  t t t t   t  t t t t t t t t t   t  t t t t t tt t  t  t t  t t t t t t   t t    t t tt t t t t t t t t   t t t t t tt  t      t   t t t  t t  t tt t \n",
            " t   t t t   t t t t t t   t  t   t   t t   t  t t t t   t  t t t t t   t   t   t  t t t t t tt t  t  t t  t t t t t     t t    t t tt t t t t   t   t   t t t t t tt  t      t   t t t  t t  t tt t \n",
            " t   t       t t t t t t   t  t   t   t t   t  t t t t   t  t t t t t   t   t   t  t t t   t tt t  t    t  t t t t t     t t    t t tt t t t t   t   t   t t t t t tt  t  t   t   t t t  t t  t tt t \n",
            " t   t   t   t t t t t t   t  t   t  tt t   t  t t t t   t  t t t t t   t  tt   t  t t t   t tt t  t    t  t t t t t     t t    t t tt t t t t   t  tt   t t t t t tt  t  t   t   t t t  t t  t tt t \n",
            " t   t   t   t t t t t t   t  t   t  tt t   t  t t t t   t  t t t t t   t  tt   t  t t t t t tt t  t    t  t t t t t t   t t    t t tt t t t t   t  tt   t t t t t tt  t  t   t t t t t  t t  t tt t \n",
            " t   t e t   t t t t t t e t  t t t  tt tt  t  t t t t   t  t t t t t   t ett   t  t t t t t tt t  tt   t  t t t t t t   t tt t t t tt t t t t   t ett   t t t t t tt  t  t   t t t t t  t t  t tt t \n",
            " t e t e t   t t t t t t e t  t t t   t tt  t  t t t t   t  t t t t t   t ett   t  t t t t t tt t  tt   t  t t t t t t   t tt t t t tt t t t t   t ett   t t t t t tt  t et   t t t t t  t t  t tt t \n",
            " t e t e t   t t t t t t e t  t t t   t tt  t  t t t t   t  t t t t t   t ett   t  t t e t t tt t  tt   t  t t t t t t   t tt t t t tt t t t t   t ett   t t t t t tt  t et   t t t t t  t t  t tt t \n",
            " t e t ett   t t t t t t e t  t t t   t tt  tt t t t t   t  t t t t t   t ett   t  t t e t t tt t  tt   t  t t t t e t   t tt t t t et t t t t   t ett   t t t t t tt  t et   t t t t t  t t  t et t \n",
            " t e t ett   t t t t t t e t  t t t   t tt  tt t t t t   t  t t t t t   t ett   t  t t e t t tt t  tt  et  t t t t e t   t tt t t t et t t t t   t ett   t t t t t tt  t et   t e t t t  t t  t et t \n",
            " e e t ett   t t t t t t e t  t t t   t tt  tt t t t t   t  t t t t t e t ett   t  t t e t t tt t  tt  et  t t t t e t   t et t t t et t t t t e t ett   t t t t t tt  t et   t e t t t  t t  t et t \n",
            " e e t ett   t t t e t t e t  t e t   t tt  tt t t t e   t  t t e t t e t ett   t  t t e e t tt e  tt  et  t t t t e t   t et t e t et t e t t e t ett   t t t e t tt  t et   t e t t t  t t  t et t \n",
            " e e t ett   t t t e t t e t  t e t   t tt  tt t t t e   t  t t e t t e t ett   t  t t e e t tt e  tt   t  t t t t e e   t et t e t et t e t t e t ett   t t t e t tt  t et   t e t t t  t t  t et t \n",
            " e e t e t   e t t e t t e t  t e t   t tt  tt t t t e   t  t t e t t e t ett   e  t t e e t tt e  tt   t  t t t t e e   t et t e t et t e t t e t ett   e t t e t tt  t et   t e t t t  t t  t e  t \n",
            " e e t e t   e t e   t t e t  t e t   t t   tt t t t e   t  t t e t t e t ett   e  t t e e t tt e  tt   t  t t t t e ee  t es t e t et t e t t e t ett   e t e   t tt  t et   t e t t t  t t  t e  t \n",
            " e e t e t   e t e   t t e t  t e t   t t   tt t t t e   t  t t e t t e t est   e  t t e e t tt e  tt   t  t t e t e ee  t es t e t et t e t t e t est   e t e   t tt  t et   t e t t t  t e  t e  t \n",
            " e e t e t   e t e e t t e t  t e t   t t   tt t t t e   t  t t e t t e t ett   e  t t e e t tt e  tt   t  t t e t e ee  t es t e t et t e t t e t ett   e t e e t tt  t et   t e t t t  t e  t e  t \n",
            " e e t e t   e t e e t t e t  t e t   t t   tt t t t e   t  t t e t t e t ett   e  t t e e t tt e  tt   t  t t e t e el  t es t e t et t e t t e t ett   e t e e t tt  t et   t e t t t  t e  t e  t \n",
            " e e t e t   e t e e t t e t  t e e   t t   tt t t t e   t  t t e t t e t ett   e et t e e t tt e  tt  et  t t e t e el  t es t e t et t e t t e t ett   e t e e t tt  t et   t e t t t  t e  t e  t \n",
            " t e t e t   e t e e t t e t  t e e   t t   tt t t t e   t  t t e t t e t ett   e et t e e t tt e  tt  et  t t e t e el  t es t e t et t e t t e t ett   e t e e t tt  t et   t e t t t  t e  t er t \n",
            " t e t e t   e t e e t t e t  t e e   t t   tt t t t er  t  t t e t t e t ett   e et t e e t tt e  tt  et  t t e t e es  t es t e t et t e t t e t ett   e t e e t tt  t et   t e t t t  t e  t er t \n",
            " t e t e t e e t e e t t e t  t e e   t t   tt t t t es  t  t t e t t e t ett e e et t e e t tt e  tt  et  t t e t e et  t es t e t et t e t t e t ett e e t e e t et  t et   t e t t t  t e  t e  t \n",
            " t e t elt e e t e e t t e t  t e e   t t   tt t t t es  t  t t e t t   t ett e e et t e e t tt e  et  et  t t e t e et  t es t e t et t e t t   t ett e e t e e t et  t et   t e t t t  t e  t e  t \n",
            " t e t elt e e t e e t t e t  t e e   t t   tt t t t es  t  t t e t t   t ett e e et t e e t et e  et  et  t t e t e  t  t es t t t et t e t t   t ett e e t e e t et  t et   t e t t t  t e  t e  t \n",
            " t e t elt   e t e e t t e t  t e e   t t   tt t t t es  t  t t e t e e t est   e et t e e t et e  et  et  t t e t e  t  t es t t t  t t e t e e t est   e t e e t et  t et   t e t t t  t e  t e  t \n",
            " t   t elt   e t e e t t e t  t e e   t t   tt t t t es  t  t t e t e e t elt   e et t e e t es e  et  et  t t e t e  t  t es t t t  t t e t e e t elt   e t e e t es  t es   t e t t t  t e  t e  t \n",
            " t   t elt   e t e e t t e t  t e e   t t   tt t t t es  t  t t e t e e t elt   e  t t e e t es e  et  et  t t e t e  t  t es t t t  t t e t e e t elt   e t e e t es  t es   t e t t t  t e  t e  t \n",
            " l e t elt   e t e e t t e t  t e e   t t   tt t t t er  t  t t e t e e t elt   e  t t e e t es e  et  et  t t e t e  t  t es t t t  t t e t e e t elt   e t e e t es  t es   t e t t t  t e  t e  t \n",
            " l e t elt   e t e e t t e t  t e e   t t   tt t t t er  t  t t e t e e t elt   e  t t e e t es e  et  tt  t t e t e  t  t es t t t  t t e t e e t elt   e t e e t es  t es   t e t t t  t e  t e  t \n",
            " l e t elt   e t e e t t e t  t e e a t t   tt t t t es  t  t t e t e e t elt   e  t t e e t es e  et  tt  t t e t e  t  t es t t t  t t e t e e t elt   e t e e t es  t es   t e t t t  t e  t er t \n",
            " l e t elt   e t e e t t e t  t e e e t t   tt t t t es  t  t t e t e e t elt   e et t e e t et e  et  tt  t t e t e et  t es t t t  t t e t e e t elt   e t e e t et  t et   t e t t t  t e  t er t \n",
            " l e t elt   e t e e t e e tr t e e e t t   tt t t t es  t  t t e t e e t elt   e et the e t et e  et  et  t t e t e et  t es t t t  t t e t e e t elt   e t e e t et  t et   t e t t t  the  t er t \n",
            " l e thelt   e the e t e e ts t t e e t t   tt t t thes  th t the t e   thelt   e et the e thes e  et  et  t t e t e et  t es t t th t the t e   thelt   e the e thes  t et   t ert t t  the  ther t \n",
            " l e thelt   e the e the e ts t t e e t t   tt t t thes  th t the t e   thelt   e et the e thes e  et  et  t t e t e et  thes t t th t the t e   thelt   e the e thes  thet   t ert t t  the  ther t \n",
            " l e thelt   e the e the a ts t t e e t t   tt t t thes  thet the t e   thelt   e et the e thes e  et  et  t t e t e etr thes t t th t the t e   thelt   e the e thes  thet   t ert t t  the  thes th\n",
            " l e thelt   e the e the a ts t t e e t t   tt t t thes  thet the t e   thelt   e  t the e thes e  et  et  t t e t e etr thes t t th t the t e   thelt   e the e thes  thet   t ert t t  the  thes th\n",
            " l e thelt   e the e the a ts t t e e t t   tt t t thes  thet the t e   thelt   e  t the e thes e  et  et  t t   t e etr thes t t th t the t e   thelt   e the e thes  thes   t ese t t  the  ther th\n",
            " e e thelt a e the e the a ts t t e e t t   tt t t thes  thet the t e   thelt a e  t the e thes e  et  et  t t   t e etr thes tht th t the t e   thelt a e the e thes  thts   t ere t t  the  ther th\n",
            " e e thelt are the e the a ts t t e e t t   tt t t thes  thet the t e e thelt are  t the e thes e  et  et  t t   t e et  thes tht th t the t e e thelt are the e thes  thts   there t t  the  ther th\n",
            " e e thelt are the e the a ts t t e e t t   tt t t thes  thet the t e e thelt are  t the e thes e  ut  et  t t   the et  thes tht th t the t e e thelt are the e thes  thes   there t th the  ther th\n",
            " e e thels are the e the a ts t t e e tht   tt t t ther  thet the t e e thelt are  t the e thes e  ut  ut  t t   the etr thes tht th t the t e e thelt are the e thes  thes   there t th the  ther th\n",
            " e e thels are the e tht a ts t t e e tht   tt t t ther  thet the t e e thelt are  t the e thes e  ut  ut  t t   the etr thes tht th t the t e e thelt are the e thes  thes   there t th the  ther th\n",
            " e e thels are the e tht a ts t t  re tht   tt t t ther  thet the t e e thels are at the e thes e  ut  ut  tat   the  tr thes tht th t the t e e thels are the e thes  t es   there t th the  ther th\n",
            " e e thels are the e tht a tl t t  rl tht   tt t t ther  th t the t e e thels are at the e thes e  ut  ut  tat   the  tr thes tht th t the t e e thels are the e thes  t es   t tre t th the  ther th\n",
            " l e thels are the e tht a tl t t arl tht   tt tht ther  th t the t e e thels are at there thes e  ut  ut  tat  ather tr thes tht th t the t e e thels are the e thes  t us   t tre t th the  ther th\n",
            " e e thels are there tht a tl t t are tht   tt tht ther  th t the t e e thels are at there thes e  ut  ut  tat  ather tr thes tht th t the t e e thels are there thes  t us   t tre t th the  ther th\n",
            " e e thels are there tht a ts t t are tht   tt tht ther  th t the t ere thels are at there thes e  ut  ut  tut  ather tr thes tht th t the t ere thels are there thes  t us   t tre t th the  thes th\n",
            " e e thels are there tht a ts t t are tht   ts tht ther  th t thert ere thels are at there thes e  ut  ut  tut  ather tr thes tht that thert ere thels are there thes  t us   t tre t th thi  thes th\n",
            " e e thels are there tht a tt t t are tht   ts tht ther  th t thertrere thlls are at there thes e  us  ut  tut  ather tr thes tht that thertrere thlls are there thes  t us   t tre t t  thi  thes th\n",
            " e e thlls are there tht a tt t t are tht   ts tht ther  th t thertrere thlls are at there thes e  us  ut  tut  ather tr thes tht that thertrere thlls are there thes  t us   t tre t t  thi  thes th\n",
            " e e thlls are there tht a tt t t are tht   ts tht ther  th t thertrere thlls are at there thes e  us  ut  tut aather tr thes tht that thertrere thlls are there thes  t us   t tre t t  thi  thes th\n",
            " e e thlls are there tht a ti t t are tht   ts uht ther  th t therurere tolls are at there thes e  us  ut  tat aatheretr thes tht that therurere tolls are there thes  t us   t uri t t  thi  thes th\n",
            " e e thlls are there tht a te t t are tot   ts uht ther  th t the urere t lls are at there thes e  us  ut  tat aatheretr thes tot that the urere t lls are there thes  t us   t uri t t  thi  thes to\n",
            " e e tolls are there tht a te t t are tot   ts uht ther  th t the trere t lls are at there thes e  us  ut  tat aatheretr thes tot that the trere t lls are there thes  t us   t ure t t  the  thes to\n",
            " e e tolls are there tht a te t t are tot r ts uht ther  th t the brere t lls are at there thes e  us  ut  tut aatheretr thes tot that the brere t lls are there thes  t us   t ure s t  the  thes to\n",
            " e e tolls are there tht a te t t are tot rots uht ther  th t the brere t lls are at there thes e  us  ut  tut aather tr thes tot that the brere t lls are there thes  t us   t ure s t  thl  thes to\n",
            " e e tolls are there tht a te t t ari tot lots uht ther  th t the brere t lls are at there thes e  us  ut  uut aather tr thes tat that the brere t lls are there thes  t us   t ure s t  thl  thes to\n",
            " e e tolls are there tht arte t t ari tht lats uht ther  th t the brere t lls are at there thes e  us  ut  uut aather tr thes tat that the brere t lls are there thes  t us   t uri s t  thl  thes ta\n",
            " ere talls are there tht arte t t ari tht lats uht ther  th t the brere talls are at there thes e  us  ut  uut aather tr thes tat that the brere talls are there thes  t us   t uri s t  thl  thes ta\n",
            " ere talls are there tht arte t t ari tht lats uht ther  th t the brere talls are at there thes e  us  ut  uut aather tr thes tat that the brere talls are there thes  t us   t urils t  thl  thes ta\n",
            " ere talls are there tht arte s t ari tht lats uht ther  that the brere talls are at there thes e  us  ut  but aather tr thes tat that the brere talls are there thes  t us  ot urils t  tol  thes ta\n",
            " ere talls are there tot a te s t ari tht lats uht ther  that the brere talls are at there thes e  us  ut  but aather tr thes tat that the brere talls are there theso t us  ot brils t  tol  thes ta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "8qUkbiw2t0Il",
        "outputId": "4641fd36-dbcb-42d5-b700-2a4b14cc0cf4"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' ere talls are there tot a te s t ari tht lats uht ther  that the brere talls are at there thes e  us  ut  but aather tr thes tat that the brere talls are there theso t us  ot brils t  tol  thes ta'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과가 어떤가요?? 마지막 에폭의 문장이 그럴싸한가요?"
      ],
      "metadata": {
        "id": "PkIzDTdyvTHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task2\n",
        "\n",
        "위 sentence는 제가 임의로 생성한 문장들입니다.\n",
        "\n",
        "마음에 드시는 문구 가져오셔서 문장이 어떻게 생성되는지 확인해보세요!\n",
        "\n",
        "영어가 아닌 한국어로 시도해보는 것도 좋겠죠?\n",
        "\n",
        "수정이 많이 필요(토큰화 등) 할 수 있으나 한번 시도해보시는 것 권장드립니다 :)\n",
        "\n",
        "위 베이스라인은 어디든 수정하셔도 좋고 조금 더 자연스러운 문장이 나올 수 있게 다양한 시도를 해보세요!\n",
        "\n",
        "조건 : 문장 3개 이상, 연결성이 있는 문장을 \" \" 으로 구분하여 ( )에 넣기"
      ],
      "metadata": {
        "id": "kN1zL8Dpvane"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "과제 전체 참고 링크\n",
        "\n",
        "https://wikidocs.net/64517\n",
        "\n",
        "https://mr-doosun.tistory.com/25"
      ],
      "metadata": {
        "id": "WfI17tolPJlw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. 불용어처리 + baseline"
      ],
      "metadata": {
        "id": "ceM93HQ6maLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = (\"배가 고프다\"\n",
        "            \"그래서 김치찌개를 먹을 것이다\"\n",
        "            \"김치찌개랑 밥이랑 계란을 같이 먹어야지\")"
      ],
      "metadata": {
        "id": "IKp-lKrjvXR9"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "world_set = list(set(sentence))\n",
        "vocab = {char: idx for idx, char in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "knUH9goxOmBX"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8VtKU-QO0EC",
        "outputId": "2d3344ba-d0ab-4e26-b058-2390de4e0e1c"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'먹': 0, '고': 1, '치': 2, '을': 3, '계': 4, '프': 5, '개': 6, '란': 7, '야': 8, '를': 9, '같': 10, '이': 11, '어': 12, '찌': 13, '서': 14, '가': 15, '배': 16, '다': 17, '것': 18, '그': 19, '김': 20, '밥': 21, ' ': 22, '래': 23, '랑': 24, '지': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "적절하지 않음 -> 형태소 토큰화"
      ],
      "metadata": {
        "id": "Em18j0UXPG84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1Um8V_Nh2Z_",
        "outputId": "9e980fbc-8187-4bc0-b866-c9325dde1986"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy\n",
        "!pip install mecab-python\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rKkYGp3PPco",
        "outputId": "f6a0d68c-46db-411e-c711-636256a54f4c"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.5.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
            "Requirement already satisfied: mecab-python in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.10/dist-packages (from mecab-python) (1.0.8)\n",
            "mecab-ko is already installed\n",
            "mecab-ko-dic is already installed\n",
            "mecab-python is already installed\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "tokenizer = Mecab()\n",
        "print(tokenizer.morphs(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_f1MfMEPR0Q",
        "outputId": "e682c81d-18f3-4ee3-a6d7-0bd6dbab18a3"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '가', '고프', '다', '그래서', '김치찌개', '를', '먹', '을', '것', '이', '다', '김치찌개', '랑', '밥', '이랑', '계란', '을', '같이', '먹', '어야지']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer.morphs(sentence)"
      ],
      "metadata": {
        "id": "Lkjtqzrvg9Bo"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 정의\n",
        "stopwords=['가','다','를','을','이','다','랑','이랑','어야지','']"
      ],
      "metadata": {
        "id": "cuj_I3brULKM"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = [word for word in tokenized if word not in stopwords] #불용어 제거"
      ],
      "metadata": {
        "id": "EoylQIeTRLZT"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNRcDjtbUZk_",
        "outputId": "fbed0073-1b31-436e-bd2b-311be1fa331d"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '고프', '그래서', '김치찌개', '먹', '것', '김치찌개', '밥', '계란', '같이', '먹']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어 집합 생성\n",
        "word_to_idx = {word: idx for idx, word in enumerate(set(tokenized))} #tokenized에 포함된 단어들을중복 제거 -> 단어를 key, 인덱스를 값으로 사용하여 매핑\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()} #word to idx 키와 값 순서 바꿔서 변환 매핑"
      ],
      "metadata": {
        "id": "q5n7k5R5QODM"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 생성\n",
        "input= []\n",
        "target = []\n",
        "\n",
        "sequence_length = 3 #문장이 짧아서 짧게 설정\n",
        "learning_rate = 0.01\n",
        "vocab_size = len(word_to_idx)\n",
        "hidden_size = vocab_size\n",
        "\n",
        "for i in range(len(tokenized) - sequence_length):\n",
        "  input_seq = tokenized[i:i+sequence_length]\n",
        "  target_seq = tokenized[i+1:i+sequence_length+1]\n",
        "\n",
        "  input.append([word_to_idx[word] for word in input_seq])\n",
        "  target.append([word_to_idx[word] for word in target_seq])"
      ],
      "metadata": {
        "id": "7uqH1dszWCsa"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.array(input)\n",
        "target = np.array(target)\n",
        "\n",
        "#one-hot encoding\n",
        "def one_hot_encoding(data,num_classes):\n",
        "  num_data = data.shape[0]\n",
        "  num_seq = data.shape[1]\n",
        "  one_hot = np.zeros((num_data,num_seq,num_classes), dtype=np.float32)\n",
        "  for i in range(num_data):\n",
        "    for j in range(num_seq):\n",
        "      one_hot[i,j,data[i,j]] = 1\n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "iFUwbHIEVkWi"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = one_hot_encoding(input, vocab_size)\n",
        "\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(target)"
      ],
      "metadata": {
        "id": "bzEVEKLDk2h7"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dooVU3VHlKml",
        "outputId": "df784aa8-5299-49b2-f6f0-993093c0eb8e"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN (맨 위 베이스라인 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn1 = torch.nn.RNN(input_size=input_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.rnn2 = torch.nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn1(x)\n",
        "        out, _ = self.rnn2(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "YOSCop9-lN5L"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2) #layer=2개"
      ],
      "metadata": {
        "id": "3-ei-AbNlgT9"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "v4pyk_K_l4N6"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5CTsXFTl-CH",
        "outputId": "757ce86e-c7ae-41b7-98fd-eafa3100c1f2"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    loss = criterion(outputs.view(-1, vocab_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwQzqecqmCWB",
        "outputId": "d93b723b-06ad-45c7-a454-eefa69ca3b0f"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야개야야\n",
            "야개야야야야먹개야먹\n",
            "야개야먹야야먹개야먹\n",
            "프개야먹야야먹개야먹\n",
            "프개야먹먹야먹개야먹\n",
            "프란야먹먹야먹개야먹\n",
            "프란야먹먹야프개야먹\n",
            "프란야먹먹야프개야먹\n",
            "프란야먹먹야프개야먹\n",
            "프란야먹프야프개야먹\n",
            "프란야먹프야프개야먹\n",
            "프란야먹개야프개야먹\n",
            "프란야먹개야프개야먹\n",
            "프란야먹개야프개야먹\n",
            "프란야먹개야프개을먹\n",
            "계란야먹개야프개을먹\n",
            "계란야먹개야프개을먹\n",
            "계란야먹개야프개을먹\n",
            "계란야먹개야프개을먹\n",
            "계란야먹개야프개을먹\n",
            "계란야먹개야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HMIYgGBymPon",
        "outputId": "9815420c-1cbe-417a-d884-5e2b3ae03eca"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'계란야먹치야프개을먹'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "불용어 처리를 안하고 해보자."
      ],
      "metadata": {
        "id": "975-ZvUtmTvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. 불용어 X + baseline"
      ],
      "metadata": {
        "id": "DZVACSdDmkQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = (\"배가 고프다\"\n",
        "            \"그래서 김치찌개를 먹을 것이다\"\n",
        "            \"김치찌개랑 밥이랑 계란을 같이 먹어야지\")"
      ],
      "metadata": {
        "id": "YdelTp4bmkQj"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "world_set = list(set(sentence))\n",
        "vocab = {char: idx for idx, char in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "t3xGyNKamkQk"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f72816e-7cfc-40f3-9d70-a567aebbb929",
        "id": "kc5c-I51mkQk"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'먹': 0, '고': 1, '치': 2, '을': 3, '계': 4, '프': 5, '개': 6, '란': 7, '야': 8, '를': 9, '같': 10, '이': 11, '어': 12, '찌': 13, '서': 14, '가': 15, '배': 16, '다': 17, '것': 18, '그': 19, '김': 20, '밥': 21, ' ': 22, '래': 23, '랑': 24, '지': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "적절하지 않음 -> 형태소 토큰화"
      ],
      "metadata": {
        "id": "L4ktzEAqmkQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "tokenizer = Mecab()\n",
        "print(tokenizer.morphs(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78d0d75-83f8-4645-fc0f-626dce6d6e5f",
        "id": "uT9xbNCemkQm"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '가', '고프', '다', '그래서', '김치찌개', '를', '먹', '을', '것', '이', '다', '김치찌개', '랑', '밥', '이랑', '계란', '을', '같이', '먹', '어야지']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer.morphs(sentence)"
      ],
      "metadata": {
        "id": "GxWgmUtMmkQm"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea2376ae-4e07-4f0c-8413-562f08541cab",
        "id": "x83a-GWumkQo"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '가', '고프', '다', '그래서', '김치찌개', '를', '먹', '을', '것', '이', '다', '김치찌개', '랑', '밥', '이랑', '계란', '을', '같이', '먹', '어야지']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어 집합 생성\n",
        "word_to_idx = {word: idx for idx, word in enumerate(set(tokenized))} #tokenized에 포함된 단어들을중복 제거 -> 단어를 key, 인덱스를 값으로 사용하여 매핑\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()} #word to idx 키와 값 순서 바꿔서 변환 매핑"
      ],
      "metadata": {
        "id": "0-mUDV99mkQp"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 생성\n",
        "input= []\n",
        "target = []\n",
        "\n",
        "sequence_length = 3 #문장이 짧아서 짧게 설정\n",
        "learning_rate = 0.01\n",
        "vocab_size = len(word_to_idx)\n",
        "hidden_size = vocab_size\n",
        "\n",
        "for i in range(len(tokenized) - sequence_length):\n",
        "  input_seq = tokenized[i:i+sequence_length]\n",
        "  target_seq = tokenized[i+1:i+sequence_length+1]\n",
        "\n",
        "  input.append([word_to_idx[word] for word in input_seq])\n",
        "  target.append([word_to_idx[word] for word in target_seq])"
      ],
      "metadata": {
        "id": "FbOUsYy9mkQp"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.array(input)\n",
        "target = np.array(target)\n",
        "\n",
        "#one-hot encoding\n",
        "def one_hot_encoding(data,num_classes):\n",
        "  num_data = data.shape[0]\n",
        "  num_seq = data.shape[1]\n",
        "  one_hot = np.zeros((num_data,num_seq,num_classes), dtype=np.float32)\n",
        "  for i in range(num_data):\n",
        "    for j in range(num_seq):\n",
        "      one_hot[i,j,data[i,j]] = 1\n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "hla4R_P1mkQp"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = one_hot_encoding(input, vocab_size)\n",
        "\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(target)"
      ],
      "metadata": {
        "id": "3Dq5wO8DmkQq"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c2b9c1-1394-43a4-f954-bcecfcbf5e1d",
        "id": "K6-KLV8MmkQq"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN (맨 위 베이스라인 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn1 = torch.nn.RNN(input_size=input_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.rnn2 = torch.nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn1(x)\n",
        "        out, _ = self.rnn2(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "PMSmGBS6mkQq"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2) #layer=2개"
      ],
      "metadata": {
        "id": "KPWpzccpmkQr"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "sUB9GAP4mkQr"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f826b81-a10c-40c4-9324-c0b765e53c55",
        "id": "LkK15CkVmkQr"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([18, 3, 17])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    loss = criterion(outputs.view(-1, vocab_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ddbc67-4f6f-4813-af5a-99ea38d6372f",
        "id": "nNW_CJnMmkQs"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "를를를를를를를를를를를를를를를를를를를를\n",
            "를를를를를를를를를를를를를를를를를를를를\n",
            "를배배배배배배배배배배배배배배배배배배배\n",
            "배배배배배배배배배배배배배배배배배배배배\n",
            "배배배배배배배배배배배배배배배배배배배배\n",
            "배배배배배배배배배배배배배배배배배배배배\n",
            "배배배배배배배배배배을배배배배배배배고을\n",
            "배고을배배배을배배고을배배을배을배배고을\n",
            "배고을배을배을배배고을배고을배을배고고을\n",
            "배고을배을고을배배고을배이을배을배고고을\n",
            "을고을배을배을배배고을배이을배을배고고을\n",
            "을고을배이배을배배프을배이을배을배고고을\n",
            "을고를배이배을배계프을배프을배를배고고을\n",
            "을란를같배배고배계프을배프을배를배고고을\n",
            "을란을같배어고배계프을배프을배를배개고을\n",
            "을란을같배어고배계프을배프을배를배개고을\n",
            "을란을같이어고배계프을배프을찌를배개고을\n",
            "을란을같이어고배계프을배프을찌를배개고을\n",
            "을란을같이어고배계프을배프을찌를배개고을\n",
            "을란을같이어고배계프을배프을찌를배개고을\n",
            "을란을같이어고배계프을배프을찌를배개고을\n",
            "을란을같이어고배계프을배프을찌를배개고을\n",
            "을란을같이어고배계프을배프을찌를배개고을\n",
            "을란을같이어고배계프을이프을찌를배개고을\n",
            "을란을같이어고배계프을이프야찌를배개고을\n",
            "을란을같이어고배계프을이가야찌를배개고을\n",
            "을란을같이어고배계프을이가야찌를배개고을\n",
            "을란을같이어고배계프을이가야찌를배개고을\n",
            "을란을같이어고배계프을이가야찌를배개고을\n",
            "을란을같이어고배계프을이가야찌를배개고을\n",
            "을란을같이어고배계프을이가야찌를배개고을\n",
            "을란을같이어고배계프을이가야찌를배개고을\n",
            "을란을같이어고배계프을이가야찌를배개고을\n",
            "을란을같이어고배계프을이가야찌를배개고을\n",
            "먹란을같이어고배계프을이가야찌를배개고을\n",
            "먹란을같이어고배계프을이가야찌를배개고을\n",
            "먹란을같이어고배계프을이가야찌를배개고을\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9ed9c964-b50b-40a0-b8cd-b342e4798c76",
        "id": "JjBT7jUqmkQt"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'먹란을같이어고배계프을이가야찌를배개고서'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. 불용어처리 + baseline 수정 + sequence length 늘림"
      ],
      "metadata": {
        "id": "IGnhIoe8nQor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = (\"배가 고프다\"\n",
        "            \"그래서 김치찌개를 먹을 것이다\"\n",
        "            \"김치찌개랑 밥이랑 계란을 같이 먹어야지\")"
      ],
      "metadata": {
        "id": "9gylqjFUnQo-"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "world_set = list(set(sentence))\n",
        "vocab = {char: idx for idx, char in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "eJ1YOFPcnQo_"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e2cc693-38ed-4031-ad50-df171e923fe1",
        "id": "PlGz4hwDnQo_"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'먹': 0, '고': 1, '치': 2, '을': 3, '계': 4, '프': 5, '개': 6, '란': 7, '야': 8, '를': 9, '같': 10, '이': 11, '어': 12, '찌': 13, '서': 14, '가': 15, '배': 16, '다': 17, '것': 18, '그': 19, '김': 20, '밥': 21, ' ': 22, '래': 23, '랑': 24, '지': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "적절하지 않음 -> 형태소 토큰화"
      ],
      "metadata": {
        "id": "1dpdflTonQpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "tokenizer = Mecab()\n",
        "print(tokenizer.morphs(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a5e135c-828e-4012-aad9-b4ee824403a5",
        "id": "bTIsqyH4nQpA"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '가', '고프', '다', '그래서', '김치찌개', '를', '먹', '을', '것', '이', '다', '김치찌개', '랑', '밥', '이랑', '계란', '을', '같이', '먹', '어야지']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer.morphs(sentence)"
      ],
      "metadata": {
        "id": "T9kxyN3znQpB"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 정의\n",
        "stopwords=['가','다','를','을','이','다','랑','이랑','어야지','']"
      ],
      "metadata": {
        "id": "wbJxEDShnQpB"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = [word for word in tokenized if word not in stopwords] #불용어 제거"
      ],
      "metadata": {
        "id": "wOz5K_4OnQpB"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a7206a-b4dd-488f-9776-7c1f129b4fcd",
        "id": "1CAMDfLonQpB"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '고프', '그래서', '김치찌개', '먹', '것', '김치찌개', '밥', '계란', '같이', '먹']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어 집합 생성\n",
        "word_to_idx = {word: idx for idx, word in enumerate(set(tokenized))} #tokenized에 포함된 단어들을중복 제거 -> 단어를 key, 인덱스를 값으로 사용하여 매핑\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()} #word to idx 키와 값 순서 바꿔서 변환 매핑"
      ],
      "metadata": {
        "id": "24s2IddxnQpC"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 생성\n",
        "input= []\n",
        "target = []\n",
        "\n",
        "sequence_length = 5 #문장이 짧아서 짧게 설정 -> 늘려줌\n",
        "learning_rate = 0.01\n",
        "vocab_size = len(word_to_idx)\n",
        "hidden_size = vocab_size\n",
        "\n",
        "for i in range(len(tokenized) - sequence_length):\n",
        "  input_seq = tokenized[i:i+sequence_length]\n",
        "  target_seq = tokenized[i+1:i+sequence_length+1]\n",
        "\n",
        "  input.append([word_to_idx[word] for word in input_seq])\n",
        "  target.append([word_to_idx[word] for word in target_seq])"
      ],
      "metadata": {
        "id": "ejy3y1JKnQpC"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.array(input)\n",
        "target = np.array(target)\n",
        "\n",
        "#one-hot encoding\n",
        "def one_hot_encoding(data,num_classes):\n",
        "  num_data = data.shape[0]\n",
        "  num_seq = data.shape[1]\n",
        "  one_hot = np.zeros((num_data,num_seq,num_classes), dtype=np.float32)\n",
        "  for i in range(num_data):\n",
        "    for j in range(num_seq):\n",
        "      one_hot[i,j,data[i,j]] = 1\n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "unUgS6GbnQpD"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = one_hot_encoding(input, vocab_size)\n",
        "\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(target)"
      ],
      "metadata": {
        "id": "dzl6DyHlnQpD"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a27fb96-1441-4132-f1a7-76e82f7dea90",
        "id": "iVoj6MYZnQpD"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN (맨 위 베이스라인 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn1 = torch.nn.RNN(input_size=input_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.rnn2 = torch.nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.rnn3 = torch.nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn1(x)\n",
        "        out, _ = self.rnn2(out)\n",
        "        out, _ = self.rnn3(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "OJFCmd6TnQpE"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 3) #layer=3개"
      ],
      "metadata": {
        "id": "nFrw_w6unQpE"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "gfR_xWWAnQpE"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "264cf329-5a15-4dcc-ed7d-ffcdb6c2f817",
        "id": "Vh0YJmkKnQpE"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 5, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    loss = criterion(outputs.view(-1, vocab_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b6f2a4b-b7ed-433b-bcdc-e22d01905800",
        "id": "vqXVPPFlnQpF"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "프고고고고고고고고고\n",
            "프야야야고고고고고고\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야먹야야먹야\n",
            "야야치먹치야야야먹야\n",
            "야야치먹치야야치야야\n",
            "치야치먹치야야치야먹\n",
            "치야치먹치야야치야먹\n",
            "치야치먹치야야치야먹\n",
            "치먹치먹치야먹개야먹\n",
            "치먹치먹치야야개야먹\n",
            "치먹치먹치야야개야먹\n",
            "치먹치먹치야먹개야먹\n",
            "치먹치먹치야먹개야먹\n",
            "치먹치먹치야프개야먹\n",
            "치먹치먹치야프개야먹\n",
            "야먹치먹치야프개개먹\n",
            "야먹치먹치야프개야먹\n",
            "야먹치먹치야프개개먹\n",
            "야먹치먹치야프개개먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야프치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야프치먹치야프개을먹\n",
            "야프치먹치야프개을먹\n",
            "야프치먹치야프개을먹\n",
            "야먹치먹치야프개을먹\n",
            "야란치먹치야프개을먹\n",
            "야란치먹치야프개을먹\n",
            "야란치먹치야프개을먹\n",
            "야프치먹치야프개을먹\n",
            "야프치먹치야프개을먹\n",
            "야프치먹치야프개을먹\n",
            "야란치먹치야프개을먹\n",
            "야란치먹치야프개을먹\n",
            "야란치먹치야프개을먹\n",
            "야란치먹치야프개을먹\n",
            "야프치먹치야프개을먹\n",
            "야프치먹치야프개을먹\n",
            "야란치먹치야프개을먹\n",
            "야란치먹치야프개을먹\n",
            "야란치먹치야프개을먹\n",
            "야란치먹치야프개을먹\n",
            "야프치먹치야프개을먹\n",
            "야프치먹치야프개을먹\n",
            "야란치먹치야프개을먹\n",
            "야란치먹치야프개을먹\n",
            "야란치먹치야프개을먹\n",
            "야프치먹치야프개을먹\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bb4e6f03-5259-4980-ce80-603da5f12696",
        "id": "OFIvjgqJnQpF"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'야프치먹치야프개을먹'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. 불용어X + baseline 수정 + sequence length 늘림"
      ],
      "metadata": {
        "id": "arJ421ploHJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = (\"배가 고프다\"\n",
        "            \"그래서 김치찌개를 먹을 것이다\"\n",
        "            \"김치찌개랑 밥이랑 계란을 같이 먹어야지\")"
      ],
      "metadata": {
        "id": "nd80_aoYoHJ4"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "world_set = list(set(sentence))\n",
        "vocab = {char: idx for idx, char in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "jv7-AOgloHJ4"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf30c62-3468-47e5-a02a-71c3b9f462e9",
        "id": "NPZTwn4zoHJ4"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'먹': 0, '고': 1, '치': 2, '을': 3, '계': 4, '프': 5, '개': 6, '란': 7, '야': 8, '를': 9, '같': 10, '이': 11, '어': 12, '찌': 13, '서': 14, '가': 15, '배': 16, '다': 17, '것': 18, '그': 19, '김': 20, '밥': 21, ' ': 22, '래': 23, '랑': 24, '지': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "적절하지 않음 -> 형태소 토큰화"
      ],
      "metadata": {
        "id": "BgnpxWxioHJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "tokenizer = Mecab()\n",
        "print(tokenizer.morphs(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e4c2557-1fc8-4aaa-fff6-249cfd501241",
        "id": "VxL-FrOloHJ5"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '가', '고프', '다', '그래서', '김치찌개', '를', '먹', '을', '것', '이', '다', '김치찌개', '랑', '밥', '이랑', '계란', '을', '같이', '먹', '어야지']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer.morphs(sentence)"
      ],
      "metadata": {
        "id": "OiPYP9xJoHJ5"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2964c8f2-914a-468f-ec3f-3cc620d44090",
        "id": "uQzGSBsroHJ5"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '가', '고프', '다', '그래서', '김치찌개', '를', '먹', '을', '것', '이', '다', '김치찌개', '랑', '밥', '이랑', '계란', '을', '같이', '먹', '어야지']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어 집합 생성\n",
        "word_to_idx = {word: idx for idx, word in enumerate(set(tokenized))} #tokenized에 포함된 단어들을중복 제거 -> 단어를 key, 인덱스를 값으로 사용하여 매핑\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()} #word to idx 키와 값 순서 바꿔서 변환 매핑"
      ],
      "metadata": {
        "id": "aRGEoqw-oHJ6"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 생성\n",
        "input= []\n",
        "target = []\n",
        "\n",
        "sequence_length = 5 #문장이 짧아서 짧게 설정 -> 늘려줌\n",
        "learning_rate = 0.01\n",
        "vocab_size = len(word_to_idx)\n",
        "hidden_size = vocab_size\n",
        "\n",
        "for i in range(len(tokenized) - sequence_length):\n",
        "  input_seq = tokenized[i:i+sequence_length]\n",
        "  target_seq = tokenized[i+1:i+sequence_length+1]\n",
        "\n",
        "  input.append([word_to_idx[word] for word in input_seq])\n",
        "  target.append([word_to_idx[word] for word in target_seq])"
      ],
      "metadata": {
        "id": "TSH9ESZPoHJ6"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.array(input)\n",
        "target = np.array(target)\n",
        "\n",
        "#one-hot encoding\n",
        "def one_hot_encoding(data,num_classes):\n",
        "  num_data = data.shape[0]\n",
        "  num_seq = data.shape[1]\n",
        "  one_hot = np.zeros((num_data,num_seq,num_classes), dtype=np.float32)\n",
        "  for i in range(num_data):\n",
        "    for j in range(num_seq):\n",
        "      one_hot[i,j,data[i,j]] = 1\n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "2WBwwAgdoHJ6"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = one_hot_encoding(input, vocab_size)\n",
        "\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(target)"
      ],
      "metadata": {
        "id": "fhaEatpRoHJ6"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08fa1c6-a24d-4864-a7be-f1fb26f3e488",
        "id": "VS6Ze5_qoHJ6"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN (맨 위 베이스라인 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn1 = torch.nn.RNN(input_size=input_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.rnn2 = torch.nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.rnn3 = torch.nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn1(x)\n",
        "        out, _ = self.rnn2(out)\n",
        "        out, _ = self.rnn3(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "wtN9KKWCoHJ7"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 3) #layer=3개"
      ],
      "metadata": {
        "id": "mpoMWZo5oHJ7"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "n3IPkt5OoHJ7"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99a8129b-2d8c-4f08-a035-079a9847dbe4",
        "id": "1xkUwNaWoHJ7"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 5, 17])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    loss = criterion(outputs.view(-1, vocab_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e29077-6552-4026-b6d0-e171996b17ad",
        "id": "rFMzREKyoHJ8"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "란가을을을을을을을을을을을을을을을을을을\n",
            "을을을을을을을을을을을을을을을을을을을을\n",
            "을을이이이이이이이이이이이이이이이이이이\n",
            "을을이이이이이이이이이이이이이이이이이이\n",
            "을이이이이이이이이이이이이이이이이이이이\n",
            "을이이이이이이이이이이이이이이이이이이이\n",
            "이이이이이이이이이이이이이이이이이이이이\n",
            "이이이배배배이배배배이배배이배배배배배배\n",
            "이이이배배배고배배배이배배고배배배고이배\n",
            "이이이이이배고배배고이이배고배배배고고이\n",
            "을이이이이배고배배고이이배고배배배고고이\n",
            "을을을이이배고배배고을이배고배배배고고을\n",
            "을을을이이배고배고고을이배야배배배고고을\n",
            "을을을이이배야배야을을이배야배를배고고을\n",
            "을을을이이배야배야을을이배야배를배개개을\n",
            "을을을이이배야배야을을이배야배를배개개을\n",
            "을을을이이배야배야을을이배야배를배개개을\n",
            "을을을이이배야배야을을이배야배를배개개을\n",
            "을을을이이배야배야을을이배야배를배개고을\n",
            "을을을이이어야배를을을이어야배를배개고을\n",
            "을을을이이배야배를을을이어야배를배개고을\n",
            "을을을이이어야배를을을이어야배를배개고을\n",
            "을을을이이어야배를프을이어야배를배개고을\n",
            "을을을이이어야배계프을이어야배를배개고을\n",
            "을을을이이어야배계프을이어야배를배개고야\n",
            "을을을이이어야배계프을이어야배를배개고을\n",
            "을을을이이어야배계프을이어야배를배개고을\n",
            "을을을이이어고배계프을이가야배를배개고고\n",
            "을을을이이가고배계프을이가야배를배개고을\n",
            "을을을이이가고배계프을이가야배를배개고을\n",
            "을을을이이가고배계프을이가야배를배개고고\n",
            "을을을이이가고배계프을이가야배를배개고고\n",
            "을을을이이가고배계프을이가야배를배개고을\n",
            "을을을이이가고배계프을이가야배를배개고을\n",
            "을을을이이가고배계프을이가야배를배개고고\n",
            "을을을이이가고배계프을이가야찌를배개고고\n",
            "을을을이이어고배계프을이가야찌를배개고을\n",
            "을을을이이어고배계프을이가야찌를배개고서\n",
            "을을을이이어고배계프을이가야찌를배개고고\n",
            "을을을이이어고배계프을이가야찌를배개고고\n",
            "을을을이이어고배계프을이가야찌를배개고고\n",
            "을을을이이어고배계프을이어야찌를배개고서\n",
            "을을을같이어고배계프을이어야찌를배개고서\n",
            "을을을같이어고배계프을이어야찌를배개고서\n",
            "을을을이이어고배계프을이어야찌를배개고서\n",
            "야을을같이어고배계프을이가야찌를배개고서\n",
            "야을을같이어고배계프을이가야찌를배개고서\n",
            "을을을같이어고배계프을이가야찌를배개고서\n",
            "을을을같이가고배계프을이가야찌를배개고서\n",
            "을을을같이가고배계프을이가야찌를배개고서\n",
            "을을을같이가고배계프을이가야찌를배개고서\n",
            "을을을같이가고배계프을이가야찌를배개고서\n",
            "을을을같이가고배계프을이가야찌를배개고서\n",
            "야을을같이어고배계프을이가야찌를배개고서\n",
            "야을을같이어고배계프을이가야찌를배개고서\n",
            "야을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란을을같이어고배계프을이가야찌를배개고서\n",
            "란란을같이어고배계프을이가야찌를배개고서\n",
            "란란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n",
            "먹란을같이어고배계프을이가야찌를배개고서\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "da4b1823-413f-442f-8e58-8f387fc7e224",
        "id": "NBc9eF5DoHJ8"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'먹란을같이어고배계프을이가야찌를배개고서'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. 불용어X + baseline 수정 + sequence length 늘림 + lr 0.05"
      ],
      "metadata": {
        "id": "Snd7LY6hodKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = (\"배가 고프다\"\n",
        "            \"그래서 김치찌개를 먹을 것이다\"\n",
        "            \"김치찌개랑 밥이랑 계란을 같이 먹어야지\")"
      ],
      "metadata": {
        "id": "7-94h6SyodLB"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "world_set = list(set(sentence))\n",
        "vocab = {char: idx for idx, char in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "lLVgQyyOodLB"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74be714a-7019-43ba-f93e-ca6d5982402f",
        "id": "yBSXt1lBodLC"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'먹': 0, '고': 1, '치': 2, '을': 3, '계': 4, '프': 5, '개': 6, '란': 7, '야': 8, '를': 9, '같': 10, '이': 11, '어': 12, '찌': 13, '서': 14, '가': 15, '배': 16, '다': 17, '것': 18, '그': 19, '김': 20, '밥': 21, ' ': 22, '래': 23, '랑': 24, '지': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "적절하지 않음 -> 형태소 토큰화"
      ],
      "metadata": {
        "id": "Ys1W-_6kodLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "tokenizer = Mecab()\n",
        "print(tokenizer.morphs(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15da60a8-2ec9-4f25-adb2-6092f69a23c8",
        "id": "Nrhjoi4SodLC"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '가', '고프', '다', '그래서', '김치찌개', '를', '먹', '을', '것', '이', '다', '김치찌개', '랑', '밥', '이랑', '계란', '을', '같이', '먹', '어야지']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer.morphs(sentence)"
      ],
      "metadata": {
        "id": "T0yUnV8TodLD"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c2eb328-9877-40be-c00c-ec1098efafa2",
        "id": "-tI3AHxpodLD"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '가', '고프', '다', '그래서', '김치찌개', '를', '먹', '을', '것', '이', '다', '김치찌개', '랑', '밥', '이랑', '계란', '을', '같이', '먹', '어야지']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어 집합 생성\n",
        "word_to_idx = {word: idx for idx, word in enumerate(set(tokenized))} #tokenized에 포함된 단어들을중복 제거 -> 단어를 key, 인덱스를 값으로 사용하여 매핑\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()} #word to idx 키와 값 순서 바꿔서 변환 매핑"
      ],
      "metadata": {
        "id": "Nf4kEVEPodLD"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 생성\n",
        "input= []\n",
        "target = []\n",
        "\n",
        "sequence_length = 5 #문장이 짧아서 짧게 설정 -> 늘려줌\n",
        "learning_rate = 0.05\n",
        "vocab_size = len(word_to_idx)\n",
        "hidden_size = vocab_size\n",
        "\n",
        "for i in range(len(tokenized) - sequence_length):\n",
        "  input_seq = tokenized[i:i+sequence_length]\n",
        "  target_seq = tokenized[i+1:i+sequence_length+1]\n",
        "\n",
        "  input.append([word_to_idx[word] for word in input_seq])\n",
        "  target.append([word_to_idx[word] for word in target_seq])"
      ],
      "metadata": {
        "id": "2596P9HZodLE"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.array(input)\n",
        "target = np.array(target)\n",
        "\n",
        "#one-hot encoding\n",
        "def one_hot_encoding(data,num_classes):\n",
        "  num_data = data.shape[0]\n",
        "  num_seq = data.shape[1]\n",
        "  one_hot = np.zeros((num_data,num_seq,num_classes), dtype=np.float32)\n",
        "  for i in range(num_data):\n",
        "    for j in range(num_seq):\n",
        "      one_hot[i,j,data[i,j]] = 1\n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "K3xYtQo0odLE"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = one_hot_encoding(input, vocab_size)\n",
        "\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(target)"
      ],
      "metadata": {
        "id": "8tnawKc7odLE"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2adee1c4-c7cb-4c7b-fd10-d49a61e663d0",
        "id": "4UYJJga9odLE"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN (맨 위 베이스라인 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn1 = torch.nn.RNN(input_size=input_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.rnn2 = torch.nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.rnn3 = torch.nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn1(x)\n",
        "        out, _ = self.rnn2(out)\n",
        "        out, _ = self.rnn3(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "bwPwnKU7odLF"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 3) #layer=3개"
      ],
      "metadata": {
        "id": "NwjwJVr_odLF"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "rgjI-3XYodLG"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8d1a5bb-0265-483f-df70-51c666bc37ab",
        "id": "18nTKse_odLG"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 5, 17])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    loss = criterion(outputs.view(-1, vocab_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "218e040e-e38c-4906-ae59-f72828a170e5",
        "id": "5p1E1J7DodLG"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "을을을을을을을을을을을을을을을을을을을을\n",
            "을을이를를이를이이를이를이이를이이이이이\n",
            "을을이이이이이이이이이이이이이이이이이이\n",
            "배이고고고고고고고고고고고고고고고고고고\n",
            "배배배배배배배배배배배배배배배배배배배배\n",
            "배배배배배배배배배배배배배배배배배배배배\n",
            "를배배이이이이이이이이이이이이이이이이이\n",
            "을을이이이이이이이이이이이이이이이이이이\n",
            "을이이이이고이이이이이이이이이이이이이이\n",
            "을이을를이고고고을이고이고고을을이이고을\n",
            "이이배를이고고고을이을이고고배을이고고을\n",
            "을이을을이배고을을이을이고을배을이고고을\n",
            "을이을을이배이을이배이이고이배이배고을을\n",
            "을이찌을이배이배이찌을이가찌을을이가고찌\n",
            "을이찌을이가고찌이찌을이가고찌을이이가찌\n",
            "을이가찌을이고찌계찌을이이고찌찌을이가찌\n",
            "을이프을이가고프계프을이이고프을이이가찌\n",
            "을이프을이야고프을이을이가찌프을이가고찌\n",
            "을이배를이가고프를배를이가고서를이이가서\n",
            "을이배를이개고프를배를배이어서를배이어서\n",
            "을이배를이어고배를배를이가고서를이가고서\n",
            "을란찌을이어고배를배를이어고서를배개어서\n",
            "을란찌를이어고찌계배을이가어찌를배개어찌\n",
            "을이찌을이어고찌계배을이어고찌를배개어찌\n",
            "을가찌을이어고배고배을이어고찌을배개어찌\n",
            "을가배을이어고배계배을이어고배을배개어찌\n",
            "을가배을이어고배계배을이어고배을배개어서\n",
            "을이어을이어고배계배을이어고배를배개어서\n",
            "을이어을이어고배계배을이가고배를배개가서\n",
            "어계프을이어고배계배을이가고찌를배개가서\n",
            "야야찌을이어계배계배을이가고찌를배개가찌\n",
            "가야찌을이가고배계배을이가고찌를배개가찌\n",
            "가야찌을이가고배계프을이가고찌를배개가찌\n",
            "란고배같이어고배계프계이가고찌배배개가찌\n",
            "이고찌같이어고배이배을이가고찌배배이가찌\n",
            "이이배같이어고배이프을이가고배같배개가찌\n",
            "이이배을이가고프고프을이가고배같배개가서\n",
            "이배을배개가이프고프을이가야찌를이가가서\n",
            "이고찌를이가계프고프을이가야서를배개가서\n",
            "이어찌를이고야찌이프을배개고서를배이고서\n",
            "을어서를을이야찌계이찌같배이야어을배이야\n",
            "을어찌을이어야찌계프을같이야찌같배를어서\n",
            "을어어찌계어야찌계프찌배이야찌배을계어찌\n",
            "계프을배계어야배계프배배가야을배배계어찌\n",
            "계프계배이어고배이어배배가계계프배이어찌\n",
            "고배계배이고고배이고배배가고찌찌배이고찌\n",
            "고찌계배이고고배이고배이가고찌찌배이고찌\n",
            "고배계배이고고배이고배이가계찌찌배이고찌\n",
            "프고고배이고고배이고배이가를찌찌배이고찌\n",
            "프어를배이어고배이어배이가계를를배이어을\n",
            "프배계배이어야배이어배이가계를를배이어을\n",
            "를어를배개어야배개어배이가를찌찌배개어을\n",
            "를어를배개고야배개고배이가찌찌찌배개고서\n",
            "를을계배개고야배개고배이가찌찌찌배개고서\n",
            "를을계배계고고배계고배이가찌찌찌배계고서\n",
            "를을를배계고고배계고배이가야찌찌배계고서\n",
            "찌을를배계고고배계고배이가야찌찌배계고서\n",
            "찌을이배계프고배계프배이가야찌찌배계프서\n",
            "를을이배계프고배이프배이가고찌를배이프서\n",
            "를란찌배이프고배이프배이가고찌를배이프서\n",
            "를란를배이프고배이프배이가고찌를배이프서\n",
            "를을을배이프고를이어배이가고찌를배이프서\n",
            "를을배이가프서배가프배이가어배이배가프서\n",
            "를을배이가어서이가어이이가어배이배가어서\n",
            "를을배이가어서이가프이이가가이이배가어서\n",
            "를배배이가어서이계배이이가가이이배가어서\n",
            "를배이이계어서이계배이배가어이이배계어서\n",
            "를배이이계어서같계어이배계어같이배계어서\n",
            "를배을배이어찌같계프을배이어같개프계어찌\n",
            "를배을배이야고같계프을같이야같개프계어고\n",
            "를고을같이야고같계프을같이야같개프계고고\n",
            "를고을같이야고같계프을같이야찌고프가고고\n",
            "를야찌을개야고같가프을같가야고고프개고고\n",
            "를야를을가야고배가프을같가야고를프가고고\n",
            "어야배을가야찌배가프을같가야찌를프가어찌\n",
            "어야배을가어찌배가프을같가야찌를프가어찌\n",
            "어야배배가야찌배가프을이가야고를프가어찌\n",
            "어야배배가야서배가프을이이야고를프가어을\n",
            "어배배이이야을배이프을이이야찌를프이프을\n",
            "어배배이이야을배이프을이이야찌를프이프을\n",
            "어배배이이프을배이프을이이프찌를프이프을\n",
            "을배을이이프을배계프을이이프찌를프이프을\n",
            "을찌을이이고고프계고을이이고찌를프이고을\n",
            "계찌고이개어고프계어을이이어찌계배이어을\n",
            "계찌고이가어고배계어을이개야찌를배개어을\n",
            "계찌고이가야고배계야을이가야찌를배계야을\n",
            "먹을를배계고고배계고을같가고찌를배계고을\n",
            "먹을를배개야서배계야을같가야찌를을개야을\n",
            "를을를배개야서배개야배을가야찌를배개야을\n",
            "프을고배개야서배개야을을가야찌를배개어을\n",
            "프을를배개고서를개어배배가고찌를배개어을\n",
            "프프를배개어고배개어서을가어찌를배개어을\n",
            "프프를배개어찌배개어서을가어찌를배개어서\n",
            "프프를배개어찌배이고서을가어찌를배개고서\n",
            "프프를배개야고배개고서이가야찌를배개고서\n",
            "찌프를배개야고배개프이이가야찌를배개고서\n",
            "찌프고배계야고배계고이이가야찌를배계고서\n",
            "야고고배계야고배계프을이가야고를배계프서\n",
            "야고을배개야고배계고서이가야고를배계고서\n",
            "을계을배개야고배개프서이가야찌를배개프서\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "89daa164-b973-4c16-eef3-599a5cdebf9f",
        "id": "Veh40DJyodLH"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'을계을배개야고배개프서이가야찌를배개프서'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. 불용어X + baseline 수정 + sequence length 늘림 + lr 0.001"
      ],
      "metadata": {
        "id": "RGgB5x8Pot8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = (\"배가 고프다\"\n",
        "            \"그래서 김치찌개를 먹을 것이다\"\n",
        "            \"김치찌개랑 밥이랑 계란을 같이 먹어야지\")"
      ],
      "metadata": {
        "id": "nCEFmx0Wot8X"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "world_set = list(set(sentence))\n",
        "vocab = {char: idx for idx, char in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "quT62cY2ot8Y"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3f9cce-4622-41db-f67f-6367bdca7d9d",
        "id": "dYpI41XBot8Y"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'먹': 0, '고': 1, '치': 2, '을': 3, '계': 4, '프': 5, '개': 6, '란': 7, '야': 8, '를': 9, '같': 10, '이': 11, '어': 12, '찌': 13, '서': 14, '가': 15, '배': 16, '다': 17, '것': 18, '그': 19, '김': 20, '밥': 21, ' ': 22, '래': 23, '랑': 24, '지': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "적절하지 않음 -> 형태소 토큰화"
      ],
      "metadata": {
        "id": "Y5IL4YEZot8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "tokenizer = Mecab()\n",
        "print(tokenizer.morphs(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca4e568-0a96-4b48-c503-bb75fb900f38",
        "id": "ZW0Q38Pcot8Z"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '가', '고프', '다', '그래서', '김치찌개', '를', '먹', '을', '것', '이', '다', '김치찌개', '랑', '밥', '이랑', '계란', '을', '같이', '먹', '어야지']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer.morphs(sentence)"
      ],
      "metadata": {
        "id": "swQgba7got8a"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e7a599-cde9-42b7-a58a-cfeec5db90b9",
        "id": "G1h4sK6Yot8a"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '가', '고프', '다', '그래서', '김치찌개', '를', '먹', '을', '것', '이', '다', '김치찌개', '랑', '밥', '이랑', '계란', '을', '같이', '먹', '어야지']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어 집합 생성\n",
        "word_to_idx = {word: idx for idx, word in enumerate(set(tokenized))} #tokenized에 포함된 단어들을중복 제거 -> 단어를 key, 인덱스를 값으로 사용하여 매핑\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()} #word to idx 키와 값 순서 바꿔서 변환 매핑"
      ],
      "metadata": {
        "id": "45t5P4VSot8a"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 생성\n",
        "input= []\n",
        "target = []\n",
        "\n",
        "sequence_length = 5 #문장이 짧아서 짧게 설정 -> 늘려줌\n",
        "learning_rate = 0.001\n",
        "vocab_size = len(word_to_idx)\n",
        "hidden_size = vocab_size\n",
        "\n",
        "for i in range(len(tokenized) - sequence_length):\n",
        "  input_seq = tokenized[i:i+sequence_length]\n",
        "  target_seq = tokenized[i+1:i+sequence_length+1]\n",
        "\n",
        "  input.append([word_to_idx[word] for word in input_seq])\n",
        "  target.append([word_to_idx[word] for word in target_seq])"
      ],
      "metadata": {
        "id": "HtfkAEUMot8b"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.array(input)\n",
        "target = np.array(target)\n",
        "\n",
        "#one-hot encoding\n",
        "def one_hot_encoding(data,num_classes):\n",
        "  num_data = data.shape[0]\n",
        "  num_seq = data.shape[1]\n",
        "  one_hot = np.zeros((num_data,num_seq,num_classes), dtype=np.float32)\n",
        "  for i in range(num_data):\n",
        "    for j in range(num_seq):\n",
        "      one_hot[i,j,data[i,j]] = 1\n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "S52PZ2loot8b"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = one_hot_encoding(input, vocab_size)\n",
        "\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(target)"
      ],
      "metadata": {
        "id": "TDc6ddttot8b"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca6c66e-6ef7-4cfb-dc1f-e504efaedf70",
        "id": "O7rr0Bobot8c"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN (맨 위 베이스라인 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn1 = torch.nn.RNN(input_size=input_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.rnn2 = torch.nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.rnn3 = torch.nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn1(x)\n",
        "        out, _ = self.rnn2(out)\n",
        "        out, _ = self.rnn3(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "svdvSwfYot8c"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 3) #layer=3개"
      ],
      "metadata": {
        "id": "bvkfqUI_ot8c"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "4Yp6kFPUot8d"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5355e6c7-138b-416f-b231-7398e24ca5a5",
        "id": "tY6VMaW4ot8d"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 5, 17])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    loss = criterion(outputs.view(-1, vocab_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7982b6-df95-4093-c79f-c73e9976817b",
        "id": "DV_OK-hOot8d"
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이이계이이이이이이이이이이이이이이이이이\n",
            "이이계이이이이이이이이이이이이이이이이이\n",
            "이이계계이이이이이이이이이이이이이이이이\n",
            "이이계계이이이이이이이이이이이이이이이이\n",
            "이이계계이이이이계이이이이이이이이이계이\n",
            "이이계계계계계계계계계계계계계계계계계계\n",
            "이이계계계계계계계계계계계계계계계계계계\n",
            "이이계계계계계계계계계계계계계계계계계계\n",
            "이이계계계계계계계계계계계계계계계계계계\n",
            "이이계계계계계계계계계계계계계계계계계계\n",
            "이이계계계계계계계계계계계계계계계계계계\n",
            "이이계계계계계계계계계계계계계계계계계계\n",
            "이이계계계계계계계계계계계계계계계계계계\n",
            "이이계계계계계계계계계계계계계계계계계계\n",
            "이이계계계계계계계계계계계계계계계계계계\n",
            "이이계계계계계계계계계계계계계계계계계계\n",
            "이이계계배배배배계배배배배배배배배배배배\n",
            "이이계계배배배배배배배배배배배배배배배배\n",
            "이이계계배배배배배배배배배배배배배배배배\n",
            "이이계배배배배배배배배배배배배배배배배배\n",
            "이이계배배배배배배배배배배배배배배배배배\n",
            "이이계배배배배배배배배배배배배배배배배배\n",
            "이이계배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이배배배배배배배배배배배배배배배배배배\n",
            "이이이배이배배이배배이배배배이이배배배배\n",
            "이이이배이배이이배배이배배이이이이배배이\n",
            "이이이배이배이이배이이배이이이이이배배이\n",
            "이이이이이이이이배이이이이이이이이이이이\n",
            "이이이이이이이이이이이이이이이이이이이이\n",
            "이이이이이이이이이이이이이이이이이이이이\n",
            "이이이이이이이이이이이이이이이이이이이이\n",
            "이이이이이이이이이이이이이이이이이이이이\n",
            "이이이이이이이이배이이이이이이이이이이이\n",
            "이이이이이이이이배이이배이이이이이배이이\n",
            "이이이이이배이이배이이배이이이이이배이이\n",
            "이이이이이배이이배이이배이이이이이배이이\n",
            "이이이이이배이이배이이배이이이이이배이이\n",
            "이이이이이배이이배이이배이이이이이배이이\n",
            "이이이이이배이이배이이배이이이이이배이이\n",
            "이이이이이배이이배이이배이이이이배배이이\n",
            "이이이이이배이이배이이배이이이이배배이이\n",
            "이이이이이배이이배이이배배이이이배배이이\n",
            "이이이이이배이이배이이배배이이이배배이이\n",
            "이이이고이배이이배고이배배이이이배배이이\n",
            "이이이고이배이이배고이배배이이이배배고이\n",
            "이이이고이배프이배고이배배이배이배배고프\n",
            "이이이고이배프이배프이이고프배이배배고프\n",
            "이이이고이배프이이프이이고프배이배배고프\n",
            "이이이프이배프이이프이이고프배이배배고프\n",
            "이이이프이배프이이프이이고프프이배배고프\n",
            "을이이프이배프이이프이이고프프이배배고프\n",
            "을이이프이배프이이프이이고프프이배배고프\n",
            "프이이프이배프이이프이이고프프이배이고프\n",
            "프이이프이이프이이프이이고프프이배이고프\n",
            "프이이프이이프이이프이이고프프배배이고프\n",
            "프이이프이이프이이프이이고프프배배이고프\n",
            "프이이프이어프이이프이이고프프배배이고프\n",
            "프배이프배어프이이프배이고프프배배이고프\n",
            "프배이프배어프이이프배이고프프배배이고프\n",
            "프배이프배어프이이프배이어프프배배이고프\n",
            "프을이프배어프이이프배이어프프배배이고프\n",
            "프을이프배어프이이프배이어프프를배이고프\n",
            "프을이프배어프이이프배이어프프를배이고프\n",
            "프을이프배어프이이프배이어프프를배이고프\n",
            "프을이고배어프이이프배이어프프를배이고프\n",
            "프를이고배어프이이프배이어프프를배이고프\n",
            "프를이고배어프이이프배이어프프를배이고프\n",
            "프를이고배어프이이프배이어프프를배이고프\n",
            "프를이을배어프이이프배이이고프를배이고프\n",
            "프를을을배어프이이프배이이고프를이이고프\n",
            "프를을을배어프이이프배이이고프를이이고프\n",
            "프를을을배어프이이프배이이고프를이이고프\n",
            "프를을을배어프이이프배이이고프를이이고프\n",
            "프를을을배어프이이프배이이고프를이이고를\n",
            "프를을을배어프이이프배이이고프를이이고을\n",
            "프를을를이어프이계프을이이고프를이이고을\n",
            "프를을를이어프이계프을이이고프를이이고을\n",
            "프를을를이어프이계프을이이고프를이이고을\n",
            "프를을를이어프이계프을이이고프를이이고을\n",
            "프를을를이어프이계프을이이고프를이이고을\n",
            "프를을를이어프이계프을이이고프를이이고을\n",
            "프를를를이어프이계프을이이고프를이이고을\n",
            "프를를를이어프이계프을이이고프를이이고을\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "64da33fa-cf6b-4b8f-cf22-203b9e33448d",
        "id": "2F6fuQgPot8d"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'프를를를이어프이계프을이이고프를이이고을'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7. 불용어처리 + baseline + lr 0.05"
      ],
      "metadata": {
        "id": "OhDv74rupBFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = (\"배가 고프다\"\n",
        "            \"그래서 김치찌개를 먹을 것이다\"\n",
        "            \"김치찌개랑 밥이랑 계란을 같이 먹어야지\")"
      ],
      "metadata": {
        "id": "DwqDaqHnpBFk"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "world_set = list(set(sentence))\n",
        "vocab = {char: idx for idx, char in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "C7uP40DTpBFl"
      },
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef49594-62db-4b88-863c-ec93a72f7ef9",
        "id": "7e3_YKkApBFl"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'먹': 0, '고': 1, '치': 2, '을': 3, '계': 4, '프': 5, '개': 6, '란': 7, '야': 8, '를': 9, '같': 10, '이': 11, '어': 12, '찌': 13, '서': 14, '가': 15, '배': 16, '다': 17, '것': 18, '그': 19, '김': 20, '밥': 21, ' ': 22, '래': 23, '랑': 24, '지': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "적절하지 않음 -> 형태소 토큰화"
      ],
      "metadata": {
        "id": "cGeZqWS7pBFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "tokenizer = Mecab()\n",
        "print(tokenizer.morphs(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f8f5af-9eaa-4d11-e3b3-18093bdea026",
        "id": "p2NH8NzKpBFo"
      },
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '가', '고프', '다', '그래서', '김치찌개', '를', '먹', '을', '것', '이', '다', '김치찌개', '랑', '밥', '이랑', '계란', '을', '같이', '먹', '어야지']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer.morphs(sentence)"
      ],
      "metadata": {
        "id": "V5bLTBRDpBFo"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 정의\n",
        "stopwords=['가','다','를','을','이','다','랑','이랑','어야지','']"
      ],
      "metadata": {
        "id": "uC0FHapTpBFo"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = [word for word in tokenized if word not in stopwords] #불용어 제거"
      ],
      "metadata": {
        "id": "GH-rUg6SpBFo"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "966aca33-bde5-4bb8-f13c-6f3e7012d417",
        "id": "8B9t8MRNpBFp"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '고프', '그래서', '김치찌개', '먹', '것', '김치찌개', '밥', '계란', '같이', '먹']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어 집합 생성\n",
        "word_to_idx = {word: idx for idx, word in enumerate(set(tokenized))} #tokenized에 포함된 단어들을중복 제거 -> 단어를 key, 인덱스를 값으로 사용하여 매핑\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()} #word to idx 키와 값 순서 바꿔서 변환 매핑"
      ],
      "metadata": {
        "id": "PytWGpl2pBFp"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 생성\n",
        "input= []\n",
        "target = []\n",
        "\n",
        "sequence_length = 3 #문장이 짧아서 짧게 설정\n",
        "learning_rate = 0.05\n",
        "vocab_size = len(word_to_idx)\n",
        "hidden_size = vocab_size\n",
        "\n",
        "for i in range(len(tokenized) - sequence_length):\n",
        "  input_seq = tokenized[i:i+sequence_length]\n",
        "  target_seq = tokenized[i+1:i+sequence_length+1]\n",
        "\n",
        "  input.append([word_to_idx[word] for word in input_seq])\n",
        "  target.append([word_to_idx[word] for word in target_seq])"
      ],
      "metadata": {
        "id": "6cfLjaWqpBFp"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.array(input)\n",
        "target = np.array(target)\n",
        "\n",
        "#one-hot encoding\n",
        "def one_hot_encoding(data,num_classes):\n",
        "  num_data = data.shape[0]\n",
        "  num_seq = data.shape[1]\n",
        "  one_hot = np.zeros((num_data,num_seq,num_classes), dtype=np.float32)\n",
        "  for i in range(num_data):\n",
        "    for j in range(num_seq):\n",
        "      one_hot[i,j,data[i,j]] = 1\n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "_lSPM97fpBFq"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = one_hot_encoding(input, vocab_size)\n",
        "\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(target)"
      ],
      "metadata": {
        "id": "ZRnB5jxfpBFq"
      },
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "801da151-80f2-49b8-cf00-01a58a16980d",
        "id": "45-mQkfmpBFq"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN (맨 위 베이스라인 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn1 = torch.nn.RNN(input_size=input_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.rnn2 = torch.nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn1(x)\n",
        "        out, _ = self.rnn2(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "3lFFwtBxpBFq"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2) #layer=2개"
      ],
      "metadata": {
        "id": "MbO3OgJ0pBFr"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "8lb2sjSspBFr"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081ca614-80e0-4449-f5c4-c2471f7c6720",
        "id": "fM98zIJbpBFr"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    loss = criterion(outputs.view(-1, vocab_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d953c90-08a2-4fc0-9104-20250e175e46",
        "id": "_6HGsi1LpBFr"
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "프프고고고을을을고고\n",
            "개개개개개개개개개개\n",
            "프야야야프프프야먹야\n",
            "야치야야야야야야먹야\n",
            "야치야야치야야야먹야\n",
            "야치야먹치야먹치먹야\n",
            "야을야먹치야먹개을야\n",
            "개을야먹치야먹개을야\n",
            "개란야먹치야프개을야\n",
            "개란야먹치야프개을야\n",
            "개란야먹치야프개을야\n",
            "개란야먹치야프개을야\n",
            "개란야먹치야프개을먹\n",
            "란란야먹치야프개을먹\n",
            "개란야먹치야프개을먹\n",
            "개란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ad6e9ec5-56d8-45bb-f091-7ee5bd8716ac",
        "id": "7x49Mm9IpBFs"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'계란야먹치야프개을먹'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8. 불용어처리 + baseline + lr 0.05 + optimizer-sgd\n",
        "\n",
        "=> 너무 별로임"
      ],
      "metadata": {
        "id": "wQNIcdGGpWyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = (\"배가 고프다\"\n",
        "            \"그래서 김치찌개를 먹을 것이다\"\n",
        "            \"김치찌개랑 밥이랑 계란을 같이 먹어야지\")"
      ],
      "metadata": {
        "id": "gd6QQKlEpWyq"
      },
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "world_set = list(set(sentence))\n",
        "vocab = {char: idx for idx, char in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "o4E2Nf-BpWyr"
      },
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f9c90d-0470-49c2-ef05-56f2946c7d75",
        "id": "PUyBS4MSpWyr"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'먹': 0, '고': 1, '치': 2, '을': 3, '계': 4, '프': 5, '개': 6, '란': 7, '야': 8, '를': 9, '같': 10, '이': 11, '어': 12, '찌': 13, '서': 14, '가': 15, '배': 16, '다': 17, '것': 18, '그': 19, '김': 20, '밥': 21, ' ': 22, '래': 23, '랑': 24, '지': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "적절하지 않음 -> 형태소 토큰화"
      ],
      "metadata": {
        "id": "5XKZj7SLpWys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "tokenizer = Mecab()\n",
        "print(tokenizer.morphs(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae5b3d1-f77d-44ba-954b-880e9306a49f",
        "id": "qkQQ7qKgpWyt"
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '가', '고프', '다', '그래서', '김치찌개', '를', '먹', '을', '것', '이', '다', '김치찌개', '랑', '밥', '이랑', '계란', '을', '같이', '먹', '어야지']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer.morphs(sentence)"
      ],
      "metadata": {
        "id": "3GMgSbrTpWyt"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 정의\n",
        "stopwords=['가','다','를','을','이','다','랑','이랑','어야지','']"
      ],
      "metadata": {
        "id": "xcPxKie6pWyt"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = [word for word in tokenized if word not in stopwords] #불용어 제거"
      ],
      "metadata": {
        "id": "cU9B8BDvpWyu"
      },
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83cf8f9d-eb0b-4978-f1b5-f585c20b3b48",
        "id": "kQqpi9BIpWyu"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '고프', '그래서', '김치찌개', '먹', '것', '김치찌개', '밥', '계란', '같이', '먹']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어 집합 생성\n",
        "word_to_idx = {word: idx for idx, word in enumerate(set(tokenized))} #tokenized에 포함된 단어들을중복 제거 -> 단어를 key, 인덱스를 값으로 사용하여 매핑\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()} #word to idx 키와 값 순서 바꿔서 변환 매핑"
      ],
      "metadata": {
        "id": "LkXySiPHpWyu"
      },
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 생성\n",
        "input= []\n",
        "target = []\n",
        "\n",
        "sequence_length = 3 #문장이 짧아서 짧게 설정\n",
        "learning_rate = 0.05\n",
        "vocab_size = len(word_to_idx)\n",
        "hidden_size = vocab_size\n",
        "\n",
        "for i in range(len(tokenized) - sequence_length):\n",
        "  input_seq = tokenized[i:i+sequence_length]\n",
        "  target_seq = tokenized[i+1:i+sequence_length+1]\n",
        "\n",
        "  input.append([word_to_idx[word] for word in input_seq])\n",
        "  target.append([word_to_idx[word] for word in target_seq])"
      ],
      "metadata": {
        "id": "mZ9elz_7pWyu"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.array(input)\n",
        "target = np.array(target)\n",
        "\n",
        "#one-hot encoding\n",
        "def one_hot_encoding(data,num_classes):\n",
        "  num_data = data.shape[0]\n",
        "  num_seq = data.shape[1]\n",
        "  one_hot = np.zeros((num_data,num_seq,num_classes), dtype=np.float32)\n",
        "  for i in range(num_data):\n",
        "    for j in range(num_seq):\n",
        "      one_hot[i,j,data[i,j]] = 1\n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "0udVYYbHpWyv"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = one_hot_encoding(input, vocab_size)\n",
        "\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(target)"
      ],
      "metadata": {
        "id": "TixQGI2SpWyv"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b2bb54-e68b-4f95-bad9-528a0bd782da",
        "id": "TeelZQGspWyv"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN (맨 위 베이스라인 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn1 = torch.nn.RNN(input_size=input_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.rnn2 = torch.nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn1(x)\n",
        "        out, _ = self.rnn2(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "1cfnrCwxpWyw"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2) #layer=2개"
      ],
      "metadata": {
        "id": "ufbPsG2opWyw"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "LmSGuDJPpWyx"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a074a2-f3c6-4bef-8456-d6a899ced259",
        "id": "Vxnvzl2XpWyx"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    loss = criterion(outputs.view(-1, vocab_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e7b2520-a030-4d51-c387-e1f1560f3383",
        "id": "IRiwk_iIpWyx"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "먹먹을먹먹먹먹먹을먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹야먹먹먹먹먹먹먹\n",
            "먹먹야먹먹먹먹먹야야\n",
            "먹먹야먹야야먹먹야야\n",
            "먹야야야야야먹야야야\n",
            "먹야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "73d190b5-2e1a-43d6-903c-6d280c791f28",
        "id": "L3JlYdvbpWyy"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'야야야야야야야야야야'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##9. 불용어처리 + baseline + lr 0.05 + optimizer-sgd + epoch 늘림"
      ],
      "metadata": {
        "id": "Qkg4Lcz2p0ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = (\"배가 고프다\"\n",
        "            \"그래서 김치찌개를 먹을 것이다\"\n",
        "            \"김치찌개랑 밥이랑 계란을 같이 먹어야지\")"
      ],
      "metadata": {
        "id": "RZ0xl-Ejp0i-"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "world_set = list(set(sentence))\n",
        "vocab = {char: idx for idx, char in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "vrhBfBbip0i-"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e4c0e0-dcc7-48e7-ea72-2bb20f16355a",
        "id": "-McTOwq0p0i_"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'먹': 0, '고': 1, '치': 2, '을': 3, '계': 4, '프': 5, '개': 6, '란': 7, '야': 8, '를': 9, '같': 10, '이': 11, '어': 12, '찌': 13, '서': 14, '가': 15, '배': 16, '다': 17, '것': 18, '그': 19, '김': 20, '밥': 21, ' ': 22, '래': 23, '랑': 24, '지': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "적절하지 않음 -> 형태소 토큰화"
      ],
      "metadata": {
        "id": "ifVkbWnsp0i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "tokenizer = Mecab()\n",
        "print(tokenizer.morphs(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65bf5a72-8778-4060-8755-8c744b381d70",
        "id": "75ZR5GJpp0jA"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '가', '고프', '다', '그래서', '김치찌개', '를', '먹', '을', '것', '이', '다', '김치찌개', '랑', '밥', '이랑', '계란', '을', '같이', '먹', '어야지']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer.morphs(sentence)"
      ],
      "metadata": {
        "id": "_VeQM9ucp0jA"
      },
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 정의\n",
        "stopwords=['가','다','를','을','이','다','랑','이랑','어야지','']"
      ],
      "metadata": {
        "id": "fbIgYpv3p0jB"
      },
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = [word for word in tokenized if word not in stopwords] #불용어 제거"
      ],
      "metadata": {
        "id": "FNp6faUyp0jB"
      },
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d52ec4-3f2f-44ec-ef4c-6f2b9ca72656",
        "id": "n-A-ph5Bp0jB"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '고프', '그래서', '김치찌개', '먹', '것', '김치찌개', '밥', '계란', '같이', '먹']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어 집합 생성\n",
        "word_to_idx = {word: idx for idx, word in enumerate(set(tokenized))} #tokenized에 포함된 단어들을중복 제거 -> 단어를 key, 인덱스를 값으로 사용하여 매핑\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()} #word to idx 키와 값 순서 바꿔서 변환 매핑"
      ],
      "metadata": {
        "id": "D8W7YxS5p0jC"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 생성\n",
        "input= []\n",
        "target = []\n",
        "\n",
        "sequence_length = 3 #문장이 짧아서 짧게 설정\n",
        "learning_rate = 0.05\n",
        "vocab_size = len(word_to_idx)\n",
        "hidden_size = vocab_size\n",
        "\n",
        "for i in range(len(tokenized) - sequence_length):\n",
        "  input_seq = tokenized[i:i+sequence_length]\n",
        "  target_seq = tokenized[i+1:i+sequence_length+1]\n",
        "\n",
        "  input.append([word_to_idx[word] for word in input_seq])\n",
        "  target.append([word_to_idx[word] for word in target_seq])"
      ],
      "metadata": {
        "id": "WY-RZR68p0jC"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.array(input)\n",
        "target = np.array(target)\n",
        "\n",
        "#one-hot encoding\n",
        "def one_hot_encoding(data,num_classes):\n",
        "  num_data = data.shape[0]\n",
        "  num_seq = data.shape[1]\n",
        "  one_hot = np.zeros((num_data,num_seq,num_classes), dtype=np.float32)\n",
        "  for i in range(num_data):\n",
        "    for j in range(num_seq):\n",
        "      one_hot[i,j,data[i,j]] = 1\n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "ATD4D_Gyp0jC"
      },
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = one_hot_encoding(input, vocab_size)\n",
        "\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(target)"
      ],
      "metadata": {
        "id": "hfZzQmPgp0jC"
      },
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "423d1619-7687-405a-f463-9804d033d64a",
        "id": "HGPJlPLap0jD"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN (맨 위 베이스라인 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn1 = torch.nn.RNN(input_size=input_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.rnn2 = torch.nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn1(x)\n",
        "        out, _ = self.rnn2(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "5M1A30s-p0jD"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2) #layer=2개"
      ],
      "metadata": {
        "id": "v96hGJJwp0jE"
      },
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "W5f8eenrp0jE"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df115083-2d30-4a96-fafb-b3d2c1ea29b9",
        "id": "O94GERgFp0jE"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습\n",
        "for i in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    loss = criterion(outputs.view(-1, vocab_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1baf7b77-52e2-4d8b-ddae-978dd197aad7",
        "id": "v2vhVbrCp0jF"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5d95f4fe-3501-4331-f317-5debd5210b41",
        "id": "yapKtgTXp0jF"
      },
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'계란야먹치야프개을먹'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##10. 불용어처리 + baseline + lr 0.05 + epoch늘림"
      ],
      "metadata": {
        "id": "g8QVf0MiqNpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = (\"배가 고프다\"\n",
        "            \"그래서 김치찌개를 먹을 것이다\"\n",
        "            \"김치찌개랑 밥이랑 계란을 같이 먹어야지\")"
      ],
      "metadata": {
        "id": "6rcu-yidqNpb"
      },
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "world_set = list(set(sentence))\n",
        "vocab = {char: idx for idx, char in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "RbiDU5EjqNpc"
      },
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "279a5fab-0144-4e95-fc6b-31d6bd04c025",
        "id": "8tKWbqVMqNpc"
      },
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'먹': 0, '고': 1, '치': 2, '을': 3, '계': 4, '프': 5, '개': 6, '란': 7, '야': 8, '를': 9, '같': 10, '이': 11, '어': 12, '찌': 13, '서': 14, '가': 15, '배': 16, '다': 17, '것': 18, '그': 19, '김': 20, '밥': 21, ' ': 22, '래': 23, '랑': 24, '지': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "적절하지 않음 -> 형태소 토큰화"
      ],
      "metadata": {
        "id": "h1mA7ydQqNpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "tokenizer = Mecab()\n",
        "print(tokenizer.morphs(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd580599-f9d1-4e11-d3b0-7b1590406035",
        "id": "d9QoZ4AUqNpd"
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '가', '고프', '다', '그래서', '김치찌개', '를', '먹', '을', '것', '이', '다', '김치찌개', '랑', '밥', '이랑', '계란', '을', '같이', '먹', '어야지']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer.morphs(sentence)"
      ],
      "metadata": {
        "id": "eY-Lg0dOqNpd"
      },
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 정의\n",
        "stopwords=['가','다','를','을','이','다','랑','이랑','어야지','']"
      ],
      "metadata": {
        "id": "tloCvOEAqNpe"
      },
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = [word for word in tokenized if word not in stopwords] #불용어 제거"
      ],
      "metadata": {
        "id": "n2jeodgMqNpe"
      },
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6770fcea-6cc1-4051-d262-18055b9d7324",
        "id": "K82X6opvqNpe"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['배', '고프', '그래서', '김치찌개', '먹', '것', '김치찌개', '밥', '계란', '같이', '먹']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어 집합 생성\n",
        "word_to_idx = {word: idx for idx, word in enumerate(set(tokenized))} #tokenized에 포함된 단어들을중복 제거 -> 단어를 key, 인덱스를 값으로 사용하여 매핑\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()} #word to idx 키와 값 순서 바꿔서 변환 매핑"
      ],
      "metadata": {
        "id": "1Cva1VEjqNpf"
      },
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 생성\n",
        "input= []\n",
        "target = []\n",
        "\n",
        "sequence_length = 3 #문장이 짧아서 짧게 설정\n",
        "learning_rate = 0.05\n",
        "vocab_size = len(word_to_idx)\n",
        "hidden_size = vocab_size\n",
        "\n",
        "for i in range(len(tokenized) - sequence_length):\n",
        "  input_seq = tokenized[i:i+sequence_length]\n",
        "  target_seq = tokenized[i+1:i+sequence_length+1]\n",
        "\n",
        "  input.append([word_to_idx[word] for word in input_seq])\n",
        "  target.append([word_to_idx[word] for word in target_seq])"
      ],
      "metadata": {
        "id": "7xSaFTyJqNpf"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.array(input)\n",
        "target = np.array(target)\n",
        "\n",
        "#one-hot encoding\n",
        "def one_hot_encoding(data,num_classes):\n",
        "  num_data = data.shape[0]\n",
        "  num_seq = data.shape[1]\n",
        "  one_hot = np.zeros((num_data,num_seq,num_classes), dtype=np.float32)\n",
        "  for i in range(num_data):\n",
        "    for j in range(num_seq):\n",
        "      one_hot[i,j,data[i,j]] = 1\n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "uNwGuC1UqNpf"
      },
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = one_hot_encoding(input, vocab_size)\n",
        "\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(target)"
      ],
      "metadata": {
        "id": "3JSYzHPrqNpg"
      },
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0d9b68-107e-4b63-ad81-a9f862de488a",
        "id": "Tnu6VKAkqNpg"
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN (맨 위 베이스라인 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn1 = torch.nn.RNN(input_size=input_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.rnn2 = torch.nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn1(x)\n",
        "        out, _ = self.rnn2(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "AaTc4z5-qNpg"
      },
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2) #layer=2개"
      ],
      "metadata": {
        "id": "OqRt7lZVqNph"
      },
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "5V8uhpXfqNph"
      },
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be0f5c46-f351-4aae-e32b-a469761be682",
        "id": "75hjhRzYqNph"
      },
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습\n",
        "for i in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    loss = criterion(outputs.view(-1, vocab_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe7d7a0-3d97-411f-e0ac-674a9e5a1bc6",
        "id": "S5Cj94khqNph"
      },
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "란란란란란란란란란란\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "먹먹먹먹먹먹먹먹먹먹\n",
            "야야야야야야야야야야\n",
            "야야야야야야야야야야\n",
            "치야야먹야야프야야먹\n",
            "치야야먹야야프개먹먹\n",
            "치프개먹먹야프개먹먹\n",
            "치프개먹치야프개먹먹\n",
            "치프야먹치야야개을먹\n",
            "치프야먹치야야개을먹\n",
            "치프야먹치야야개을먹\n",
            "치프야먹치야야개을먹\n",
            "치프야야치야야개을먹\n",
            "치프야먹치야야개을먹\n",
            "치란야먹치야야개을먹\n",
            "치란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n",
            "계란야먹치야프개을먹\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "031950bf-3d32-4602-e1ae-7f8a4c0947c8",
        "id": "7gNMGtd3qNpi"
      },
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'계란야먹치야프개을먹'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 340
        }
      ]
    }
  ]
}