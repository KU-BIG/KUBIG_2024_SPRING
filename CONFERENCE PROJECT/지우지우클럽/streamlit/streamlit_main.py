import streamlit as st
import numpy as np
import pandas as pd
import requests
import pickle
import sklearn
import re
import tqdm
import numpy as np
import pandas as pd
import zipfile
import scipy
from zipfile import ZipFile



from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from implicit.als import AlternatingLeastSquares as ALS  



st.set_page_config(layout="wide")


# ''' Backend '''
franchise_burger = pd.read_csv('df_franchise.csv')
premium_burger = pd.read_csv('df_premium_final.csv')

# ë°ì´í„° ì „ì²˜ë¦¬
# í”„ë¦¬ë¯¸ì—„ ë²„ê±° ê°€ê²© ìˆ«ìí˜• ë°ì´í„°ë¡œ ë°”ê¾¸ëŠ” ì‘ì—…
# 'ì›' ì§€ìš°ê³  ì§„í–‰
premium_burger['price'] = premium_burger['price'].replace({'ì›': '', ',': ''}, regex=True)
# ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ëŠ” ê²½ìš° nan ì²˜ë¦¬
premium_burger['price'] = pd.to_numeric(premium_burger['price'], errors='coerce')
# priceì—ì„œ ê²°ì¸¡ê°’ ìˆëŠ” í–‰ ì œê±°
premium_burger = premium_burger.dropna(subset=['price'])
# ì •ìˆ˜í˜•ìœ¼ë¡œ ë°”ê¾¸ê¸°
premium_burger['price'] = premium_burger['price'].astype(int)
franchise_burger = franchise_burger.rename(columns={
    'brand': 'name',
    'name': 'menu',
})


franchise_burger['menu_input'] = '[' + franchise_burger['name'] + '] ' + franchise_burger['menu']


# í”„ëœì°¨ì´ì¦ˆì—ì„œ ê´€ë ¨ìˆëŠ” í–‰ë§Œ ëª¨ìœ¼ê¸°
filtered_franchise_burger = franchise_burger[[ 'name', 'menu', 'price', 'wordlist', 'patty']]
# í”„ëœì°¨ì´ì¦ˆ, í”„ë¦¬ë¯¸ì—„ í´ë˜ìŠ¤ êµ¬ë¶„
filtered_franchise_burger['class'] = 0
premium_burger['class'] = 1
burger_data = pd.concat([filtered_franchise_burger, premium_burger], ignore_index = True)

burger_data['visitor'] = burger_data['visitor'].fillna('0')
burger_data['blog'] = burger_data['blog'].fillna('0')

burger_data['visitor'] = burger_data['visitor'].str.replace(',', '').astype(int)
burger_data['blog'] = burger_data['blog'].str.replace(',', '').astype(int)

max_visitors = burger_data['visitor'].max()
max_blogs = burger_data['blog'].max()


burger_data['wordlist'] = burger_data['wordlist'].astype(str)

tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(' '))
tfidf_matrix = tfidf_vectorizer.fit_transform(burger_data['wordlist'])

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í™•ì¸
similarity_df = pd.DataFrame(cosine_sim, index=burger_data['name'], columns=burger_data['menu'])
similarity_df.head()


def final_recommendation(burger_data, selected_burger_input, min, max, popularity_min):
    selected_burger = re.sub(r'\[.*?\]\s*', '', selected_burger_input)
    selected_burger_patty = burger_data[burger_data['menu'] == selected_burger]['patty'].values[0]
    
    final_scores = similarity_df[selected_burger].values
    recommendations_df = pd.DataFrame({
        'id': burger_data['id'],
    'menu': burger_data['menu'],
    'name': burger_data['name'],
    'class': burger_data['class'],
    'price': burger_data['price'],
    'patty': burger_data['patty'],
    'visitor': burger_data['visitor'],
    'blog': burger_data['blog'],
    'score': final_scores
  })
    filtered_recommendations = recommendations_df[
        (recommendations_df['class'] == 1) &
        (recommendations_df['price'] >= min) &
        (recommendations_df['price'] < max) &
        ((recommendations_df['visitor'] + recommendations_df['blog']) >= popularity_min) &
        (recommendations_df['patty'].str.contains(selected_burger_patty, na = False))
  ]
    filtered_recommendations = filtered_recommendations.drop_duplicates(subset='menu')
    final_recommendations = filtered_recommendations[['id', 'menu', 'name', 'price', 'score']].sort_values(by='score', ascending=False).iloc[1:11]
    return final_recommendations

# ALS í˜‘ì—… í•„í„°ë§
zip_file = 'review_data.csv.zip'
csv_file = 'review_data.csv'

# ZIP íŒŒì¼ ì—´ê¸°
with zipfile.ZipFile(zip_file, 'r') as zipf:
    with zipf.open(csv_file) as file:
        train = pd.read_csv(file)

train = train[['username','restaurant']]
train.columns = ['user_id', 'rest_id']

# ë°ì´í„° <--> ì¸ë±ìŠ¤ êµí™˜ ë”•ì…”ë„ˆë¦¬
user2idx = {}
for i, l in enumerate(train['user_id'].unique()):
    user2idx[l] = i
    
rest2idx = {}
for i, l in enumerate(train['rest_id'].unique()):
    rest2idx[l] = i

idx2user = {}
for i, l in enumerate(train['user_id'].unique()):
    idx2user[i] = l

idx2rest = {}
for i, l in enumerate(train['rest_id'].unique()):
    idx2rest[i] = l

# ì¸ë±ìŠ¤ ìƒì„±
data = train.copy()
useridx = data['useridx'] = train['user_id'].apply(lambda x: user2idx[x]).values
restidx = data['restidx'] = train['rest_id'].apply(lambda x: rest2idx[x]).values
rating = np.ones(len(data))

# í¬ì†Œ í–‰ë ¬(csr_matrix)
purchase_sparse = scipy.sparse.csr_matrix((rating, (useridx, restidx)), shape=(len(set(useridx)), len(set(restidx))))
# ALS ëª¨ë¸ ì´ˆê¸°í™”
als_model = ALS(factors=40, regularization=0.01, iterations=50)
# ëª¨ë¸ ìµœì í™”
als_model.fit(purchase_sparse, show_progress=False)



# ''' Frontend '''
st.title("[KUBIG 19ê¸° ì¶”ì²œì‹œìŠ¤í…œíŒ€] ìˆ˜ì œë²„ê±° ì¶”ì²œì‹œìŠ¤í…œ")
v = st.write(""" <h2> <b style="color:red"> ìˆ˜ì œë²„ê±° </b> ì¶”ì²œì‹œìŠ¤í…œ ğŸ”</h2>""",unsafe_allow_html=True)
st.write(""" <p> í”„ëœì°¨ì´ì¦ˆ ë²„ê±°ë¡œ ì·¨í–¥ ì €ê²© <b style="color:red">ìˆ˜ì œë²„ê±°</b> ì°¾ê¸°! </p>""",unsafe_allow_html=True)
my_expander = st.expander("Tap to Select a Burger ğŸ”")
selected_burger_name = my_expander.selectbox("ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” í”„ëœì°¨ì´ì¦ˆ ë²„ê±°ëŠ”",franchise_burger['menu_input'])
price_range = my_expander.slider("ê°€ê²© ë²”ìœ„ ì„¤ì •", value=[0, 42500])


if my_expander.button("Recommend"):
    st.text("Here are few Recommendations..")
    st.text("ë‹¤ë¥¸ ì¶”ì²œ ê²°ê³¼ë¥¼ ì›í•˜ì‹ ë‹¤ë©´ ê¼­ reset ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”..")
    if st.button("reset"):
        st.session_state.value = "Foo"
        st.rerun()

    st.write("#")
    result = final_recommendation(burger_data, selected_burger_name, price_range[0], price_range[1], 0)
    
    menu_list = result['menu'].tolist()
    id_list = result['id'].tolist()
    name_list = result['name'].tolist()
    price_list = result['price'].tolist()
    score_list = result['score'].tolist()
    
    unique_names = []
    for name in name_list:
        if name not in unique_names:
            unique_names.append(name)
        if len(unique_names) == 5:
            break
    related = als_model.similar_items(rest2idx[unique_names[0]])
    array2list = related[0]
    number_list = array2list.tolist()
    
    result_list = []
    for idx in number_list:
        rest_ids = data[data['restidx'] == idx]['rest_id'].unique()
        for rest_id in rest_ids:
            if rest_id not in unique_names:
                result_list.append(rest_id)

    v = st.write("""<h2> ë‹¹ì‹ ì˜ <b style="color:red"> ìˆ˜ì œë²„ê±° </b> ì·¨í–¥ì€? </h2>""",unsafe_allow_html=True)
    col1,col2,col3,col4,col5=st.columns(5)
    cols=[col1,col2,col3,col4,col5]
    if not menu_list:
        st.write('<b style="color:#E50914"> Sorry, no results found! </b>', unsafe_allow_html=True)
        st.text("ê°€ê²© ë²”ìœ„ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš” ğŸ˜¢")
    else:
        for i in range(0,5):
            rank = i + 1
            with cols[i]:
                st.write(f'{rank}ìœ„')
                st.write(f' <b style="color:#E50914"> {menu_list[i]} </b>',unsafe_allow_html=True)
                # st.write("#")
                st.write("________")
                st.write(f'<b style="color:#DB4437">ê°€ê²Œëª…</b>:<b> {name_list[i]}</b>',unsafe_allow_html=True)
                st.write(f'<b style="color:#DB4437">   Price  </b>: <b> {price_list[i]} <b> ',unsafe_allow_html=True)
    v = st.write(""" <h2> ë°©ë¬¸í•´ë³´ë©´ ì¢‹ì„ ìˆ˜ì œë²„ê±° <b style="color:red"> ê°€ê²Œ </b> ì¶”ì²œ </h2>""",unsafe_allow_html=True)
    col1,col2,col3,col4,col5=st.columns(5)
    cols=[col1,col2,col3,col4,col5]
    for i in range(0,5):
        rank = i + 1
        with cols[i]:
            st.write(f'{rank}ìœ„')
            st.write(f' <b style="color:#E50914"> {result_list[i]} </b>',unsafe_allow_html=True)
            # st.write("#")
            st.write("________")


